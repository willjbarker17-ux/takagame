<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Football Pitch Labeling Tool</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: #1a1a2e;
            color: #eee;
            min-height: 100vh;
        }
        .container { display: flex; height: 100vh; }

        /* Sidebar */
        .sidebar {
            width: 280px;
            background: #16213e;
            padding: 15px;
            overflow-y: auto;
            border-right: 1px solid #0f3460;
        }
        .sidebar h2 { color: #e94560; margin-bottom: 15px; font-size: 1.1rem; }
        .sidebar h3 { color: #94a3b8; margin: 12px 0 8px; font-size: 0.85rem; text-transform: uppercase; }

        /* Video List */
        .video-list {
            max-height: 180px;
            overflow-y: auto;
            border: 1px solid #0f3460;
            border-radius: 6px;
            margin-bottom: 15px;
        }
        .video-item {
            padding: 8px 10px;
            cursor: pointer;
            border-bottom: 1px solid #0f3460;
            font-size: 0.8rem;
            white-space: nowrap;
            overflow: hidden;
            text-overflow: ellipsis;
        }
        .video-item:hover { background: #0f3460; }
        .video-item.selected { background: #e94560; }
        .cache-indicator { font-size: 0.7rem; margin-right: 2px; }

        /* Mode Selector */
        .mode-selector {
            display: flex;
            gap: 4px;
            margin-bottom: 12px;
            background: #0d1117;
            padding: 4px;
            border-radius: 8px;
        }
        .mode-btn {
            flex: 1;
            padding: 10px 8px;
            background: transparent;
            border: none;
            border-radius: 6px;
            color: #94a3b8;
            cursor: pointer;
            font-size: 0.75rem;
            font-weight: 600;
            text-transform: uppercase;
            transition: all 0.2s;
        }
        .mode-btn:hover { background: #1a1a2e; color: #eee; }
        .mode-btn.active.field { background: #22c55e; color: white; }
        .mode-btn.active.player { background: #3b82f6; color: white; }
        .mode-btn.active.ball { background: #f97316; color: white; }

        /* Player Number Input */
        .player-input {
            display: none;
            margin-bottom: 12px;
        }
        .player-input.show { display: block; }
        .player-input label {
            font-size: 0.75rem;
            color: #94a3b8;
            display: block;
            margin-bottom: 4px;
        }
        .player-input input {
            width: 100%;
            padding: 8px;
            background: #0f3460;
            border: 1px solid #1a4a7a;
            border-radius: 5px;
            color: #eee;
            font-size: 0.9rem;
        }

        /* Tools */
        .tools { display: flex; flex-wrap: wrap; gap: 6px; margin-bottom: 15px; }
        .tool-btn {
            padding: 8px 12px;
            background: #0f3460;
            border: none;
            border-radius: 5px;
            color: #eee;
            cursor: pointer;
            font-size: 0.8rem;
        }
        .tool-btn:hover { background: #1a4a7a; }
        .tool-btn.active { background: #e94560; }

        /* Magnifier */
        .magnifier {
            position: absolute;
            width: 150px;
            height: 150px;
            border: 3px solid #e94560;
            border-radius: 50%;
            pointer-events: none;
            display: none;
            overflow: hidden;
            box-shadow: 0 4px 20px rgba(0,0,0,0.5);
        }
        .magnifier canvas {
            position: absolute;
            top: 0;
            left: 0;
        }

        /* Class Selector */
        .class-selector {
            max-height: 250px;
            overflow-y: auto;
            border: 1px solid #0f3460;
            border-radius: 6px;
        }
        .class-item {
            padding: 6px 10px;
            cursor: pointer;
            border-bottom: 1px solid #0f3460;
            font-size: 0.75rem;
        }
        .class-item:hover { background: #0f3460; }
        .class-item.selected { background: #e94560; }

        /* Main Area */
        .main { flex: 1; display: flex; flex-direction: column; padding: 15px; overflow: hidden; }

        /* Canvas Container */
        .canvas-container {
            flex: 1;
            display: flex;
            justify-content: center;
            align-items: center;
            background: #0d1117;
            border-radius: 10px;
            overflow: hidden;
            position: relative;
        }
        #canvas { max-width: 100%; max-height: 100%; cursor: crosshair; }

        /* Hover delete indicator */
        .delete-hint {
            position: absolute;
            background: rgba(239, 68, 68, 0.9);
            color: white;
            padding: 4px 8px;
            border-radius: 4px;
            font-size: 0.75rem;
            pointer-events: none;
            display: none;
        }

        /* Controls */
        .controls { display: flex; align-items: center; gap: 12px; padding: 12px 0; flex-wrap: wrap; }
        .frame-nav { display: flex; align-items: center; gap: 8px; }
        .frame-nav button {
            padding: 6px 12px;
            background: #0f3460;
            border: none;
            border-radius: 5px;
            color: #eee;
            cursor: pointer;
            font-size: 0.85rem;
        }
        .frame-nav button:hover { background: #1a4a7a; }
        .frame-nav button.playing { background: #10b981; }
        .frame-slider { flex: 1; min-width: 150px; }
        .frame-slider input { width: 100%; }
        .frame-info { color: #94a3b8; font-size: 0.85rem; min-width: 120px; }

        /* Action Buttons */
        .actions { display: flex; gap: 8px; flex-wrap: wrap; }
        .action-btn {
            padding: 8px 14px;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            font-size: 0.8rem;
            font-weight: 500;
        }
        .action-btn.primary { background: #10b981; color: white; }
        .action-btn.secondary { background: #0f3460; color: #eee; }
        .action-btn.danger { background: #ef4444; color: white; }
        .action-btn:hover { opacity: 0.9; }
        .action-btn:disabled { opacity: 0.5; cursor: not-allowed; }

        /* Status */
        .status {
            padding: 8px 12px;
            background: #0f3460;
            border-radius: 5px;
            font-size: 0.8rem;
            color: #94a3b8;
            flex: 1;
        }
        .status.saving { color: #fbbf24; }
        .status.saved { color: #10b981; }

        /* Annotations Panel */
        .annotations-panel { margin-top: 10px; padding: 10px; background: #0f3460; border-radius: 6px; }
        .annotation-item {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 6px 8px;
            background: #16213e;
            border-radius: 4px;
            margin-bottom: 4px;
            font-size: 0.8rem;
            cursor: pointer;
        }
        .annotation-item:hover { background: #1a4a7a; }
        .annotation-item .delete-btn {
            background: #ef4444;
            border: none;
            color: white;
            padding: 3px 6px;
            border-radius: 3px;
            cursor: pointer;
            font-size: 0.7rem;
        }

        /* Loading Overlay */
        .loading {
            position: fixed;
            top: 0; left: 0; right: 0; bottom: 0;
            background: rgba(0,0,0,0.8);
            display: none;
            justify-content: center;
            align-items: center;
            z-index: 1000;
        }
        .loading.show { display: flex; }
        .loading-text { color: white; font-size: 1.1rem; }

        .search-input {
            width: 100%;
            padding: 8px;
            background: #0f3460;
            border: 1px solid #1a4a7a;
            border-radius: 5px;
            color: #eee;
            margin-bottom: 8px;
            font-size: 0.85rem;
        }

        /* Keyframe indicator */
        .keyframe-indicator {
            position: absolute;
            top: 10px;
            left: 10px;
            background: #e94560;
            color: white;
            padding: 4px 10px;
            border-radius: 4px;
            font-size: 0.75rem;
            font-weight: bold;
        }

        /* Keyboard shortcuts help */
        .shortcuts {
            font-size: 0.7rem;
            color: #64748b;
            margin-top: 15px;
            line-height: 1.6;
        }
        .shortcuts kbd {
            background: #0f3460;
            padding: 2px 5px;
            border-radius: 3px;
            font-family: monospace;
        }

        /* GT Timeline */
        .gt-timeline {
            background: #0f3460;
            border-radius: 6px;
            padding: 10px 12px;
            margin-top: 8px;
        }
        .gt-timeline-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 8px;
        }
        .gt-timeline-header h4 {
            font-size: 0.8rem;
            color: #94a3b8;
            margin: 0;
        }
        .timeline-zoom-controls {
            display: flex;
            gap: 4px;
            align-items: center;
        }
        .timeline-zoom-controls button {
            background: #16213e;
            border: 1px solid #0f3460;
            color: #eee;
            padding: 6px 14px;
            border-radius: 4px;
            cursor: pointer;
            font-size: 1.1rem;
            font-weight: bold;
            min-width: 36px;
        }
        .timeline-zoom-controls button:hover { background: #1a4a7a; color: #fff; }
        .timeline-zoom-controls span { font-size: 0.85rem; color: #94a3b8; font-weight: 600; min-width: 30px; text-align: center; }
        .timeline-container {
            overflow-x: auto;
            overflow-y: hidden;
        }
        .timeline-rows {
            min-width: 100%;
        }
        .timeline-row {
            display: flex;
            align-items: center;
            margin-bottom: 4px;
        }
        .timeline-row-label {
            width: 50px;
            font-size: 0.65rem;
            color: #64748b;
            text-transform: uppercase;
            flex-shrink: 0;
        }
        .gt-timeline-bar {
            position: relative;
            height: 16px;
            background: #16213e;
            border-radius: 3px;
            cursor: pointer;
            flex: 1;
        }
        .gt-timeline-bar.field { border-left: 3px solid #22c55e; }
        .gt-timeline-bar.player { border-left: 3px solid #3b82f6; }
        .gt-timeline-bar.ball { border-left: 3px solid #f97316; }
        .gt-marker {
            position: absolute;
            top: 2px;
            width: 6px;
            height: 12px;
            background: #22c55e;
            border-radius: 2px;
            cursor: pointer;
            transition: transform 0.1s;
        }
        .gt-marker:hover {
            transform: scaleX(1.8);
            z-index: 10;
        }
        .gt-marker.current {
            outline: 2px solid #fff;
            outline-offset: 1px;
        }
        /* Mode-specific marker colors */
        .gt-marker.field { background: #22c55e; }
        .gt-marker.player { background: #3b82f6; }
        .gt-marker.ball { background: #f97316; }
        .gt-marker-tooltip {
            position: absolute;
            bottom: 100%;
            left: 50%;
            transform: translateX(-50%);
            background: rgba(0,0,0,0.9);
            color: white;
            padding: 4px 8px;
            border-radius: 4px;
            font-size: 0.7rem;
            white-space: nowrap;
            pointer-events: none;
            opacity: 0;
            transition: opacity 0.15s;
            margin-bottom: 4px;
        }
        .gt-marker:hover .gt-marker-tooltip {
            opacity: 1;
        }
        .gt-timeline-info {
            display: flex;
            justify-content: space-between;
            margin-top: 6px;
            font-size: 0.7rem;
            color: #64748b;
        }
        .timeline-playhead {
            position: absolute;
            top: 0;
            width: 2px;
            height: 100%;
            background: #e94560;
            pointer-events: none;
        }

        /* Confirmation Modal */
        .modal-overlay {
            position: fixed;
            top: 0; left: 0; right: 0; bottom: 0;
            background: rgba(0,0,0,0.7);
            display: none;
            justify-content: center;
            align-items: center;
            z-index: 1001;
        }
        .modal-overlay.show { display: flex; }
        .modal-box {
            background: #16213e;
            border-radius: 10px;
            padding: 24px;
            max-width: 400px;
            text-align: center;
        }
        .modal-box h3 {
            color: #ef4444;
            margin-bottom: 12px;
        }
        .modal-box p {
            color: #94a3b8;
            margin-bottom: 20px;
            font-size: 0.9rem;
        }
        .modal-buttons {
            display: flex;
            gap: 12px;
            justify-content: center;
        }
    </style>
</head>
<body>
    <div class="loading" id="loading">
        <div class="loading-text">Loading...</div>
    </div>

    <!-- Confirmation Modal -->
    <div class="modal-overlay" id="confirmModal">
        <div class="modal-box">
            <h3>Clear All Annotations?</h3>
            <p id="confirmMessage">This will permanently delete all annotations for this video. This cannot be undone.</p>
            <div class="modal-buttons">
                <button class="action-btn secondary" onclick="closeConfirmModal()">Cancel</button>
                <button class="action-btn danger" id="confirmDeleteBtn">Yes, Delete All</button>
            </div>
        </div>
    </div>

    <div class="container">
        <div class="sidebar">
            <h2>Pitch Labeler</h2>

            <h3 style="display: flex; justify-content: space-between; align-items: center;">
                Videos
                <button onclick="loadVideos()" style="background: #0f3460; border: none; color: #eee; padding: 2px 6px; border-radius: 3px; cursor: pointer; font-size: 0.7rem;">‚Üª Refresh</button>
            </h3>
            <input type="text" class="search-input" id="videoSearch" placeholder="Search videos...">
            <div class="video-list" id="videoList">
                <div class="video-item">Loading...</div>
            </div>

            <h3>Mode</h3>
            <div class="mode-selector">
                <button class="mode-btn active field" data-mode="field">Field</button>
                <button class="mode-btn player" data-mode="player">Player</button>
                <button class="mode-btn ball" data-mode="ball">Ball</button>
            </div>

            <!-- Player number input (shown in player mode) -->
            <div class="player-input" id="playerInput">
                <label>Player Number</label>
                <input type="text" id="playerNumber" placeholder="e.g. 10, 7, GK" maxlength="3">
            </div>

            <h3>Tools</h3>
            <div class="tools" id="toolsContainer">
                <button class="tool-btn active" data-tool="select">Select</button>
                <button class="tool-btn" data-tool="ellipse">Ellipse</button>
                <button class="tool-btn" data-tool="point">Point</button>
                <button class="tool-btn" data-tool="magnifier" title="Hold to magnify">üîç Mag</button>
            </div>

            <h3>3D Field View</h3>
            <div class="field-3d-controls" style="margin-bottom: 15px;">
                <div style="margin-bottom: 8px;">
                    <label style="font-size: 0.8rem; color: #94a3b8;">Pitch (X): <span id="rotXValue">70.0</span>¬∞</label>
                    <input type="range" id="rotationX" min="-5400" max="5400" value="700" step="1" style="width: 100%;">
                </div>
                <div style="margin-bottom: 8px;">
                    <label style="font-size: 0.8rem; color: #94a3b8;">Yaw (Y): <span id="rotYValue">0.0</span>¬∞</label>
                    <input type="range" id="rotationY" min="-2700" max="2700" value="0" step="1" style="width: 100%;">
                </div>
                <div style="margin-bottom: 8px;">
                    <label style="font-size: 0.8rem; color: #94a3b8;">Roll (Z): <span id="rotZValue">0.0</span>¬∞</label>
                    <input type="range" id="rotationZ" min="-1350" max="1350" value="0" step="1" style="width: 100%;">
                </div>
                <div style="margin-bottom: 8px;">
                    <label style="font-size: 0.8rem; color: #94a3b8;">Distance: <span id="distValue">80.0</span></label>
                    <input type="range" id="cameraDistance" min="50" max="4500" value="800" step="10" style="width: 100%;">
                </div>
                <div style="margin-bottom: 8px;">
                    <label style="font-size: 0.8rem; color: #94a3b8;">Scale: <span id="scaleValue">1.5</span></label>
                    <input type="range" id="fieldScale" min="1" max="150" value="15" step="1" style="width: 100%;">
                </div>
                <div style="margin-bottom: 8px;">
                    <label style="font-size: 0.8rem; color: #94a3b8;">Pos X: <span id="posXValue">0.0</span></label>
                    <input type="range" id="positionX" min="-750" max="750" value="0" step="1" style="width: 100%;">
                </div>
                <div style="margin-bottom: 8px;">
                    <label style="font-size: 0.8rem; color: #94a3b8;">Pos Y: <span id="posYValue">0.0</span></label>
                    <input type="range" id="positionY" min="-750" max="750" value="0" step="1" style="width: 100%;">
                </div>
                <div style="margin-bottom: 8px;">
                    <label style="font-size: 0.8rem; color: #94a3b8;">Pos Z: <span id="posZValue">0.0</span></label>
                    <input type="range" id="positionZ" min="-750" max="750" value="0" step="1" style="width: 100%;">
                </div>
                <div style="margin-bottom: 8px;">
                    <label style="font-size: 0.8rem; color: #94a3b8;">Field Length: <span id="fieldLengthValue">105.0</span>m (110-120 yds)</label>
                    <input type="range" id="fieldLength" min="900" max="1200" value="1050" style="width: 100%;">
                </div>
                <div style="margin-bottom: 8px;">
                    <label style="font-size: 0.8rem; color: #94a3b8;">Field Width: <span id="fieldWidthValue">68.0</span>m (70-80 yds)</label>
                    <input type="range" id="fieldWidth" min="550" max="850" value="685" style="width: 100%;">
                </div>
                <button id="load3DTemplate" class="tool-btn" style="width: 100%; margin-top: 5px;">Load 3D Template</button>
                <button id="reset3DView" class="tool-btn" style="width: 100%; margin-top: 5px;">Reset View</button>
                <button id="calibrateFieldBtn" class="tool-btn" style="width: 100%; margin-top: 10px; background: #065f46;">Calibrate Field (Click Points)</button>
            </div>

            <!-- Calibration Mode Panel -->
            <div id="calibrationPanel" style="display: none; margin-bottom: 15px; padding: 10px; background: #134e4a; border-radius: 6px; border: 2px solid #10b981;">
                <h4 style="margin: 0 0 8px 0; color: #10b981;">Field Calibration Mode</h4>
                <p style="font-size: 0.75rem; color: #a7f3d0; margin: 0 0 8px 0;">
                    Click on visible field points, then select what each point is.
                </p>
                <div id="calibrationPoints" style="font-size: 0.8rem; color: #d1fae5; margin-bottom: 8px;">
                    Points: 0 / 4 minimum
                </div>
                <select id="fieldPointSelector" style="width: 100%; padding: 6px; margin-bottom: 8px; background: #1e3a5f; color: white; border: 1px solid #10b981; border-radius: 4px;">
                    <option value="">-- Select point type after clicking --</option>
                    <optgroup label="Field Corners">
                        <option value="corner_tl">Top-Left Corner</option>
                        <option value="corner_tr">Top-Right Corner</option>
                        <option value="corner_bl">Bottom-Left Corner</option>
                        <option value="corner_br">Bottom-Right Corner</option>
                    </optgroup>
                    <optgroup label="Center Line">
                        <option value="center_top">Center Line - Top</option>
                        <option value="center_mid">Center Spot</option>
                        <option value="center_bottom">Center Line - Bottom</option>
                    </optgroup>
                    <optgroup label="Left Penalty Area">
                        <option value="penalty_left_top">Left Penalty - Top Corner</option>
                        <option value="penalty_left_bottom">Left Penalty - Bottom Corner</option>
                        <option value="penalty_left_goal_top">Left Penalty - Goal Line Top</option>
                        <option value="penalty_left_goal_bottom">Left Penalty - Goal Line Bottom</option>
                    </optgroup>
                    <optgroup label="Right Penalty Area">
                        <option value="penalty_right_top">Right Penalty - Top Corner</option>
                        <option value="penalty_right_bottom">Right Penalty - Bottom Corner</option>
                        <option value="penalty_right_goal_top">Right Penalty - Goal Line Top</option>
                        <option value="penalty_right_goal_bottom">Right Penalty - Goal Line Bottom</option>
                    </optgroup>
                    <optgroup label="Left Goal Area (6-yard box)">
                        <option value="goal_area_left_top">Left Goal Area - Top Corner</option>
                        <option value="goal_area_left_bottom">Left Goal Area - Bottom Corner</option>
                        <option value="goal_area_left_goal_top">Left Goal Area - Goal Line Top</option>
                        <option value="goal_area_left_goal_bottom">Left Goal Area - Goal Line Bottom</option>
                    </optgroup>
                    <optgroup label="Right Goal Area (6-yard box)">
                        <option value="goal_area_right_top">Right Goal Area - Top Corner</option>
                        <option value="goal_area_right_bottom">Right Goal Area - Bottom Corner</option>
                        <option value="goal_area_right_goal_top">Right Goal Area - Goal Line Top</option>
                        <option value="goal_area_right_goal_bottom">Right Goal Area - Goal Line Bottom</option>
                    </optgroup>
                    <optgroup label="Center Circle">
                        <option value="center_circle_top">Center Circle - Top</option>
                        <option value="center_circle_bottom">Center Circle - Bottom</option>
                        <option value="center_circle_left">Center Circle - Left</option>
                        <option value="center_circle_right">Center Circle - Right</option>
                    </optgroup>
                </select>
                <div style="display: flex; gap: 5px;">
                    <button id="undoCalibrationPoint" class="tool-btn" style="flex: 1; background: #7c3aed;">Undo</button>
                    <button id="clearCalibration" class="tool-btn" style="flex: 1; background: #dc2626;">Clear</button>
                </div>
                <button id="generateFromCalibration" class="tool-btn" style="width: 100%; margin-top: 8px; background: #059669;" disabled>Generate Template (need 4+ points)</button>
                <button id="exitCalibration" class="tool-btn" style="width: 100%; margin-top: 5px; background: #475569;">Exit Calibration</button>
            </div>

            <h3>Tracking Settings</h3>
            <div style="margin-bottom: 15px; padding: 8px; background: #1e3a5f; border-radius: 6px;">
                <label style="display: flex; align-items: center; cursor: pointer; font-size: 0.85rem;">
                    <input type="checkbox" id="sotacvToggle" checked style="margin-right: 8px; width: 16px; height: 16px;">
                    <span style="color: #94a3b8;">SOTA CV Propagation</span>
                </label>
                <div style="font-size: 0.7rem; color: #64748b; margin-top: 4px; margin-left: 24px;">
                    KLT tracking + Kalman filter<br>
                    (faster, more accurate)
                </div>
            </div>

            <h3 id="classLabel">Pitch Element</h3>
            <div class="class-selector" id="classSelector">
                {% for cls in pitch_classes %}
                <div class="class-item {% if loop.first %}selected{% endif %}" data-class="{{ cls }}">{{ cls }}</div>
                {% endfor %}
            </div>

            <h3>Frame Annotations</h3>
            <div class="annotations-panel" id="annotationsPanel">
                <div style="color: #64748b; font-size: 0.8rem;">No annotations</div>
            </div>

            <div class="shortcuts">
                <strong>Shortcuts:</strong><br>
                <kbd>Cmd+Z</kbd> Undo | <kbd>Cmd+Shift+Z</kbd> Redo<br>
                <kbd>Enter</kbd> Finish drawing<br>
                <kbd>Delete</kbd> Delete hovered item<br>
                <kbd>Space</kbd> Play/Pause<br>
                <kbd>‚Üê</kbd><kbd>‚Üí</kbd> Prev/Next frame
            </div>
        </div>

        <div class="main">
            <div class="canvas-container">
                <canvas id="canvas" width="960" height="540"></canvas>
                <div class="keyframe-indicator" id="keyframeIndicator" style="display:none;">KEYFRAME</div>
                <div class="delete-hint" id="deleteHint">Click to delete</div>
                <div class="magnifier" id="magnifier">
                    <canvas id="magCanvas" width="150" height="150"></canvas>
                </div>
            </div>

            <div class="controls">
                <div class="frame-nav">
                    <button id="playBtn" title="Play/Pause (Space)">‚ñ∂ Play</button>
                    <button id="prevKeyframe" title="Previous keyframe">&lt;&lt;</button>
                    <button id="prevFrame" title="Previous frame (‚Üê)">&lt;</button>
                    <button id="nextFrame" title="Next frame (‚Üí)">&gt;</button>
                    <button id="nextKeyframe" title="Next keyframe">&gt;&gt;</button>
                </div>
                <div class="frame-slider">
                    <input type="range" id="frameSlider" min="0" max="100" value="0">
                </div>
                <div class="frame-info">
                    <span id="frameNum">Frame: 0 / 0</span>
                </div>
            </div>

            <div class="controls">
                <div class="actions">
                    <button class="action-btn secondary" id="undoBtn" disabled title="Cmd+Z">Undo</button>
                    <button class="action-btn secondary" id="redoBtn" disabled title="Cmd+Shift+Z">Redo</button>
                    <button class="action-btn primary" id="saveBtn" title="Cmd+S">Save</button>
                    <button class="action-btn" id="learnBtn" title="Train model from current GT" style="background: linear-gradient(135deg, #8b5cf6, #6366f1);">Learn</button>
                    <button class="action-btn" id="bulkLearnBtn" title="Train from ALL saved GT annotations" style="background: linear-gradient(135deg, #ec4899, #8b5cf6);">Bulk Learn</button>
                    <button class="action-btn" id="debugBtn" title="Show detected lines/features" style="background: linear-gradient(135deg, #f59e0b, #d97706);">Debug</button>
                    <button class="action-btn primary" id="propagateRangeBtn" title="Propagate to next 50 frames">Propagate 50‚Üí</button>
                    <button class="action-btn secondary" id="exportBtn">Export JSON</button>
                    <button class="action-btn danger" id="clearBtn">Clear Frame</button>
                    <button class="action-btn danger" id="clearAllBtn">Clear All Video</button>
                </div>
                <div class="status" id="status">Select a video to begin</div>
            </div>

            <!-- GT Timeline -->
            <div class="gt-timeline" id="gtTimeline" style="display: none;">
                <div class="gt-timeline-header">
                    <h4>GT Keyframes <span id="gtCount" style="font-weight:normal;color:#64748b;"></span></h4>
                    <div class="timeline-zoom-controls">
                        <button onclick="zoomTimeline(-1)">‚àí</button>
                        <span id="timelineZoomLevel">1x</span>
                        <button onclick="zoomTimeline(1)">+</button>
                    </div>
                </div>
                <div class="timeline-container" id="timelineContainer">
                    <div class="timeline-rows" id="timelineRows">
                        <div class="timeline-row">
                            <span class="timeline-row-label" style="color:#22c55e;">Field</span>
                            <div class="gt-timeline-bar field" id="fieldTimelineBar">
                                <div class="timeline-playhead playhead-field"></div>
                            </div>
                        </div>
                        <div class="timeline-row">
                            <span class="timeline-row-label" style="color:#3b82f6;">Player</span>
                            <div class="gt-timeline-bar player" id="playerTimelineBar">
                                <div class="timeline-playhead playhead-player"></div>
                            </div>
                        </div>
                        <div class="timeline-row">
                            <span class="timeline-row-label" style="color:#f97316;">Ball</span>
                            <div class="gt-timeline-bar ball" id="ballTimelineBar">
                                <div class="timeline-playhead playhead-ball"></div>
                            </div>
                        </div>
                    </div>
                </div>
                <div class="gt-timeline-info">
                    <span>0:00</span>
                    <span id="videoDuration">0:00</span>
                </div>
            </div>
        </div>
    </div>

    <script>
        // State
        let currentVideo = null;
        let currentFrame = 0;
        let totalFrames = 0;
        let fps = 25;
        let currentMode = 'field';  // field, player, ball
        let currentTool = 'select';
        let currentClass = '{{ pitch_classes[0] }}';
        let playerNumber = '';
        let annotations = [];
        let allAnnotations = {};
        let keyframes = [];
        let tempPoints = [];
        let hoveredAnnotation = null;
        let hoveredPoint = null;
        let isPlaying = false;
        let playInterval = null;
        let lastSavedFrame = -1;
        let magnifierActive = false;

        // Dragging state
        let isDragging = false;
        let dragAnnotation = null;
        let dragPoint = null;
        let dragStartPos = null;
        let dragOriginalValue = null;  // Original point position before drag
        let dragWasPropagated = false;  // Was this annotation propagated (not GT)?
        let dragLastPos = null;         // Last position for smooth delta-based panning

        // Drift correction learning
        // Stores recent corrections per mode to learn drift patterns
        // More conservative approach: only learn from consistent, small corrections
        let driftCorrections = {
            field: { dx: 0, dy: 0, count: 0, variance: 0 },
            player: { dx: 0, dy: 0, count: 0, variance: 0 },
            ball: { dx: 0, dy: 0, count: 0, variance: 0 }
        };

        // Drift correction config - VERY conservative to avoid harming tracking
        const DRIFT_CONFIG = {
            decay: 0.95,           // High decay = slow learning, corrections fade slowly
            minMagnitude: 2,       // Ignore corrections smaller than 2px (precision tweaks)
            maxMagnitude: 25,      // Reject corrections larger than 25px (scene cuts/jumps)
            minSamples: 3,         // Need at least 3 samples before applying
            maxVariance: 15,       // If variance is high, corrections are inconsistent
            applyScale: 0.5       // Only apply 50% of learned correction (conservative)
        };

        // ========== ROBUST PROPAGATION SYSTEM ==========
        // Pre-computes all frames using GT keyframes as anchors
        // Interpolates smoothly between GT keyframes using homography
        let propagationCache = {};      // { frameNum: { annotations, corners, camera3D } }
        let gtKeyframes = [];           // Sorted list of GT keyframe numbers
        let propagationInProgress = false;
        let lastPropagationVideo = null;

        // ========== STATE-OF-THE-ART COMPUTER VISION MODULE ==========
        // Line detection, RANSAC homography, KLT tracking, Kalman filtering
        const SOTACV = {
            // Configuration
            config: {
                // Edge detection
                cannyLow: 50,
                cannyHigh: 150,
                sobelKernelSize: 3,

                // Hough lines
                houghRho: 1,              // Distance resolution in pixels
                houghTheta: Math.PI/180,  // Angle resolution in radians
                houghThreshold: 40,       // Min votes for line detection (lowered for better detection)
                houghMinLength: 50,       // Min line length
                houghMaxGap: 20,          // Max gap in line

                // Line filtering
                whiteThreshold: 180,      // Brightness threshold for white lines
                greenRange: { hMin: 35, hMax: 85, sMin: 30, vMin: 40 }, // Green HSV range

                // RANSAC
                ransacIterations: 500,
                ransacThreshold: 3,       // Reprojection error threshold in pixels
                ransacMinInliers: 4,      // Min inliers for valid homography

                // KLT tracking
                kltWindowSize: 21,
                kltMaxLevel: 3,
                kltMaxIterations: 30,
                kltEpsilon: 0.01,

                // Temporal filtering
                kalmanProcessNoise: 5.0,      // High = more responsive to changes
                kalmanMeasurementNoise: 0.2,  // Low = trust measurements more

                // Re-detection interval
                redetectInterval: 30,     // Re-detect lines every N frames
            },

            // State
            prevGray: null,           // Previous frame grayscale
            trackedFeatures: [],       // KLT tracked features
            kalmanState: null,         // Kalman filter state
            framesSinceDetection: 0,   // Counter for re-detection
            lastHomography: null,      // Last computed homography

            // ========== IMAGE PROCESSING ==========

            // Convert ImageData to grayscale array
            toGrayscale(imageData) {
                const w = imageData.width;
                const h = imageData.height;
                const data = imageData.data;
                const gray = new Float32Array(w * h);

                for (let i = 0; i < w * h; i++) {
                    const r = data[i * 4];
                    const g = data[i * 4 + 1];
                    const b = data[i * 4 + 2];
                    gray[i] = 0.299 * r + 0.587 * g + 0.114 * b;
                }
                return { data: gray, width: w, height: h };
            },

            // Gaussian blur (5x5 kernel)
            gaussianBlur(gray) {
                const w = gray.width;
                const h = gray.height;
                const src = gray.data;
                const dst = new Float32Array(w * h);

                // 5x5 Gaussian kernel (sigma=1.4)
                const kernel = [
                    [2, 4, 5, 4, 2],
                    [4, 9, 12, 9, 4],
                    [5, 12, 15, 12, 5],
                    [4, 9, 12, 9, 4],
                    [2, 4, 5, 4, 2]
                ];
                const kSum = 159;

                for (let y = 2; y < h - 2; y++) {
                    for (let x = 2; x < w - 2; x++) {
                        let sum = 0;
                        for (let ky = -2; ky <= 2; ky++) {
                            for (let kx = -2; kx <= 2; kx++) {
                                sum += src[(y + ky) * w + (x + kx)] * kernel[ky + 2][kx + 2];
                            }
                        }
                        dst[y * w + x] = sum / kSum;
                    }
                }
                return { data: dst, width: w, height: h };
            },

            // Sobel edge detection
            sobelEdges(gray) {
                const w = gray.width;
                const h = gray.height;
                const src = gray.data;
                const magnitude = new Float32Array(w * h);
                const direction = new Float32Array(w * h);

                // Sobel kernels
                const gx = [[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]];
                const gy = [[-1, -2, -1], [0, 0, 0], [1, 2, 1]];

                for (let y = 1; y < h - 1; y++) {
                    for (let x = 1; x < w - 1; x++) {
                        let sumX = 0, sumY = 0;
                        for (let ky = -1; ky <= 1; ky++) {
                            for (let kx = -1; kx <= 1; kx++) {
                                const val = src[(y + ky) * w + (x + kx)];
                                sumX += val * gx[ky + 1][kx + 1];
                                sumY += val * gy[ky + 1][kx + 1];
                            }
                        }
                        magnitude[y * w + x] = Math.sqrt(sumX * sumX + sumY * sumY);
                        direction[y * w + x] = Math.atan2(sumY, sumX);
                    }
                }
                return { magnitude, direction, width: w, height: h };
            },

            // Non-maximum suppression for edge thinning
            nonMaxSuppression(edges) {
                const w = edges.width;
                const h = edges.height;
                const mag = edges.magnitude;
                const dir = edges.direction;
                const result = new Float32Array(w * h);

                for (let y = 1; y < h - 1; y++) {
                    for (let x = 1; x < w - 1; x++) {
                        const idx = y * w + x;
                        const angle = dir[idx] * 180 / Math.PI;
                        const m = mag[idx];

                        let m1 = 0, m2 = 0;

                        // Round angle to 0, 45, 90, 135 degrees
                        if ((angle >= -22.5 && angle < 22.5) || (angle >= 157.5 || angle < -157.5)) {
                            m1 = mag[y * w + (x - 1)];
                            m2 = mag[y * w + (x + 1)];
                        } else if ((angle >= 22.5 && angle < 67.5) || (angle >= -157.5 && angle < -112.5)) {
                            m1 = mag[(y - 1) * w + (x + 1)];
                            m2 = mag[(y + 1) * w + (x - 1)];
                        } else if ((angle >= 67.5 && angle < 112.5) || (angle >= -112.5 && angle < -67.5)) {
                            m1 = mag[(y - 1) * w + x];
                            m2 = mag[(y + 1) * w + x];
                        } else {
                            m1 = mag[(y - 1) * w + (x - 1)];
                            m2 = mag[(y + 1) * w + (x + 1)];
                        }

                        result[idx] = (m >= m1 && m >= m2) ? m : 0;
                    }
                }
                return { data: result, width: w, height: h };
            },

            // Double threshold and edge tracking (Canny hysteresis)
            hysteresisThreshold(edges, low, high) {
                const w = edges.width;
                const h = edges.height;
                const src = edges.data;
                const result = new Uint8Array(w * h);

                // First pass: mark strong and weak edges
                const STRONG = 255;
                const WEAK = 128;

                for (let i = 0; i < w * h; i++) {
                    if (src[i] >= high) result[i] = STRONG;
                    else if (src[i] >= low) result[i] = WEAK;
                }

                // Second pass: connect weak edges to strong edges
                let changed = true;
                while (changed) {
                    changed = false;
                    for (let y = 1; y < h - 1; y++) {
                        for (let x = 1; x < w - 1; x++) {
                            const idx = y * w + x;
                            if (result[idx] === WEAK) {
                                // Check 8-neighbors for strong edge
                                for (let dy = -1; dy <= 1; dy++) {
                                    for (let dx = -1; dx <= 1; dx++) {
                                        if (result[(y + dy) * w + (x + dx)] === STRONG) {
                                            result[idx] = STRONG;
                                            changed = true;
                                            break;
                                        }
                                    }
                                    if (result[idx] === STRONG) break;
                                }
                            }
                        }
                    }
                }

                // Remove remaining weak edges
                for (let i = 0; i < w * h; i++) {
                    if (result[i] !== STRONG) result[i] = 0;
                }

                return { data: result, width: w, height: h };
            },

            // Full Canny edge detection pipeline
            cannyEdges(imageData) {
                const gray = this.toGrayscale(imageData);
                const blurred = this.gaussianBlur(gray);
                const edges = this.sobelEdges(blurred);
                const thinned = this.nonMaxSuppression(edges);
                const final = this.hysteresisThreshold(thinned, this.config.cannyLow, this.config.cannyHigh);
                return final;
            },

            // White-line specific edge detection (better for field lines)
            whiteLineEdges(imageData) {
                const w = imageData.width;
                const h = imageData.height;
                const data = imageData.data;

                // First pass: identify white pixels (field lines)
                const whiteMask = new Uint8Array(w * h);
                for (let i = 0; i < w * h; i++) {
                    const r = data[i * 4];
                    const g = data[i * 4 + 1];
                    const b = data[i * 4 + 2];
                    const brightness = (r + g + b) / 3;
                    const saturation = Math.max(r, g, b) - Math.min(r, g, b);

                    // White: high brightness, low saturation
                    if (brightness > 160 && saturation < 60) {
                        whiteMask[i] = 255;
                    }
                }

                // Dilate white mask slightly to connect nearby white pixels
                const dilated = new Uint8Array(w * h);
                for (let y = 1; y < h - 1; y++) {
                    for (let x = 1; x < w - 1; x++) {
                        const idx = y * w + x;
                        if (whiteMask[idx] > 0 ||
                            whiteMask[idx - 1] > 0 || whiteMask[idx + 1] > 0 ||
                            whiteMask[idx - w] > 0 || whiteMask[idx + w] > 0) {
                            dilated[idx] = 255;
                        }
                    }
                }

                // Apply Sobel only on white regions
                const gray = this.toGrayscale(imageData);
                const edges = this.sobelEdges(gray);

                // Combine: keep edges only where white mask is set
                const result = new Uint8Array(w * h);
                for (let i = 0; i < w * h; i++) {
                    if (dilated[i] > 0 && edges.magnitude[i] > this.config.cannyLow) {
                        result[i] = 255;
                    }
                }

                return { data: result, width: w, height: h };
            },

            // ========== HOUGH LINE TRANSFORM ==========

            // Detect lines using Hough transform
            houghLines(edges) {
                const w = edges.width;
                const h = edges.height;
                const data = edges.data;

                const rhoMax = Math.ceil(Math.sqrt(w * w + h * h));
                const thetaSteps = Math.ceil(Math.PI / this.config.houghTheta);

                // Accumulator: [rho + rhoMax][theta]
                const accumulator = new Int32Array((2 * rhoMax + 1) * thetaSteps);

                // Precompute sin/cos
                const sinTable = new Float32Array(thetaSteps);
                const cosTable = new Float32Array(thetaSteps);
                for (let t = 0; t < thetaSteps; t++) {
                    const theta = t * this.config.houghTheta;
                    sinTable[t] = Math.sin(theta);
                    cosTable[t] = Math.cos(theta);
                }

                // Vote for each edge pixel
                for (let y = 0; y < h; y++) {
                    for (let x = 0; x < w; x++) {
                        if (data[y * w + x] > 0) {
                            for (let t = 0; t < thetaSteps; t++) {
                                const rho = Math.round(x * cosTable[t] + y * sinTable[t]);
                                accumulator[(rho + rhoMax) * thetaSteps + t]++;
                            }
                        }
                    }
                }

                // Find peaks above threshold
                const lines = [];
                for (let r = 0; r < 2 * rhoMax + 1; r++) {
                    for (let t = 0; t < thetaSteps; t++) {
                        if (accumulator[r * thetaSteps + t] >= this.config.houghThreshold) {
                            const rho = r - rhoMax;
                            const theta = t * this.config.houghTheta;
                            lines.push({ rho, theta, votes: accumulator[r * thetaSteps + t] });
                        }
                    }
                }

                // Sort by votes and remove duplicates (similar rho/theta)
                lines.sort((a, b) => b.votes - a.votes);
                const filtered = [];
                for (const line of lines) {
                    let isDuplicate = false;
                    for (const existing of filtered) {
                        if (Math.abs(line.rho - existing.rho) < 20 &&
                            Math.abs(line.theta - existing.theta) < 0.1) {
                            isDuplicate = true;
                            break;
                        }
                    }
                    if (!isDuplicate) filtered.push(line);
                }

                return filtered.slice(0, 30); // Top 30 lines
            },

            // Convert Hough line (rho, theta) to two endpoints
            lineToPoints(line, w, h) {
                const { rho, theta } = line;
                const cos_t = Math.cos(theta);
                const sin_t = Math.sin(theta);

                const points = [];

                // Check intersection with all 4 edges
                // Top edge (y = 0)
                if (Math.abs(sin_t) > 0.001) {
                    const x = rho / cos_t;
                    if (x >= 0 && x <= w) points.push({ x, y: 0 });
                }

                // Bottom edge (y = h)
                if (Math.abs(sin_t) > 0.001) {
                    const x = (rho - h * sin_t) / cos_t;
                    if (x >= 0 && x <= w) points.push({ x, y: h });
                }

                // Left edge (x = 0)
                if (Math.abs(cos_t) > 0.001) {
                    const y = rho / sin_t;
                    if (y >= 0 && y <= h) points.push({ x: 0, y });
                }

                // Right edge (x = w)
                if (Math.abs(cos_t) > 0.001) {
                    const y = (rho - w * cos_t) / sin_t;
                    if (y >= 0 && y <= h) points.push({ x: w, y });
                }

                // Return two unique points
                if (points.length >= 2) {
                    return [points[0], points[1]];
                }
                return null;
            },

            // ========== LINE INTERSECTION ==========

            // Find intersection of two lines (each defined by two points)
            lineIntersection(line1, line2) {
                const [p1, p2] = line1;
                const [p3, p4] = line2;

                const x1 = p1.x, y1 = p1.y;
                const x2 = p2.x, y2 = p2.y;
                const x3 = p3.x, y3 = p3.y;
                const x4 = p4.x, y4 = p4.y;

                const denom = (x1 - x2) * (y3 - y4) - (y1 - y2) * (x3 - x4);
                if (Math.abs(denom) < 0.001) return null; // Parallel lines

                const t = ((x1 - x3) * (y3 - y4) - (y1 - y3) * (x3 - x4)) / denom;

                return {
                    x: x1 + t * (x2 - x1),
                    y: y1 + t * (y2 - y1)
                };
            },

            // Find all line intersections within image bounds
            findIntersections(lines, w, h) {
                const intersections = [];
                const linePoints = lines.map(l => this.lineToPoints(l, w, h)).filter(p => p !== null);

                for (let i = 0; i < linePoints.length; i++) {
                    for (let j = i + 1; j < linePoints.length; j++) {
                        // Check if lines are roughly perpendicular (angle diff > 30 degrees)
                        const angle1 = Math.atan2(
                            linePoints[i][1].y - linePoints[i][0].y,
                            linePoints[i][1].x - linePoints[i][0].x
                        );
                        const angle2 = Math.atan2(
                            linePoints[j][1].y - linePoints[j][0].y,
                            linePoints[j][1].x - linePoints[j][0].x
                        );
                        const angleDiff = Math.abs(angle1 - angle2);
                        if (angleDiff < Math.PI / 6 && angleDiff > 5 * Math.PI / 6) continue;

                        const pt = this.lineIntersection(linePoints[i], linePoints[j]);
                        if (pt && pt.x >= -w * 0.5 && pt.x <= w * 1.5 &&
                            pt.y >= -h * 0.5 && pt.y <= h * 1.5) {
                            intersections.push({
                                point: pt,
                                lines: [i, j],
                                angles: [angle1, angle2]
                            });
                        }
                    }
                }
                return intersections;
            },

            // ========== CENTER LINE DETECTION (PRIMARY) ==========
            // The center line is ALWAYS visible in sideline camera footage
            // It's the key anchor point for field detection
            // NOTE: The center line may be faint in the middle - we detect it by
            // finding columns with white pixels at BOTH touchline positions

            detectCenterLine(imageData, whiteMask, greenBounds) {
                const w = imageData.width;
                const h = imageData.height;

                console.log('[detect] CENTER LINE DETECTION starting...');

                // First, find approximate touchline Y positions using white histogram
                const whitePerRow = new Array(h).fill(0);
                for (let y = 0; y < h; y++) {
                    for (let x = Math.floor(w * 0.15); x < Math.floor(w * 0.85); x++) {
                        if (whiteMask[y * w + x]) {
                            whitePerRow[y]++;
                        }
                    }
                }

                // Find top touchline (in top 35% of frame)
                let topTouchline = 100;
                let topMax = 0;
                for (let y = 50; y < Math.floor(h * 0.35); y++) {
                    if (whitePerRow[y] > topMax) {
                        topMax = whitePerRow[y];
                        topTouchline = y;
                    }
                }

                // Find bottom touchline (in bottom 35% of frame)
                let bottomTouchline = h - 100;
                let bottomMax = 0;
                for (let y = Math.floor(h * 0.65); y < h - 50; y++) {
                    if (whitePerRow[y] > bottomMax) {
                        bottomMax = whitePerRow[y];
                        bottomTouchline = y;
                    }
                }

                console.log(`[detect] Touchline estimates: top y=${topTouchline} (${topMax} white), bottom y=${bottomTouchline} (${bottomMax} white)`);

                // Now find columns that have white pixels at BOTH touchline positions
                // This finds the center line even if it's faint in the middle
                const centerLineCandidates = [];

                for (let x = Math.floor(w * 0.3); x < Math.floor(w * 0.7); x++) {
                    // Count white pixels near top touchline
                    let topHits = 0;
                    for (let y = topTouchline - 30; y < topTouchline + 40; y++) {
                        if (y >= 0 && y < h && whiteMask[y * w + x]) {
                            topHits++;
                        }
                    }

                    // Count white pixels near bottom touchline
                    let bottomHits = 0;
                    for (let y = bottomTouchline - 40; y < bottomTouchline + 30; y++) {
                        if (y >= 0 && y < h && whiteMask[y * w + x]) {
                            bottomHits++;
                        }
                    }

                    // Also count total white pixels in this column between touchlines
                    let totalHits = 0;
                    for (let y = topTouchline; y < bottomTouchline; y++) {
                        if (whiteMask[y * w + x]) {
                            totalHits++;
                        }
                    }

                    // A good center line candidate has hits at BOTH top and bottom
                    if (topHits >= 3 && bottomHits >= 3) {
                        // Score: prefer more hits, near frame center
                        const centerDist = Math.abs(x - w/2) / (w/2);
                        const centerBonus = 1 + (1 - centerDist) * 0.3;

                        centerLineCandidates.push({
                            x: x,
                            topHits: topHits,
                            bottomHits: bottomHits,
                            totalHits: totalHits,
                            score: (topHits + bottomHits + totalHits * 0.5) * centerBonus
                        });
                    }
                }

                console.log(`[detect] Found ${centerLineCandidates.length} center line candidates`);

                if (centerLineCandidates.length === 0) {
                    console.log('[detect] No center line candidates found');
                    return null;
                }

                // Group adjacent X values
                centerLineCandidates.sort((a, b) => a.x - b.x);
                const groups = [];
                let currentGroup = [centerLineCandidates[0]];

                for (let i = 1; i < centerLineCandidates.length; i++) {
                    if (centerLineCandidates[i].x - currentGroup[currentGroup.length - 1].x <= 10) {
                        currentGroup.push(centerLineCandidates[i]);
                    } else {
                        if (currentGroup.length >= 2) {
                            groups.push(currentGroup);
                        }
                        currentGroup = [centerLineCandidates[i]];
                    }
                }
                if (currentGroup.length >= 2) {
                    groups.push(currentGroup);
                }

                console.log(`[detect] Grouped into ${groups.length} line groups`);

                if (groups.length === 0) {
                    // Try using individual high-scoring candidates
                    centerLineCandidates.sort((a, b) => b.score - a.score);
                    if (centerLineCandidates[0].score > 10) {
                        const best = centerLineCandidates[0];
                        console.log(`[detect] Using single best candidate: x=${best.x}, score=${best.score.toFixed(1)}`);
                        return {
                            x: best.x,
                            topY: topTouchline,
                            bottomY: bottomTouchline,
                            length: bottomTouchline - topTouchline,
                            centerY: (topTouchline + bottomTouchline) / 2
                        };
                    }
                    return null;
                }

                // Score each group
                const scoredGroups = groups.map(group => {
                    const avgX = group.reduce((s, c) => s + c.x, 0) / group.length;
                    const totalScore = group.reduce((s, c) => s + c.score, 0);
                    return {
                        x: avgX,
                        score: totalScore,
                        width: group[group.length - 1].x - group[0].x,
                        count: group.length
                    };
                });

                scoredGroups.sort((a, b) => b.score - a.score);

                console.log('[detect] Top 3 center line groups:');
                scoredGroups.slice(0, 3).forEach((g, i) => {
                    console.log(`  ${i+1}. x=${g.x.toFixed(0)}, w=${g.width}, count=${g.count}, score=${g.score.toFixed(0)}`);
                });

                const bestGroup = scoredGroups[0];

                console.log(`[detect] CENTER LINE FOUND: x=${bestGroup.x.toFixed(0)}`);

                return {
                    x: bestGroup.x,
                    topY: topTouchline,
                    bottomY: bottomTouchline,
                    length: bottomTouchline - topTouchline,
                    centerY: (topTouchline + bottomTouchline) / 2
                };
            },

            // ========== CENTER CIRCLE DETECTION ==========
            // Detect center circle ellipse around the center line
            // Used to determine camera pitch angle

            detectCenterCircleAroundLine(imageData, whiteMask, centerLine) {
                const w = imageData.width;
                const h = imageData.height;

                // Search region: around the center line, middle third vertically
                const searchXMin = Math.floor(centerLine.x - 200);
                const searchXMax = Math.floor(centerLine.x + 200);
                const fieldMidY = centerLine.centerY;
                const searchYMin = Math.max(0, Math.floor(fieldMidY - 150));
                const searchYMax = Math.min(h, Math.floor(fieldMidY + 150));

                console.log(`[detect] Circle search: x=${searchXMin}-${searchXMax}, y=${searchYMin}-${searchYMax}, around centerLine.x=${centerLine.x.toFixed(0)}`);

                // Group white pixels by Y coordinate (5px bins)
                const byY = {};
                for (let y = searchYMin; y < searchYMax; y++) {
                    for (let x = Math.max(0, searchXMin); x < Math.min(w, searchXMax); x++) {
                        if (whiteMask[y * w + x]) {
                            const yBin = Math.floor(y / 5) * 5;
                            if (!byY[yBin]) byY[yBin] = [];
                            byY[yBin].push(x);
                        }
                    }
                }

                // Find rows with left and right arc segments (gap in middle for center line)
                const arcSegments = [];
                for (const [yBinStr, xList] of Object.entries(byY)) {
                    const yBin = parseInt(yBinStr);
                    if (xList.length < 5) continue;

                    const xSorted = [...xList].sort((a, b) => a - b);

                    // Find the center line position in this row
                    const centerLineX = centerLine.x;

                    // Split pixels into left and right of center line
                    const leftPixels = xSorted.filter(x => x < centerLineX - 10);
                    const rightPixels = xSorted.filter(x => x > centerLineX + 10);

                    if (leftPixels.length >= 2 && rightPixels.length >= 2) {
                        // Get the rightmost left pixel and leftmost right pixel (arc edges)
                        const leftEdge = leftPixels[leftPixels.length - 1];
                        const rightEdge = rightPixels[0];
                        const width = rightEdge - leftEdge;

                        if (width > 80 && width < 450) {  // Reasonable circle width
                            arcSegments.push({
                                y: yBin,
                                leftX: leftEdge,
                                rightX: rightEdge,
                                centerX: (leftEdge + rightEdge) / 2,
                                width: width
                            });
                        }
                    }
                }

                console.log(`[detect] Circle: found ${arcSegments.length} arc segments split by center line`);

                if (arcSegments.length < 5) {
                    console.log('[detect] Circle: not enough arc segments');
                    return null;
                }

                // Filter to segments with consistent center (near center line)
                const filtered = arcSegments.filter(s => Math.abs(s.centerX - centerLine.x) < 30);

                if (filtered.length < 5) {
                    console.log(`[detect] Circle: only ${filtered.length} segments centered on line`);
                    return null;
                }

                // Sort by Y to find vertical extent
                filtered.sort((a, b) => a.y - b.y);

                // Find row with maximum width (widest part of ellipse)
                const maxWidthSeg = filtered.reduce((max, s) => s.width > max.width ? s : max, filtered[0]);

                const ellipse = {
                    centerX: maxWidthSeg.centerX,
                    centerY: maxWidthSeg.y,
                    width: maxWidthSeg.width,
                    topY: filtered[0].y,
                    bottomY: filtered[filtered.length - 1].y,
                    height: filtered[filtered.length - 1].y - filtered[0].y
                };

                // Validate ellipse dimensions
                if (ellipse.height < 50 || ellipse.width < 100) {
                    console.log(`[detect] Circle: ellipse too small (${ellipse.width.toFixed(0)}x${ellipse.height})`);
                    return null;
                }

                // Calculate aspect ratio
                ellipse.aspectRatio = ellipse.width / ellipse.height;

                // sin(elevation) = height/width for a circle viewed from above
                if (ellipse.height < ellipse.width) {
                    const sinElevation = ellipse.height / ellipse.width;
                    ellipse.elevationAngle = Math.asin(sinElevation) * 180 / Math.PI;
                    ellipse.sinElevation = sinElevation;
                } else {
                    ellipse.elevationAngle = 90;
                    ellipse.sinElevation = 1;
                }

                console.log(`[detect] CIRCLE FOUND: center=(${ellipse.centerX.toFixed(0)}, ${ellipse.centerY}), ` +
                           `size=${ellipse.width.toFixed(0)}x${ellipse.height}, aspect=${ellipse.aspectRatio.toFixed(2)}, ` +
                           `elevation=${ellipse.elevationAngle.toFixed(1)}¬∞`);

                return ellipse;
            },

            // Legacy function for backward compatibility
            detectCenterCircle(imageData, whiteMask, searchYMin, searchYMax) {
                const w = imageData.width;
                const h = imageData.height;

                const searchXMin = Math.floor(w / 5);
                const searchXMax = Math.floor(4 * w / 5);

                const byY = {};
                for (let y = searchYMin; y < searchYMax; y++) {
                    for (let x = searchXMin; x < searchXMax; x++) {
                        if (whiteMask[y * w + x]) {
                            const yBin = Math.floor(y / 5) * 5;
                            if (!byY[yBin]) byY[yBin] = [];
                            byY[yBin].push(x);
                        }
                    }
                }

                const arcSegments = [];
                for (const [yBinStr, xList] of Object.entries(byY)) {
                    const yBin = parseInt(yBinStr);
                    if (xList.length < 3) continue;

                    const xSorted = xList.sort((a, b) => a - b);

                    let maxGapIdx = -1;
                    let maxGap = 30;
                    for (let i = 1; i < xSorted.length; i++) {
                        const gap = xSorted[i] - xSorted[i - 1];
                        if (gap > maxGap) {
                            maxGap = gap;
                            maxGapIdx = i;
                        }
                    }

                    if (maxGapIdx > 0) {
                        const leftSegment = xSorted.slice(0, maxGapIdx);
                        const rightSegment = xSorted.slice(maxGapIdx);

                        if (leftSegment.length >= 1 && rightSegment.length >= 1) {
                            const leftCenter = (leftSegment[0] + leftSegment[leftSegment.length - 1]) / 2;
                            const rightCenter = (rightSegment[0] + rightSegment[rightSegment.length - 1]) / 2;
                            const width = rightCenter - leftCenter;

                            if (width > 100 && width < 400) {
                                arcSegments.push({
                                    y: yBin,
                                    leftX: leftCenter,
                                    rightX: rightCenter,
                                    centerX: (leftCenter + rightCenter) / 2,
                                    width: width
                                });
                            }
                        }
                    }
                }

                if (arcSegments.length < 3) return null;

                const centerXs = arcSegments.map(s => s.centerX);
                centerXs.sort((a, b) => a - b);
                const medianCenterX = centerXs[Math.floor(centerXs.length / 2)];

                const filtered = arcSegments.filter(s => Math.abs(s.centerX - medianCenterX) < 80);

                if (filtered.length < 3) return null;

                filtered.sort((a, b) => a.y - b.y);

                const maxWidthSeg = filtered.reduce((max, s) => s.width > max.width ? s : max, filtered[0]);

                const ellipse = {
                    centerX: maxWidthSeg.centerX,
                    centerY: maxWidthSeg.y,
                    width: maxWidthSeg.width,
                    topY: filtered[0].y,
                    bottomY: filtered[filtered.length - 1].y,
                    height: filtered[filtered.length - 1].y - filtered[0].y
                };

                if (ellipse.height < 30 || ellipse.width < 50) return null;

                ellipse.aspectRatio = ellipse.width / ellipse.height;

                if (ellipse.height < ellipse.width) {
                    const cosTheta = ellipse.height / ellipse.width;
                    ellipse.pitchAngle = Math.acos(cosTheta) * 180 / Math.PI;
                    ellipse.cosPitch = cosTheta;
                } else {
                    ellipse.pitchAngle = 0;
                    ellipse.cosPitch = 1;
                }

                return ellipse;
            },

            // ========== RANSAC HOMOGRAPHY ==========

            // Compute homography from 4 point correspondences using DLT
            computeHomography(srcPoints, dstPoints) {
                if (srcPoints.length < 4) return null;

                // Build the A matrix for DLT
                const A = [];
                for (let i = 0; i < srcPoints.length; i++) {
                    const [x, y] = [srcPoints[i].x, srcPoints[i].y];
                    const [xp, yp] = [dstPoints[i].x, dstPoints[i].y];

                    A.push([-x, -y, -1, 0, 0, 0, x * xp, y * xp, xp]);
                    A.push([0, 0, 0, -x, -y, -1, x * yp, y * yp, yp]);
                }

                // Solve using SVD (simplified - find null space of A^T A)
                const ATA = this.matMul(this.transpose(A), A);
                const h = this.smallestEigenvector(ATA);

                if (!h) return null;

                // Reshape to 3x3 homography matrix
                return [
                    [h[0], h[1], h[2]],
                    [h[3], h[4], h[5]],
                    [h[6], h[7], h[8]]
                ];
            },

            // Matrix multiplication
            matMul(A, B) {
                const m = A.length;
                const n = B[0].length;
                const k = B.length;
                const C = Array(m).fill(null).map(() => Array(n).fill(0));

                for (let i = 0; i < m; i++) {
                    for (let j = 0; j < n; j++) {
                        for (let p = 0; p < k; p++) {
                            C[i][j] += A[i][p] * B[p][j];
                        }
                    }
                }
                return C;
            },

            // Matrix transpose
            transpose(A) {
                return A[0].map((_, i) => A.map(row => row[i]));
            },

            // Power iteration for smallest eigenvector (for homography)
            smallestEigenvector(A) {
                const n = A.length;
                let v = Array(n).fill(1 / Math.sqrt(n));

                // Shift to make smallest eigenvalue largest
                const trace = A.reduce((s, row, i) => s + row[i], 0);
                const shift = trace / n + 100;
                const shifted = A.map((row, i) => row.map((val, j) => (i === j ? shift - val : -val)));

                // Power iteration
                for (let iter = 0; iter < 100; iter++) {
                    const newV = shifted.map(row => row.reduce((s, val, i) => s + val * v[i], 0));
                    const norm = Math.sqrt(newV.reduce((s, val) => s + val * val, 0));
                    if (norm < 1e-10) return null;
                    v = newV.map(val => val / norm);
                }

                return v;
            },

            // Apply homography to a point
            applyHomography(H, point) {
                const x = H[0][0] * point.x + H[0][1] * point.y + H[0][2];
                const y = H[1][0] * point.x + H[1][1] * point.y + H[1][2];
                const w = H[2][0] * point.x + H[2][1] * point.y + H[2][2];
                return { x: x / w, y: y / w };
            },

            // RANSAC homography estimation
            ransacHomography(srcPoints, dstPoints) {
                if (srcPoints.length < 4) return null;

                let bestH = null;
                let bestInliers = 0;
                let bestInlierSet = [];

                const n = srcPoints.length;

                for (let iter = 0; iter < this.config.ransacIterations; iter++) {
                    // Random sample of 4 points
                    const indices = [];
                    while (indices.length < 4) {
                        const idx = Math.floor(Math.random() * n);
                        if (!indices.includes(idx)) indices.push(idx);
                    }

                    const sampleSrc = indices.map(i => srcPoints[i]);
                    const sampleDst = indices.map(i => dstPoints[i]);

                    // Compute homography from sample
                    const H = this.computeHomography(sampleSrc, sampleDst);
                    if (!H) continue;

                    // Count inliers
                    const inliers = [];
                    for (let i = 0; i < n; i++) {
                        const projected = this.applyHomography(H, srcPoints[i]);
                        const error = Math.sqrt(
                            Math.pow(projected.x - dstPoints[i].x, 2) +
                            Math.pow(projected.y - dstPoints[i].y, 2)
                        );
                        if (error < this.config.ransacThreshold) {
                            inliers.push(i);
                        }
                    }

                    if (inliers.length > bestInliers) {
                        bestInliers = inliers.length;
                        bestH = H;
                        bestInlierSet = inliers;
                    }
                }

                // Recompute homography with all inliers
                if (bestInliers >= this.config.ransacMinInliers) {
                    const inlierSrc = bestInlierSet.map(i => srcPoints[i]);
                    const inlierDst = bestInlierSet.map(i => dstPoints[i]);
                    return {
                        H: this.computeHomography(inlierSrc, inlierDst) || bestH,
                        inliers: bestInlierSet,
                        inlierCount: bestInliers
                    };
                }

                return null;
            },

            // ========== KLT FEATURE TRACKING ==========

            // Compute image gradient at a point (bilinear interpolation)
            getGradient(gray, x, y) {
                const w = gray.width;
                const h = gray.height;
                const data = gray.data;

                if (x < 1 || x >= w - 1 || y < 1 || y >= h - 1) {
                    return { Ix: 0, Iy: 0, I: 0 };
                }

                const x0 = Math.floor(x);
                const y0 = Math.floor(y);
                const fx = x - x0;
                const fy = y - y0;

                // Bilinear interpolation for intensity
                const I = (1 - fx) * (1 - fy) * data[y0 * w + x0] +
                          fx * (1 - fy) * data[y0 * w + x0 + 1] +
                          (1 - fx) * fy * data[(y0 + 1) * w + x0] +
                          fx * fy * data[(y0 + 1) * w + x0 + 1];

                // Gradient via central differences
                const Ix = (data[y0 * w + x0 + 1] - data[y0 * w + x0 - 1]) / 2;
                const Iy = (data[(y0 + 1) * w + x0] - data[(y0 - 1) * w + x0]) / 2;

                return { Ix, Iy, I };
            },

            // Track a single feature using Lucas-Kanade
            trackFeatureLK(prevGray, currGray, point) {
                const winSize = this.config.kltWindowSize;
                const halfWin = Math.floor(winSize / 2);

                let x = point.x;
                let y = point.y;

                // Iterative refinement
                for (let iter = 0; iter < this.config.kltMaxIterations; iter++) {
                    // Build structure tensor and error vector
                    let Gxx = 0, Gyy = 0, Gxy = 0;
                    let bx = 0, by = 0;

                    for (let wy = -halfWin; wy <= halfWin; wy++) {
                        for (let wx = -halfWin; wx <= halfWin; wx++) {
                            const px = point.x + wx;
                            const py = point.y + wy;
                            const cx = x + wx;
                            const cy = y + wy;

                            const prevG = this.getGradient(prevGray, px, py);
                            const currG = this.getGradient(currGray, cx, cy);

                            const It = currG.I - prevG.I;

                            Gxx += prevG.Ix * prevG.Ix;
                            Gyy += prevG.Iy * prevG.Iy;
                            Gxy += prevG.Ix * prevG.Iy;
                            bx -= prevG.Ix * It;
                            by -= prevG.Iy * It;
                        }
                    }

                    // Solve 2x2 linear system
                    const det = Gxx * Gyy - Gxy * Gxy;
                    if (Math.abs(det) < 1e-6) {
                        return { point: null, status: false }; // Lost track
                    }

                    const dx = (Gyy * bx - Gxy * by) / det;
                    const dy = (Gxx * by - Gxy * bx) / det;

                    x += dx;
                    y += dy;

                    if (Math.abs(dx) < this.config.kltEpsilon &&
                        Math.abs(dy) < this.config.kltEpsilon) {
                        break;
                    }
                }

                // Check if tracked point is within bounds
                if (x < 0 || x >= currGray.width || y < 0 || y >= currGray.height) {
                    return { point: null, status: false };
                }

                return { point: { x, y }, status: true };
            },

            // Track multiple features
            trackFeatures(prevGray, currGray, features) {
                return features.map(f => this.trackFeatureLK(prevGray, currGray, f));
            },

            // ========== KALMAN FILTER ==========

            // Initialize Kalman filter for homography parameters
            initKalman() {
                // State: [tx, ty, scale, rotation, vx, vy, vs, vr] (position + velocity)
                this.kalmanState = {
                    x: new Float32Array([0, 0, 1, 0, 0, 0, 0, 0]), // State estimate
                    P: this.identityMatrix(8, 100.0), // Error covariance - high = trust measurements initially
                    Q: this.identityMatrix(8, this.config.kalmanProcessNoise), // Process noise
                    R: this.identityMatrix(4, this.config.kalmanMeasurementNoise), // Measurement noise
                };
            },

            identityMatrix(n, scale = 1) {
                const m = Array(n).fill(null).map(() => Array(n).fill(0));
                for (let i = 0; i < n; i++) m[i][i] = scale;
                return m;
            },

            // Predict step
            kalmanPredict() {
                if (!this.kalmanState) this.initKalman();

                const s = this.kalmanState;
                // Constant velocity model: x = x + v * dt
                s.x[0] += s.x[4]; // tx += vx
                s.x[1] += s.x[5]; // ty += vy
                s.x[2] += s.x[6]; // scale += vs
                s.x[3] += s.x[7]; // rotation += vr

                // Update covariance: P = F * P * F' + Q
                // Simplified: just add process noise
                for (let i = 0; i < 8; i++) {
                    s.P[i][i] += s.Q[i][i];
                }
            },

            // Update step with measurement
            kalmanUpdate(measurement) {
                if (!this.kalmanState) this.initKalman();

                const s = this.kalmanState;
                const z = measurement; // [tx, ty, scale, rotation]

                // Innovation: y = z - H * x (H extracts first 4 state elements)
                const y = [
                    z[0] - s.x[0],
                    z[1] - s.x[1],
                    z[2] - s.x[2],
                    z[3] - s.x[3]
                ];

                // Simplified Kalman gain (diagonal approximation)
                const K = [];
                for (let i = 0; i < 4; i++) {
                    const k = s.P[i][i] / (s.P[i][i] + s.R[i][i]);
                    K.push(k);

                    // Update state
                    s.x[i] += k * y[i];
                    s.x[i + 4] = k * y[i]; // Update velocity estimate

                    // Update covariance
                    s.P[i][i] *= (1 - k);
                }

                return {
                    tx: s.x[0],
                    ty: s.x[1],
                    scale: s.x[2],
                    rotation: s.x[3]
                };
            },

            // ========== MAIN DETECTION PIPELINE ==========

            // Detect field using line detection + RANSAC homography
            detectField(imageData, templatePoints) {
                console.log('[SOTACV] Starting field detection...');

                // 1. Edge detection
                const edges = this.cannyEdges(imageData);
                console.log('[SOTACV] Canny edges computed');

                // 2. Hough line detection
                const lines = this.houghLines(edges);
                console.log(`[SOTACV] Detected ${lines.length} lines`);

                if (lines.length < 4) {
                    console.log('[SOTACV] Not enough lines detected');
                    return null;
                }

                // 3. Find line intersections
                const intersections = this.findIntersections(lines, imageData.width, imageData.height);
                console.log(`[SOTACV] Found ${intersections.length} intersections`);

                if (intersections.length < 4) {
                    console.log('[SOTACV] Not enough intersections');
                    return null;
                }

                // 4. Match intersections to template points
                // For now, use a simple matching: sort by position and match
                const sortedIntersections = intersections
                    .map(i => i.point)
                    .sort((a, b) => a.y - b.y || a.x - b.x);

                // Template points should be provided as array of {x, y, id}
                const sortedTemplate = [...templatePoints]
                    .sort((a, b) => a.y - b.y || a.x - b.x);

                // Match top-left, top-right, bottom-left, bottom-right
                const matches = {
                    src: [],
                    dst: []
                };

                const numMatches = Math.min(sortedIntersections.length, sortedTemplate.length, 8);
                for (let i = 0; i < numMatches; i++) {
                    matches.src.push(sortedTemplate[i]);
                    matches.dst.push(sortedIntersections[i]);
                }

                // 5. RANSAC homography
                const result = this.ransacHomography(matches.src, matches.dst);

                if (result && result.inlierCount >= 4) {
                    console.log(`[SOTACV] Homography found with ${result.inlierCount} inliers`);
                    this.lastHomography = result.H;
                    return {
                        homography: result.H,
                        inliers: result.inlierCount,
                        intersections: sortedIntersections.slice(0, numMatches)
                    };
                }

                console.log('[SOTACV] Failed to find valid homography');
                return null;
            },

            // ========== MAIN PROPAGATION PIPELINE ==========

            // Propagate template using KLT tracking + periodic re-detection
            propagateTemplate(prevImageData, currImageData, prevAnnotations) {
                console.log('[SOTACV] Starting propagation...');

                // Convert to grayscale
                const currGray = this.toGrayscale(currImageData);

                // Debug: Check if images are different
                if (this.prevGray) {
                    let diffSum = 0;
                    const sampleSize = Math.min(1000, currGray.data.length);
                    for (let i = 0; i < sampleSize; i++) {
                        diffSum += Math.abs(currGray.data[i] - this.prevGray.data[i]);
                    }
                    const avgDiff = diffSum / sampleSize;
                    console.log(`[SOTACV] Frame difference (avg pixel): ${avgDiff.toFixed(2)}`);
                }

                // Initialize if needed
                if (!this.prevGray) {
                    this.prevGray = this.toGrayscale(prevImageData);
                    // Initialize tracked features from annotation points
                    this.trackedFeatures = [];
                    prevAnnotations.forEach(ann => {
                        if (ann.type === 'line' && ann.points) {
                            ann.points.forEach((p, idx) => {
                                this.trackedFeatures.push({
                                    x: p[0], y: p[1],
                                    annId: ann.id,
                                    pointIdx: idx
                                });
                            });
                        } else if (ann.type === 'ellipse' && ann.center) {
                            this.trackedFeatures.push({
                                x: ann.center[0], y: ann.center[1],
                                annId: ann.id,
                                pointIdx: -1 // Center
                            });
                        }
                    });
                }

                // 1. KLT tracking
                const featurePositions = this.trackedFeatures.map(f => ({ x: f.x, y: f.y }));

                // Log a sample of feature positions BEFORE tracking
                if (featurePositions.length > 0) {
                    const sample = featurePositions.slice(0, 3).map(p => `(${p.x.toFixed(0)},${p.y.toFixed(0)})`).join(', ');
                    console.log(`[SOTACV] Feature positions before: ${sample} (${featurePositions.length} total)`);
                }

                const trackResults = this.trackFeatures(this.prevGray, currGray, featurePositions);

                // Collect successfully tracked points
                const trackedSrc = [];
                const trackedDst = [];

                trackResults.forEach((result, idx) => {
                    if (result.status && result.point) {
                        trackedSrc.push({
                            x: this.trackedFeatures[idx].x,
                            y: this.trackedFeatures[idx].y
                        });
                        trackedDst.push(result.point);

                        // Update tracked feature position for next frame
                        this.trackedFeatures[idx].x = result.point.x;
                        this.trackedFeatures[idx].y = result.point.y;
                    }
                });

                // Log sample of tracked positions AFTER tracking
                if (trackedDst.length > 0) {
                    const sampleDst = trackedDst.slice(0, 3).map(p => `(${p.x.toFixed(1)},${p.y.toFixed(1)})`).join(', ');
                    console.log(`[SOTACV] Tracked positions after: ${sampleDst}`);
                }

                console.log(`[SOTACV] Tracked ${trackedDst.length}/${this.trackedFeatures.length} features`);

                // 2. Check if re-detection is needed
                this.framesSinceDetection++;
                let redetected = false;

                if (this.framesSinceDetection >= this.config.redetectInterval ||
                    trackedDst.length < this.trackedFeatures.length * 0.5) {
                    console.log('[SOTACV] Triggering re-detection...');
                    // Would run detectField here and merge with tracked points
                    this.framesSinceDetection = 0;
                    redetected = true;
                }

                // 3. Calculate motion from tracked correspondences using MEDIAN (robust to outliers)
                let motion = { dx: 0, dy: 0, scale: 1.0, rotation: 0 };

                if (trackedSrc.length >= 2) {
                    // Use median motion - robust to outliers, works for camera panning
                    const dxs = trackedDst.map((d, i) => d.x - trackedSrc[i].x);
                    const dys = trackedDst.map((d, i) => d.y - trackedSrc[i].y);

                    // Log first few displacements for debugging
                    if (dxs.length > 0) {
                        const sampleDxs = dxs.slice(0, 5).map(v => v.toFixed(2)).join(', ');
                        const sampleDys = dys.slice(0, 5).map(v => v.toFixed(2)).join(', ');
                        console.log(`[SOTACV] Sample displacements dx=[${sampleDxs}] dy=[${sampleDys}]`);
                    }

                    dxs.sort((a, b) => a - b);
                    dys.sort((a, b) => a - b);
                    motion.dx = dxs[Math.floor(dxs.length / 2)];
                    motion.dy = dys[Math.floor(dys.length / 2)];

                    console.log(`[SOTACV] Raw motion: dx=${motion.dx.toFixed(2)}, dy=${motion.dy.toFixed(2)} (${trackedSrc.length} pts)`);
                }

                // Skip Kalman filter - use raw motion directly for responsiveness
                // The median already provides robustness to outliers
                const filtered = { tx: motion.dx, ty: motion.dy, scale: motion.scale, rotation: motion.rotation };

                console.log(`[SOTACV] Applied motion: dx=${filtered.tx.toFixed(2)}, dy=${filtered.ty.toFixed(2)}`);

                // 5. Apply motion to annotations
                const newAnnotations = prevAnnotations.map(ann => {
                    const newAnn = JSON.parse(JSON.stringify(ann));

                    if (ann.type === 'line' && ann.points) {
                        newAnn.points = ann.points.map(p => [
                            p[0] + filtered.tx,
                            p[1] + filtered.ty
                        ]);
                    } else if (ann.type === 'ellipse' && ann.center) {
                        newAnn.center = [
                            ann.center[0] + filtered.tx,
                            ann.center[1] + filtered.ty
                        ];
                    }

                    return newAnn;
                });

                // Update state
                this.prevGray = currGray;

                return {
                    annotations: newAnnotations,
                    motion: filtered,
                    trackedCount: trackedDst.length,
                    redetected
                };
            },

            // Reset state (call when switching videos/keyframes)
            reset() {
                this.prevGray = null;
                this.trackedFeatures = [];
                this.kalmanState = null;
                this.framesSinceDetection = 0;
                this.lastHomography = null;
                console.log('[SOTACV] State reset');
            }
        };

        // ========== BULK PROPAGATION SYSTEM ==========
        // Pre-computes frames for smooth playback using GT keyframe interpolation

        // Extract corners from template annotations
        function extractCornersFromAnnotations(anns) {
            const fieldAnns = anns.filter(a => a.mode === 'field' && a.isTemplate);
            if (fieldAnns.length === 0) return null;

            // Find corner points from templatePoints
            let corners = { topLeft: null, topRight: null, bottomLeft: null, bottomRight: null };
            for (const ann of fieldAnns) {
                if (!ann.templatePoints || !ann.points) continue;
                ann.templatePoints.forEach((ptName, idx) => {
                    if (ptName === 'corner_tl' && ann.points[idx]) {
                        corners.topLeft = { x: ann.points[idx][0], y: ann.points[idx][1] };
                    } else if (ptName === 'corner_tr' && ann.points[idx]) {
                        corners.topRight = { x: ann.points[idx][0], y: ann.points[idx][1] };
                    } else if (ptName === 'corner_bl' && ann.points[idx]) {
                        corners.bottomLeft = { x: ann.points[idx][0], y: ann.points[idx][1] };
                    } else if (ptName === 'corner_br' && ann.points[idx]) {
                        corners.bottomRight = { x: ann.points[idx][0], y: ann.points[idx][1] };
                    }
                });
            }

            if (!corners.topLeft || !corners.topRight || !corners.bottomLeft || !corners.bottomRight) {
                return null;
            }
            return corners;
        }

        // Interpolate between two corner sets (linear for now, could use splines)
        function interpolateCorners(c1, c2, t) {
            // Use smooth easing for more natural motion
            const ease = t * t * (3 - 2 * t);  // Smoothstep
            return {
                topLeft: {
                    x: c1.topLeft.x + (c2.topLeft.x - c1.topLeft.x) * ease,
                    y: c1.topLeft.y + (c2.topLeft.y - c1.topLeft.y) * ease
                },
                topRight: {
                    x: c1.topRight.x + (c2.topRight.x - c1.topRight.x) * ease,
                    y: c1.topRight.y + (c2.topRight.y - c1.topRight.y) * ease
                },
                bottomLeft: {
                    x: c1.bottomLeft.x + (c2.bottomLeft.x - c1.bottomLeft.x) * ease,
                    y: c1.bottomLeft.y + (c2.bottomLeft.y - c1.bottomLeft.y) * ease
                },
                bottomRight: {
                    x: c1.bottomRight.x + (c2.bottomRight.x - c1.bottomRight.x) * ease,
                    y: c1.bottomRight.y + (c2.bottomRight.y - c1.bottomRight.y) * ease
                }
            };
        }

        // Get sorted list of GT keyframes from saved annotations
        async function getGTKeyframesFromServer() {
            try {
                const resp = await fetch(`/api/video/${encodeURIComponent(currentVideo)}/annotations`);
                if (!resp.ok) return [];
                const data = await resp.json();
                const frames = data.frames || {};

                // Find frames that have GT annotations (isGT: true)
                const gtFrames = [];
                for (const [frameStr, anns] of Object.entries(frames)) {
                    const frameNum = parseInt(frameStr);
                    // Check if this frame has GT field annotations
                    const hasGT = anns.some(a => a.mode === 'field' && a.isGT !== false);
                    if (hasGT) {
                        gtFrames.push(frameNum);
                    }
                }
                return gtFrames.sort((a, b) => a - b);
            } catch (e) {
                console.error('[BulkProp] Error getting GT keyframes:', e);
                return [];
            }
        }

        // Get annotations for a specific frame from server
        async function getFrameAnnotationsFromServer(frameNum) {
            try {
                const resp = await fetch(`/api/video/${encodeURIComponent(currentVideo)}/annotations`);
                if (!resp.ok) return null;
                const data = await resp.json();
                return data.frames?.[String(frameNum)] || null;
            } catch (e) {
                return null;
            }
        }

        // Bulk pre-propagate all frames between GT keyframes
        async function bulkPrePropagate(startFrame = 0, endFrame = null) {
            if (propagationInProgress) {
                console.log('[BulkProp] Already in progress');
                return;
            }

            const maxFrame = endFrame || Math.min(startFrame + 500, totalFrames - 1);  // Process up to 500 frames
            propagationInProgress = true;
            propagationCache = {};

            console.log('%c[BulkProp] Starting bulk propagation', 'background: #8b5cf6; color: white; padding: 2px 6px;');
            console.log(`[BulkProp] Range: ${startFrame} to ${maxFrame}`);

            try {
                // Get GT keyframes
                gtKeyframes = await getGTKeyframesFromServer();
                console.log('[BulkProp] GT keyframes:', gtKeyframes);

                if (gtKeyframes.length === 0) {
                    console.log('[BulkProp] No GT keyframes found, will use optical flow only');
                    propagationInProgress = false;
                    return;
                }

                // Load annotations for each GT keyframe
                const gtData = {};
                for (const kf of gtKeyframes) {
                    const anns = await getFrameAnnotationsFromServer(kf);
                    if (anns) {
                        const corners = extractCornersFromAnnotations(anns);
                        gtData[kf] = { annotations: anns, corners };
                        propagationCache[kf] = { annotations: anns, corners, isGT: true };
                    }
                }

                // Process segments between GT keyframes
                for (let i = 0; i < gtKeyframes.length; i++) {
                    const gtStart = gtKeyframes[i];
                    const gtEnd = gtKeyframes[i + 1] || maxFrame + 1;

                    if (gtStart > maxFrame) break;

                    const startCorners = gtData[gtStart]?.corners;
                    const startAnns = gtData[gtStart]?.annotations;

                    if (!startCorners || !startAnns) continue;

                    // Determine end corners (next GT or extrapolate)
                    let endCorners = gtData[gtEnd]?.corners;
                    const segmentEnd = Math.min(gtEnd - 1, maxFrame);

                    if (endCorners && gtEnd <= maxFrame) {
                        // Interpolate between two GT keyframes
                        console.log(`[BulkProp] Interpolating frames ${gtStart+1} to ${segmentEnd} between GT ${gtStart} and ${gtEnd}`);
                        for (let f = gtStart + 1; f <= segmentEnd; f++) {
                            const t = (f - gtStart) / (gtEnd - gtStart);
                            const interpCorners = interpolateCorners(startCorners, endCorners, t);

                            // Generate template from interpolated corners
                            const interpAnns = generateTemplateAnnotationsFromCorners(
                                interpCorners, currentImage?.width || 1920, currentImage?.height || 1080
                            );

                            propagationCache[f] = {
                                annotations: interpAnns,
                                corners: interpCorners,
                                isGT: false,
                                interpolated: true,
                                gtBefore: gtStart,
                                gtAfter: gtEnd
                            };
                        }
                    } else {
                        // No next GT - extrapolate using learning model + GT slope
                        console.log(`[BulkProp] Extrapolating from GT ${gtStart} to frame ${segmentEnd}`);

                        // Get motion slope from previous GT segment if available
                        let motionSlope = null;
                        const gtIdx = gtKeyframes.indexOf(gtStart);
                        if (gtIdx > 0) {
                            const prevGT = gtKeyframes[gtIdx - 1];
                            const prevCorners = gtData[prevGT]?.corners;
                            if (prevCorners) {
                                const frameDiff = gtStart - prevGT;
                                if (frameDiff > 0) {
                                    // Calculate per-frame motion from previous segment
                                    motionSlope = {
                                        topLeft: { x: (startCorners.topLeft.x - prevCorners.topLeft.x) / frameDiff, y: (startCorners.topLeft.y - prevCorners.topLeft.y) / frameDiff },
                                        topRight: { x: (startCorners.topRight.x - prevCorners.topRight.x) / frameDiff, y: (startCorners.topRight.y - prevCorners.topRight.y) / frameDiff },
                                        bottomLeft: { x: (startCorners.bottomLeft.x - prevCorners.bottomLeft.x) / frameDiff, y: (startCorners.bottomLeft.y - prevCorners.bottomLeft.y) / frameDiff },
                                        bottomRight: { x: (startCorners.bottomRight.x - prevCorners.bottomRight.x) / frameDiff, y: (startCorners.bottomRight.y - prevCorners.bottomRight.y) / frameDiff }
                                    };
                                    console.log(`[BulkProp] Using motion slope from GT ${prevGT}->${gtStart}`);
                                }
                            }
                        }

                        for (let f = gtStart + 1; f <= segmentEnd; f++) {
                            const frameOffset = f - gtStart;
                            let extrapCorners;

                            if (motionSlope) {
                                // Extrapolate using motion slope with decay
                                const decay = Math.max(0.5, 1 - frameOffset * 0.02);  // Decay motion over time
                                extrapCorners = {
                                    topLeft: { x: startCorners.topLeft.x + motionSlope.topLeft.x * frameOffset * decay, y: startCorners.topLeft.y + motionSlope.topLeft.y * frameOffset * decay },
                                    topRight: { x: startCorners.topRight.x + motionSlope.topRight.x * frameOffset * decay, y: startCorners.topRight.y + motionSlope.topRight.y * frameOffset * decay },
                                    bottomLeft: { x: startCorners.bottomLeft.x + motionSlope.bottomLeft.x * frameOffset * decay, y: startCorners.bottomLeft.y + motionSlope.bottomLeft.y * frameOffset * decay },
                                    bottomRight: { x: startCorners.bottomRight.x + motionSlope.bottomRight.x * frameOffset * decay, y: startCorners.bottomRight.y + motionSlope.bottomRight.y * frameOffset * decay }
                                };
                            } else {
                                // No slope available - copy last GT
                                extrapCorners = { ...startCorners };
                            }

                            // Generate template from extrapolated corners
                            const extrapAnns = generateTemplateAnnotationsFromCorners(
                                extrapCorners, currentImage?.width || 1920, currentImage?.height || 1080
                            );

                            propagationCache[f] = {
                                annotations: extrapAnns.annotations || JSON.parse(JSON.stringify(startAnns)),
                                corners: extrapCorners,
                                isGT: false,
                                extrapolated: true,
                                gtSource: gtStart,
                                usedSlope: !!motionSlope
                            };
                        }
                    }
                }

                const cachedCount = Object.keys(propagationCache).length;
                console.log(`%c[BulkProp] Cached ${cachedCount} frames`, 'background: #10b981; color: white; padding: 2px 6px;');

            } catch (e) {
                console.error('[BulkProp] Error:', e);
            }

            propagationInProgress = false;
            lastPropagationVideo = currentVideo;
        }

        // Generate template annotations from corner positions
        function generateTemplateAnnotationsFromCorners(corners, width, height) {
            // Use existing function if available
            if (typeof generateFieldTemplateFromCorners === 'function') {
                return generateFieldTemplateFromCorners(width, height, corners);
            }
            return [];
        }

        // Check if we have cached data for a frame
        function hasCachedFrame(frameNum) {
            return propagationCache[frameNum] !== undefined;
        }

        // Get cached annotations for a frame
        function getCachedAnnotations(frameNum) {
            return propagationCache[frameNum]?.annotations || null;
        }

        // Called when user marks a frame as GT - re-interpolate surrounding segments
        async function onNewGTKeyframe(frameNum, newAnnotations) {
            console.log(`%c[BulkProp] New GT keyframe at frame ${frameNum}`, 'background: #f59e0b; color: black; padding: 2px 6px;');

            // Add to GT keyframes list
            if (!gtKeyframes.includes(frameNum)) {
                gtKeyframes.push(frameNum);
                gtKeyframes.sort((a, b) => a - b);
            }

            // Update cache
            const corners = extractCornersFromAnnotations(newAnnotations);
            propagationCache[frameNum] = {
                annotations: newAnnotations,
                corners,
                isGT: true
            };

            // Re-interpolate segments that touch this new keyframe
            const kfIdx = gtKeyframes.indexOf(frameNum);

            // Re-interpolate previous segment (if exists)
            if (kfIdx > 0) {
                const prevGT = gtKeyframes[kfIdx - 1];
                await reinterpolateSegment(prevGT, frameNum);
            }

            // Re-interpolate next segment (if exists)
            if (kfIdx < gtKeyframes.length - 1) {
                const nextGT = gtKeyframes[kfIdx + 1];
                await reinterpolateSegment(frameNum, nextGT);
            }

            console.log('[BulkProp] Re-interpolation complete');
        }

        // Re-interpolate a segment between two GT keyframes
        async function reinterpolateSegment(startGT, endGT) {
            const startData = propagationCache[startGT];
            const endData = propagationCache[endGT];

            if (!startData?.corners || !endData?.corners) {
                console.log(`[BulkProp] Missing corner data for segment ${startGT}-${endGT}`);
                return;
            }

            console.log(`[BulkProp] Re-interpolating segment ${startGT} to ${endGT}`);

            for (let f = startGT + 1; f < endGT; f++) {
                const t = (f - startGT) / (endGT - startGT);
                const interpCorners = interpolateCorners(startData.corners, endData.corners, t);

                const interpAnns = generateTemplateAnnotationsFromCorners(
                    interpCorners, currentImage?.width || 1920, currentImage?.height || 1080
                );

                propagationCache[f] = {
                    annotations: interpAnns,
                    corners: interpCorners,
                    isGT: false,
                    interpolated: true,
                    gtBefore: startGT,
                    gtAfter: endGT
                };
            }
        }

        // Clear propagation cache (e.g., when video changes)
        function clearPropagationCache() {
            propagationCache = {};
            gtKeyframes = [];
            lastPropagationVideo = null;
        }

        // ========== GEOMETRIC STABILITY SYSTEM ==========
        // Stores the original GT geometry as the reference for all field annotations
        // All propagated field annotations are reconstructed from this reference
        let fieldGTReference = null;  // { annotations: [...], centroid: {x, y} }
        let lastFieldTransform = { dx: 0, dy: 0, scale: 1 };  // Last valid transform

        // Speed thresholds per axis (pixels per frame)
        // Camera model: Elevated center-field wide angle, rotating toward goals
        const GEOMETRY_CONFIG = {
            // X axis (horizontal pan, goal-to-goal) - most common movement
            maxSpeedX: 8,          // Conservative - field moves slowly
            // Y axis (vertical tilt) - almost NEVER happens
            maxSpeedY: 1.5,        // Very strict - camera is level
            // Z axis (zoom) - occasional, smooth
            maxScaleChange: 0.01,  // Max scale change per frame (1% zoom)
            // Noise filtering - be aggressive
            minSpeedThreshold: 0.2, // Below this is noise
            // Jump detection - detect scene cuts
            jumpThreshold: 20,     // Movement > this is a jump/cut
            // Smoothing
            smoothingFactor: 0.7,  // Strong smoothing
            // Outlier detection
            outlierThreshold: 1.5, // Very strict outlier rejection
            // Velocity tracking for smooth motion
            maxAcceleration: 3,    // Max change in velocity per frame
        };

        // ========== RIGID BODY TEMPLATE SYSTEM ==========
        // The field template is a RIGID STRUCTURE - all points maintain fixed
        // geometric relationships. This system guarantees geometry preservation.
        const RigidTemplate = {
            // Reference state (from keyframe)
            centroid: null,           // {x, y} - center of template
            offsets: [],              // [{id, dx, dy, type, ...}] - fixed offsets from centroid
            scale: 1.0,               // Current scale factor
            rotation: 0,              // Current rotation (radians)

            // Tracking points for motion estimation (invisible)
            // These are spread across and beyond the visible field area
            trackingGrid: [],         // [{x, y, weight}] - points for flow sampling

            // Motion estimation state
            lastMotion: { dx: 0, dy: 0, scale: 1.0 },
            motionVelocity: { dx: 0, dy: 0 },  // For smoothing

            // Initialize from annotations (called when creating/loading keyframe)
            initFromAnnotations(anns) {
                if (!anns || anns.length === 0) return false;

                // Compute centroid from all points
                let allPoints = [];
                anns.forEach(ann => {
                    if (ann.type === 'line' && ann.points) {
                        ann.points.forEach(p => allPoints.push({x: p[0], y: p[1]}));
                    } else if (ann.type === 'ellipse' && ann.center) {
                        allPoints.push({x: ann.center[0], y: ann.center[1]});
                    }
                });

                if (allPoints.length === 0) return false;

                const cx = allPoints.reduce((s, p) => s + p.x, 0) / allPoints.length;
                const cy = allPoints.reduce((s, p) => s + p.y, 0) / allPoints.length;
                this.centroid = { x: cx, y: cy };
                this.scale = 1.0;
                this.rotation = 0;

                // Store offsets for each annotation
                this.offsets = anns.map(ann => {
                    const offset = {
                        id: ann.id,
                        type: ann.type,
                        label: ann.label,
                        isTemplate: ann.isTemplate,
                        templatePoints: ann.templatePoints,
                        templateCenter: ann.templateCenter,
                        mode: ann.mode || 'field'
                    };

                    if (ann.type === 'line' && ann.points) {
                        offset.points = ann.points.map(p => ({
                            dx: p[0] - cx,
                            dy: p[1] - cy
                        }));
                    } else if (ann.type === 'ellipse') {
                        offset.centerDx = ann.center[0] - cx;
                        offset.centerDy = ann.center[1] - cy;
                        offset.axes = [...ann.axes];
                        offset.angle = ann.angle || 0;
                        offset.startAngle = ann.startAngle;
                        offset.endAngle = ann.endAngle;
                    }

                    return offset;
                });

                // Generate tracking grid (invisible points for motion estimation)
                this.generateTrackingGrid();

                console.log('[RigidTemplate] Initialized with centroid:', this.centroid, 'offsets:', this.offsets.length);
                return true;
            },

            // Generate a grid of tracking points for robust motion estimation
            generateTrackingGrid() {
                if (!this.centroid || !currentImage) return;

                this.trackingGrid = [];
                const imgW = currentImage.width;
                const imgH = currentImage.height;

                // Find bounding box of template
                let minX = Infinity, maxX = -Infinity;
                let minY = Infinity, maxY = -Infinity;
                this.offsets.forEach(off => {
                    if (off.points) {
                        off.points.forEach(p => {
                            const x = this.centroid.x + p.dx * this.scale;
                            const y = this.centroid.y + p.dy * this.scale;
                            minX = Math.min(minX, x); maxX = Math.max(maxX, x);
                            minY = Math.min(minY, y); maxY = Math.max(maxY, y);
                        });
                    } else if (off.centerDx !== undefined) {
                        const x = this.centroid.x + off.centerDx * this.scale;
                        const y = this.centroid.y + off.centerDy * this.scale;
                        minX = Math.min(minX, x); maxX = Math.max(maxX, x);
                        minY = Math.min(minY, y); maxY = Math.max(maxY, y);
                    }
                });

                // Expand bounds slightly for tracking outside field
                const padX = (maxX - minX) * 0.2;
                const padY = (maxY - minY) * 0.2;
                minX = Math.max(0, minX - padX);
                maxX = Math.min(imgW, maxX + padX);
                minY = Math.max(0, minY - padY);
                maxY = Math.min(imgH, maxY + padY);

                // Create grid of tracking points
                const gridCols = 7;
                const gridRows = 5;
                for (let row = 0; row < gridRows; row++) {
                    for (let col = 0; col < gridCols; col++) {
                        const x = minX + (maxX - minX) * (col / (gridCols - 1));
                        const y = minY + (maxY - minY) * (row / (gridRows - 1));
                        // Weight: center points have more influence
                        const distFromCenter = Math.sqrt(
                            Math.pow((col - gridCols/2) / gridCols, 2) +
                            Math.pow((row - gridRows/2) / gridRows, 2)
                        );
                        const weight = 1.0 - distFromCenter * 0.5;
                        this.trackingGrid.push({ x, y, weight });
                    }
                }

                console.log('[RigidTemplate] Generated tracking grid:', this.trackingGrid.length, 'points');
            },

            // Rebuild annotations from centroid + offsets
            // This GUARANTEES geometry is preserved
            rebuildAnnotations() {
                if (!this.centroid || this.offsets.length === 0) return [];

                const cx = this.centroid.x;
                const cy = this.centroid.y;
                const s = this.scale;
                const cos_r = Math.cos(this.rotation);
                const sin_r = Math.sin(this.rotation);

                return this.offsets.map(off => {
                    const ann = {
                        id: off.id,
                        type: off.type,
                        label: off.label,
                        isTemplate: off.isTemplate,
                        isGT: false,  // Propagated frames are not GT
                        mode: off.mode,
                        templatePoints: off.templatePoints,
                        templateCenter: off.templateCenter
                    };

                    if (off.type === 'line' && off.points) {
                        ann.points = off.points.map(p => {
                            // Apply scale then rotation around centroid
                            let dx = p.dx * s;
                            let dy = p.dy * s;
                            if (this.rotation !== 0) {
                                const rx = dx * cos_r - dy * sin_r;
                                const ry = dx * sin_r + dy * cos_r;
                                dx = rx; dy = ry;
                            }
                            return [cx + dx, cy + dy];
                        });
                    } else if (off.type === 'ellipse') {
                        let dx = off.centerDx * s;
                        let dy = off.centerDy * s;
                        if (this.rotation !== 0) {
                            const rx = dx * cos_r - dy * sin_r;
                            const ry = dx * sin_r + dy * cos_r;
                            dx = rx; dy = ry;
                        }
                        ann.center = [cx + dx, cy + dy];
                        ann.axes = [off.axes[0] * s, off.axes[1] * s];
                        ann.angle = (off.angle || 0) + this.rotation * 180 / Math.PI;
                        if (off.startAngle !== undefined) ann.startAngle = off.startAngle;
                        if (off.endAngle !== undefined) ann.endAngle = off.endAngle;
                    }

                    return ann;
                });
            },

            // Estimate camera motion from optical flow using multiple tracking points
            // Returns {dx, dy, scale} - the rigid transform to apply
            estimateMotion(flowData, imgWidth, imgHeight) {
                if (!this.trackingGrid || this.trackingGrid.length === 0) {
                    return { dx: 0, dy: 0, scale: 1.0 };
                }

                // Sample flow at each tracking point
                const motions = [];
                this.trackingGrid.forEach(tp => {
                    const fx = Math.floor(tp.x);
                    const fy = Math.floor(tp.y);
                    if (fx >= 0 && fx < imgWidth && fy >= 0 && fy < imgHeight) {
                        const idx = (fy * imgWidth + fx) * 2;
                        const flowX = flowData[idx];
                        const flowY = flowData[idx + 1];

                        // Reject extreme flow values (likely errors)
                        if (Math.abs(flowX) < 50 && Math.abs(flowY) < 50) {
                            motions.push({
                                dx: flowX,
                                dy: flowY,
                                weight: tp.weight,
                                x: tp.x,
                                y: tp.y
                            });
                        }
                    }
                });

                if (motions.length < 3) {
                    console.log('[RigidTemplate] Not enough valid motion samples:', motions.length);
                    return { dx: 0, dy: 0, scale: 1.0 };
                }

                // Use RANSAC-like approach: find consensus motion
                // Sort by dx to find median
                motions.sort((a, b) => a.dx - b.dx);
                const medianDx = motions[Math.floor(motions.length / 2)].dx;

                motions.sort((a, b) => a.dy - b.dy);
                const medianDy = motions[Math.floor(motions.length / 2)].dy;

                // Filter to inliers (close to median)
                const inlierThreshold = 5;  // pixels
                const inliers = motions.filter(m => {
                    const dist = Math.sqrt(Math.pow(m.dx - medianDx, 2) + Math.pow(m.dy - medianDy, 2));
                    return dist < inlierThreshold;
                });

                if (inliers.length < 3) {
                    console.log('[RigidTemplate] Not enough inliers:', inliers.length, '/', motions.length);
                    // Fall back to weighted median
                    return { dx: medianDx, dy: medianDy, scale: 1.0 };
                }

                // Weighted average of inliers
                let totalWeight = 0;
                let sumDx = 0, sumDy = 0;
                inliers.forEach(m => {
                    sumDx += m.dx * m.weight;
                    sumDy += m.dy * m.weight;
                    totalWeight += m.weight;
                });

                const dx = sumDx / totalWeight;
                const dy = sumDy / totalWeight;

                // Estimate scale from divergence of flow (zoom detection)
                // Points moving away from center = zoom out, toward = zoom in
                let scaleSum = 0;
                let scaleCount = 0;
                inliers.forEach(m => {
                    const vecToCenterX = this.centroid.x - m.x;
                    const vecToCenterY = this.centroid.y - m.y;
                    const distToCenter = Math.sqrt(vecToCenterX * vecToCenterX + vecToCenterY * vecToCenterY);
                    if (distToCenter > 50) {  // Only use points far from center
                        // Dot product of motion with vector toward center
                        const dot = (m.dx - dx) * vecToCenterX + (m.dy - dy) * vecToCenterY;
                        // Positive dot = moving toward center = zoom in
                        const scaleChange = dot / (distToCenter * distToCenter) * 0.1;
                        scaleSum += scaleChange;
                        scaleCount++;
                    }
                });

                let scale = 1.0;
                if (scaleCount > 3) {
                    scale = 1.0 + scaleSum / scaleCount;
                    // Clamp scale change
                    scale = Math.max(0.98, Math.min(1.02, scale));
                }

                // Apply smoothing with previous motion
                const smoothing = 0.3;
                const smoothedDx = dx * (1 - smoothing) + this.lastMotion.dx * smoothing;
                const smoothedDy = dy * (1 - smoothing) + this.lastMotion.dy * smoothing;

                this.lastMotion = { dx: smoothedDx, dy: smoothedDy, scale };

                console.log('[RigidTemplate] Motion estimate: dx=', smoothedDx.toFixed(2),
                    'dy=', smoothedDy.toFixed(2), 'scale=', scale.toFixed(4),
                    'inliers=', inliers.length, '/', motions.length);

                return { dx: smoothedDx, dy: smoothedDy, scale };
            },

            // Apply motion transform (called during propagation)
            applyMotion(motion) {
                if (!this.centroid) return;

                this.centroid.x += motion.dx;
                this.centroid.y += motion.dy;
                this.scale *= motion.scale;

                // Update tracking grid positions
                this.trackingGrid.forEach(tp => {
                    tp.x += motion.dx;
                    tp.y += motion.dy;
                });
            },

            // Update centroid when user drags (preserves geometry)
            updateCentroid(newX, newY) {
                if (!this.centroid) return;
                this.centroid.x = newX;
                this.centroid.y = newY;
                this.generateTrackingGrid();
            },

            // Update scale when user uses slider (preserves geometry)
            updateScale(newScale) {
                this.scale = newScale;
                this.generateTrackingGrid();
            },

            // Check if initialized
            isInitialized() {
                return this.centroid !== null && this.offsets.length > 0;
            },

            // Reset state
            reset() {
                this.centroid = null;
                this.offsets = [];
                this.scale = 1.0;
                this.rotation = 0;
                this.trackingGrid = [];
                this.lastMotion = { dx: 0, dy: 0, scale: 1.0 };
            }
        };

        // Helper function to change tools
        function setTool(toolName) {
            // Auto-finish any pending line/ellipse before switching tools
            if (currentTool === 'line' && tempPoints.length >= 2) finishLine();
            if (currentTool === 'ellipse' && tempPoints.length >= 3) finishEllipse();

            document.querySelectorAll('.tool-btn').forEach(b => b.classList.remove('active'));
            const btn = document.querySelector(`.tool-btn[data-tool="${toolName}"]`);
            if (btn) btn.classList.add('active');

            currentTool = toolName;
            tempPoints = [];

            // Show/hide magnifier
            if (currentTool === 'magnifier') {
                magnifierActive = true;
            } else {
                magnifierActive = false;
                if (typeof magnifier !== 'undefined') magnifier.style.display = 'none';
            }

            redraw();
        }

        // ========== ATTENTION-BASED TEMPLATE MEMORY MODEL ==========
        // Simple, robust model that memorizes video->template mappings
        // Uses visual similarity with attention weighting for predictions
        // Designed to overfit: same video = nearly exact template match
        const FieldPositionModel = {
            // Memory storage: array of learned examples
            // Each example: {videoName, features, corners, camera3D, timestamp}
            examples: [],
            maxExamples: 200,  // Max stored examples

            // Feature grid size (lower = faster, higher = more precise)
            gridSize: 32,  // 32x32 visual feature grid

            // Initialize model
            init() {
                this.load();
                console.log('[FieldModel] Memory-based model initialized with', this.examples.length, 'examples');
            },

            // Extract visual features from image at low resolution
            // Returns compact feature vector capturing field appearance
            extractVisualFeatures(img) {
                const size = this.gridSize;
                const canvas = document.createElement('canvas');
                canvas.width = size;
                canvas.height = size;
                const ctx = canvas.getContext('2d');
                ctx.drawImage(img, 0, 0, size, size);

                const imageData = ctx.getImageData(0, 0, size, size);
                const data = imageData.data;
                const features = [];

                // Extract green/white features for each grid cell
                for (let i = 0; i < data.length; i += 4) {
                    const r = data[i], g = data[i + 1], b = data[i + 2];

                    // Green dominance (field detection)
                    const greenScore = Math.max(0, g - Math.max(r, b)) / 255;

                    // Brightness (white line detection)
                    const brightness = (r + g + b) / (3 * 255);

                    // Saturation (distinguishes grass from white lines)
                    const maxC = Math.max(r, g, b), minC = Math.min(r, g, b);
                    const saturation = maxC > 0 ? (maxC - minC) / maxC : 0;

                    features.push(greenScore, brightness, saturation);
                }

                return features;  // 32*32*3 = 3072 features
            },

            // Compute cosine similarity between two feature vectors
            cosineSimilarity(f1, f2) {
                if (!f1 || !f2 || f1.length !== f2.length) return 0;

                let dot = 0, norm1 = 0, norm2 = 0;
                for (let i = 0; i < f1.length; i++) {
                    dot += f1[i] * f2[i];
                    norm1 += f1[i] * f1[i];
                    norm2 += f2[i] * f2[i];
                }

                const denom = Math.sqrt(norm1) * Math.sqrt(norm2);
                return denom > 0 ? dot / denom : 0;
            },

            // Compute attention weights using softmax over similarities
            computeAttention(queryFeatures, temperature = 10) {
                if (this.examples.length === 0) return [];

                // Compute similarities
                const similarities = this.examples.map(ex =>
                    this.cosineSimilarity(queryFeatures, ex.features)
                );

                // Find max for numerical stability
                const maxSim = Math.max(...similarities);

                // Softmax with temperature (higher temp = sharper attention)
                const expSims = similarities.map(s => Math.exp((s - maxSim) * temperature));
                const sumExp = expSims.reduce((a, b) => a + b, 0);

                return expSims.map(e => e / sumExp);
            },

            // Learn from current template - INSTANT (no gradient descent)
            // Simply stores the video-template association
            // Each video+frame combination is stored as a separate example
            learn(img, corners, videoName, camera3DParams = null, frameNum = null) {
                const features = this.extractVisualFeatures(img);

                // Get Camera3D state - store ALL relevant parameters
                const cam = camera3DParams || (typeof Camera3D !== 'undefined' ? Camera3D : null);
                const camera3D = cam ? {
                    pitch: cam.pitch,
                    yaw: cam.yaw,
                    focalLength: cam.focalLength,
                    posY: cam.posY,
                    posZ: cam.posZ
                } : null;

                // Also store detected elevation and circle if available
                const detectionParams = {
                    elevationAngle: typeof detectedElevationAngle !== 'undefined' ? detectedElevationAngle : null,
                    circleEllipse: typeof detectedCircleEllipse !== 'undefined' ? detectedCircleEllipse : null
                };

                // Deep copy corners
                const cornersCopy = JSON.parse(JSON.stringify(corners));

                // Create unique key for video+frame (or just video if no frame)
                const exampleKey = frameNum !== null ? `${videoName}:${frameNum}` : videoName;

                // Check if we already have this exact video+frame
                const existingIdx = this.examples.findIndex(ex => ex.exampleKey === exampleKey);

                if (existingIdx >= 0) {
                    // Update existing example
                    this.examples[existingIdx] = {
                        exampleKey,
                        videoName,
                        frameNum,
                        features,
                        corners: cornersCopy,
                        camera3D,
                        detectionParams,
                        timestamp: Date.now()
                    };
                    console.log('[FieldModel] Updated example for:', exampleKey);
                } else {
                    // Add new example
                    this.examples.push({
                        exampleKey,
                        videoName,
                        frameNum,
                        features,
                        corners: cornersCopy,
                        camera3D,
                        detectionParams,
                        timestamp: Date.now()
                    });
                    console.log('[FieldModel] Added new example for:', exampleKey);

                    // Trim if over limit (remove oldest)
                    if (this.examples.length > this.maxExamples) {
                        this.examples.sort((a, b) => b.timestamp - a.timestamp);
                        this.examples = this.examples.slice(0, this.maxExamples);
                    }
                }

                this.save();
                return this.examples.length;
            },

            // Predict corners for a new frame using attention-weighted average
            predictCorners(img, frameWidth, frameHeight, videoName = null, frameNum = null) {
                if (this.examples.length === 0) {
                    console.log('[FieldModel] No examples stored');
                    return null;
                }

                const queryFeatures = this.extractVisualFeatures(img);

                // Check for exact video+frame match first (perfect recall)
                if (videoName && frameNum !== null) {
                    const exampleKey = `${videoName}:${frameNum}`;
                    const exactMatch = this.examples.find(ex => ex.exampleKey === exampleKey);
                    if (exactMatch) {
                        console.log('[FieldModel] Exact video+frame match:', exampleKey);
                        return {
                            ...JSON.parse(JSON.stringify(exactMatch.corners)),
                            camera3D: exactMatch.camera3D ? { ...exactMatch.camera3D } : null,
                            detectionParams: exactMatch.detectionParams ? { ...exactMatch.detectionParams } : null,
                            confidence: 1.0,
                            matchType: 'exact'
                        };
                    }
                }

                // Check for same-video examples (different frame) - use visual similarity among those
                if (videoName) {
                    const sameVideoExamples = this.examples.filter(ex => ex.videoName === videoName);
                    if (sameVideoExamples.length > 0) {
                        console.log(`[FieldModel] Found ${sameVideoExamples.length} examples from same video`);

                        // Find best visual match among same-video examples
                        let bestMatch = sameVideoExamples[0];
                        let bestSim = this.cosineSimilarity(queryFeatures, bestMatch.features);

                        for (const ex of sameVideoExamples) {
                            const sim = this.cosineSimilarity(queryFeatures, ex.features);
                            if (sim > bestSim) {
                                bestSim = sim;
                                bestMatch = ex;
                            }
                        }

                        console.log('[FieldModel] Best same-video match:', bestMatch.exampleKey || bestMatch.videoName,
                                   'similarity:', (bestSim * 100).toFixed(1) + '%');
                        return {
                            ...JSON.parse(JSON.stringify(bestMatch.corners)),
                            camera3D: bestMatch.camera3D ? { ...bestMatch.camera3D } : null,
                            detectionParams: bestMatch.detectionParams ? { ...bestMatch.detectionParams } : null,
                            confidence: Math.max(0.7, bestSim), // Same-video = high confidence
                            matchType: 'same_video'
                        };
                    }
                }

                // TOP-K AVERAGING: Only use top 3 most similar examples
                // This outperforms full weighted average (378px vs 452px error in testing)
                const K = 3;
                const similarities = this.examples.map((ex, i) => ({
                    similarity: this.cosineSimilarity(queryFeatures, ex.features),
                    index: i
                }));
                similarities.sort((a, b) => b.similarity - a.similarity);

                const topK = similarities.slice(0, Math.min(K, similarities.length));
                const topIdx = topK[0].index;
                const topWeight = topK[0].similarity;

                console.log('[FieldModel] Top-3 matches:');
                topK.forEach((match, i) => {
                    const ex = this.examples[match.index];
                    console.log(`  ${i+1}. ${ex.videoName} (${(match.similarity * 100).toFixed(1)}%)`);
                });

                // Softmax over top-K similarities
                const maxSim = topK[0].similarity;
                const temperature = 10;
                const expSims = topK.map(m => Math.exp((m.similarity - maxSim) * temperature));
                const sumExp = expSims.reduce((a, b) => a + b, 0);
                const weights = expSims.map(e => e / sumExp);

                // Weighted average of top-K corners
                const corners = {
                    topLeft: { x: 0, y: 0 },
                    topRight: { x: 0, y: 0 },
                    bottomLeft: { x: 0, y: 0 },
                    bottomRight: { x: 0, y: 0 }
                };

                let camera3D = { pitch: 0, yaw: 0, focalLength: 0, posY: 0, posZ: 0 };
                let cam3DWeight = 0;

                for (let i = 0; i < topK.length; i++) {
                    const w = weights[i];
                    const ex = this.examples[topK[i].index];
                    const c = ex.corners;

                    corners.topLeft.x += w * c.topLeft.x;
                    corners.topLeft.y += w * c.topLeft.y;
                    corners.topRight.x += w * c.topRight.x;
                    corners.topRight.y += w * c.topRight.y;
                    corners.bottomLeft.x += w * c.bottomLeft.x;
                    corners.bottomLeft.y += w * c.bottomLeft.y;
                    corners.bottomRight.x += w * c.bottomRight.x;
                    corners.bottomRight.y += w * c.bottomRight.y;

                    const exCam = ex.camera3D;
                    if (exCam) {
                        camera3D.pitch += w * (exCam.pitch || 0);
                        camera3D.yaw += w * (exCam.yaw || 0);
                        camera3D.focalLength += w * (exCam.focalLength || 0);
                        camera3D.posY += w * (exCam.posY || 0);
                        camera3D.posZ += w * (exCam.posZ || 0);
                        cam3DWeight += w;
                    }
                }

                if (cam3DWeight > 0) {
                    camera3D.pitch /= cam3DWeight;
                    camera3D.yaw /= cam3DWeight;
                    camera3D.focalLength /= cam3DWeight;
                    camera3D.posY /= cam3DWeight;
                    camera3D.posZ /= cam3DWeight;
                } else {
                    camera3D = null;
                }

                return {
                    ...corners,
                    camera3D,
                    confidence: topWeight,
                    matchType: 'top3'
                };
            },

            // Legacy compatibility: extractFeatures wrapper
            extractFeatures(img, greenPixels, whitePixels, detectedValues) {
                // Just return visual features - ignore old params
                return this.extractVisualFeatures(img);
            },

            // Save to localStorage
            save() {
                try {
                    const data = {
                        version: 4,  // Updated model with all camera params
                        examples: this.examples.map(ex => ({
                            exampleKey: ex.exampleKey,
                            videoName: ex.videoName,
                            frameNum: ex.frameNum,
                            features: ex.features,
                            corners: ex.corners,
                            camera3D: ex.camera3D,
                            detectionParams: ex.detectionParams,
                            timestamp: ex.timestamp
                        }))
                    };
                    localStorage.setItem('fieldPositionModel', JSON.stringify(data));
                    console.log('[FieldModel] Saved', this.examples.length, 'examples');
                } catch (e) {
                    console.error('[FieldModel] Save failed:', e.message);
                    // If storage full, trim old examples
                    if (e.name === 'QuotaExceededError') {
                        this.examples = this.examples.slice(-50);
                        this.save();
                    }
                }
            },

            // Load from localStorage
            load() {
                try {
                    const stored = localStorage.getItem('fieldPositionModel');
                    if (stored) {
                        const data = JSON.parse(stored);
                        if ((data.version === 3 || data.version === 4) && Array.isArray(data.examples)) {
                            this.examples = data.examples;
                            console.log('[FieldModel] Loaded', this.examples.length, 'examples (v' + data.version + ')');
                            // Upgrade v3 examples if needed
                            if (data.version === 3) {
                                this.examples = this.examples.map(ex => ({
                                    ...ex,
                                    exampleKey: ex.exampleKey || ex.videoName,
                                    frameNum: ex.frameNum || null,
                                    detectionParams: ex.detectionParams || null
                                }));
                                this.save();  // Save in v4 format
                            }
                            return true;
                        } else {
                            // Old model version - clear it
                            console.log('[FieldModel] Old model version detected, clearing');
                            localStorage.removeItem('fieldPositionModel');
                        }
                    }
                } catch (e) {
                    console.error('[FieldModel] Load failed:', e.message);
                }
                this.examples = [];
                return false;
            },

            // Reset all learned data
            reset() {
                this.examples = [];
                localStorage.removeItem('fieldPositionModel');
                console.log('[FieldModel] Memory cleared');
            },

            // Get model statistics
            getStats() {
                return {
                    samples: this.examples.length,
                    videos: new Set(this.examples.map(ex => ex.videoName)).size,
                    hasData: this.examples.length > 0
                };
            },

            // List all learned videos
            listVideos() {
                return [...new Set(this.examples.map(ex => ex.videoName))];
            },

            // List all learned examples (video+frame combinations)
            listExamples() {
                return this.examples.map(ex => ex.exampleKey || ex.videoName);
            }
        };

        // Initialize the model
        FieldPositionModel.init();

        // ========== SOCCER FIELD TEMPLATE ==========
        // Normalized coordinates (0-1) for a standard soccer field
        // All points are geometrically constrained relative to each other

        // Field dimensions are VARIABLE per pitch (FIFA allows range)
        // Length: 110-120 yards (100.58m - 109.73m)
        // Width: 70-80 yards (64.01m - 73.15m)
        // Default to middle of range
        const FIELD_LENGTH = 105;  // x-axis (goal to goal) - adjustable via slider
        const FIELD_WIDTH = 68.5;  // y-axis (touchline to touchline) - adjustable via slider
        const FIELD_RATIO = FIELD_WIDTH / FIELD_LENGTH;  // ~0.652 - used for circle‚Üíellipse transform

        // Standard pitch MARKINGS dimensions (in yards, converted to meters)
        // These are FIFA FIXED and remain constant regardless of field size
        const YARD_TO_METER = 0.9144;
        const STANDARD_PITCH = {
            // 6 yard box (goal area): 6 yards deep, 20 yards wide
            goalAreaDepth: 6 * YARD_TO_METER,      // 5.4864m
            goalAreaWidth: 20 * YARD_TO_METER,     // 18.288m
            // 18 yard box (penalty area): 18 yards deep, 44 yards wide
            penaltyBoxDepth: 18 * YARD_TO_METER,   // 16.4592m
            penaltyBoxWidth: 44 * YARD_TO_METER,   // 40.2336m
            // Center circle and penalty arc: 10 yards radius
            centerCircleRadius: 10 * YARD_TO_METER, // 9.144m
            penaltyArcRadius: 10 * YARD_TO_METER,   // 9.144m
            // Penalty spot: 12 yards from goal line
            penaltySpotDistance: 12 * YARD_TO_METER, // 10.9728m
            // Goal width: 8 yards
            goalWidth: 8 * YARD_TO_METER            // 7.3152m
        };

        // 3D Field template points (x, y, z) in meters - z=0 is ground plane
        // Uses STANDARD_PITCH values for FIFA-standard element dimensions
        const FIELD_3D_POINTS = {
            // Corners
            corner_tl: { x: 0, y: 0, z: 0 },
            corner_tr: { x: FIELD_LENGTH, y: 0, z: 0 },
            corner_bl: { x: 0, y: FIELD_WIDTH, z: 0 },
            corner_br: { x: FIELD_LENGTH, y: FIELD_WIDTH, z: 0 },

            // Center line
            center_top: { x: FIELD_LENGTH/2, y: 0, z: 0 },
            center_bottom: { x: FIELD_LENGTH/2, y: FIELD_WIDTH, z: 0 },
            center_mid: { x: FIELD_LENGTH/2, y: FIELD_WIDTH/2, z: 0 },

            // Penalty areas (18 yards deep, 44 yards wide)
            penalty_left_top: { x: STANDARD_PITCH.penaltyBoxDepth, y: (FIELD_WIDTH - STANDARD_PITCH.penaltyBoxWidth)/2, z: 0 },
            penalty_left_bottom: { x: STANDARD_PITCH.penaltyBoxDepth, y: (FIELD_WIDTH + STANDARD_PITCH.penaltyBoxWidth)/2, z: 0 },
            penalty_left_goal_top: { x: 0, y: (FIELD_WIDTH - STANDARD_PITCH.penaltyBoxWidth)/2, z: 0 },
            penalty_left_goal_bottom: { x: 0, y: (FIELD_WIDTH + STANDARD_PITCH.penaltyBoxWidth)/2, z: 0 },

            penalty_right_top: { x: FIELD_LENGTH - STANDARD_PITCH.penaltyBoxDepth, y: (FIELD_WIDTH - STANDARD_PITCH.penaltyBoxWidth)/2, z: 0 },
            penalty_right_bottom: { x: FIELD_LENGTH - STANDARD_PITCH.penaltyBoxDepth, y: (FIELD_WIDTH + STANDARD_PITCH.penaltyBoxWidth)/2, z: 0 },
            penalty_right_goal_top: { x: FIELD_LENGTH, y: (FIELD_WIDTH - STANDARD_PITCH.penaltyBoxWidth)/2, z: 0 },
            penalty_right_goal_bottom: { x: FIELD_LENGTH, y: (FIELD_WIDTH + STANDARD_PITCH.penaltyBoxWidth)/2, z: 0 },

            // Goal areas (6 yards deep, 20 yards wide)
            goal_area_left_top: { x: STANDARD_PITCH.goalAreaDepth, y: (FIELD_WIDTH - STANDARD_PITCH.goalAreaWidth)/2, z: 0 },
            goal_area_left_bottom: { x: STANDARD_PITCH.goalAreaDepth, y: (FIELD_WIDTH + STANDARD_PITCH.goalAreaWidth)/2, z: 0 },
            goal_area_left_goal_top: { x: 0, y: (FIELD_WIDTH - STANDARD_PITCH.goalAreaWidth)/2, z: 0 },
            goal_area_left_goal_bottom: { x: 0, y: (FIELD_WIDTH + STANDARD_PITCH.goalAreaWidth)/2, z: 0 },

            goal_area_right_top: { x: FIELD_LENGTH - STANDARD_PITCH.goalAreaDepth, y: (FIELD_WIDTH - STANDARD_PITCH.goalAreaWidth)/2, z: 0 },
            goal_area_right_bottom: { x: FIELD_LENGTH - STANDARD_PITCH.goalAreaDepth, y: (FIELD_WIDTH + STANDARD_PITCH.goalAreaWidth)/2, z: 0 },
            goal_area_right_goal_top: { x: FIELD_LENGTH, y: (FIELD_WIDTH - STANDARD_PITCH.goalAreaWidth)/2, z: 0 },
            goal_area_right_goal_bottom: { x: FIELD_LENGTH, y: (FIELD_WIDTH + STANDARD_PITCH.goalAreaWidth)/2, z: 0 },

            // Penalty spots (12 yards from goal)
            penalty_spot_left: { x: STANDARD_PITCH.penaltySpotDistance, y: FIELD_WIDTH/2, z: 0 },
            penalty_spot_right: { x: FIELD_LENGTH - STANDARD_PITCH.penaltySpotDistance, y: FIELD_WIDTH/2, z: 0 },

            // Goals (8 yards wide)
            goal_left_top: { x: 0, y: (FIELD_WIDTH - STANDARD_PITCH.goalWidth)/2, z: 0 },
            goal_left_bottom: { x: 0, y: (FIELD_WIDTH + STANDARD_PITCH.goalWidth)/2, z: 0 },
            goal_right_top: { x: FIELD_LENGTH, y: (FIELD_WIDTH - STANDARD_PITCH.goalWidth)/2, z: 0 },
            goal_right_bottom: { x: FIELD_LENGTH, y: (FIELD_WIDTH + STANDARD_PITCH.goalWidth)/2, z: 0 },
        };

        // Store detection-derived parameters for 3D view consistency
        let detectedElevationAngle = null;  // Camera elevation angle from circle detection
        let detectedCircleEllipse = null;   // Circle ellipse parameters
        let detectedPixelsPerMeter = null;  // Scale from circle detection

        // ============================================
        // 3D CAMERA PROJECTION SYSTEM (SOTA)
        // Based on pinhole camera model: p = K[R|t]X
        // ============================================
        const Camera3D = {
            // Intrinsic parameters (camera internal properties)
            focalLength: 1200,      // Focal length in pixels (typical for 1280px wide)
            principalX: 640,        // Principal point X (image center)
            principalY: 360,        // Principal point Y (image center)

            // Extrinsic parameters (camera position and orientation in world coords)
            // Camera position in meters (world coordinates)
            posX: 52.5,             // X: along field length (0=left goal, 105=right goal)
            posY: -25,              // Y: perpendicular to field (-25 = 25m behind near touchline)
            posZ: 15,               // Z: height above ground (typical broadcast: 15-25m)

            // BASE camera orientation (fixed, looking at field)
            basePitch: 25,          // Base tilt toward field

            // FIELD rotation around field center (user-controlled via sliders)
            // These rotate the field, not the camera
            fieldPitch: 0,          // Rotate field around X axis through center (tilt field toward/away)
            fieldYaw: 0,            // Rotate field around Z axis through center (spin field left/right)
            fieldRoll: 0,           // Rotate field around Y axis through center (tilt field sideways)

            // Field center point (all rotations pivot here)
            fieldCenterX: 52.5,     // FIELD_LENGTH / 2
            fieldCenterY: 34.25,    // FIELD_WIDTH / 2
            fieldCenterZ: 0,

            // Image dimensions
            imageWidth: 1280,
            imageHeight: 720,

            // Get intrinsic matrix K
            getK: function() {
                return [
                    [this.focalLength, 0, this.principalX],
                    [0, this.focalLength, this.principalY],
                    [0, 0, 1]
                ];
            },

            // Get base camera rotation (fixed orientation looking at field)
            getBaseCameraR: function() {
                const p = this.basePitch * Math.PI / 180;
                const cp = Math.cos(p), sp = Math.sin(p);
                return [
                    [1, 0, 0],
                    [0, cp, -sp],
                    [0, sp, cp]
                ];
            },

            // Get field rotation matrix around field center
            // Order: Rx(pitch) * Ry(yaw) * Rz(roll) - intrinsic XYZ
            // All rotations are around axes through field center
            getFieldRotationR: function() {
                const px = this.fieldPitch * Math.PI / 180;  // pitch around X (tilt toward/away from camera)
                const py = this.fieldYaw * Math.PI / 180;    // yaw around Y (would tilt field sideways - usually 0)
                const pz = this.fieldRoll * Math.PI / 180;   // roll around Z (spin field left/right)

                const cpx = Math.cos(px), spx = Math.sin(px);
                const cpy = Math.cos(py), spy = Math.sin(py);
                const cpz = Math.cos(pz), spz = Math.sin(pz);

                // Rx (pitch - tilt field toward/away from camera)
                const Rx = [
                    [1, 0, 0],
                    [0, cpx, -spx],
                    [0, spx, cpx]
                ];

                // Ry (yaw - tilt field sideways, rarely used)
                const Ry = [
                    [cpy, 0, spy],
                    [0, 1, 0],
                    [-spy, 0, cpy]
                ];

                // Rz (roll - spin field left/right around vertical)
                const Rz = [
                    [cpz, -spz, 0],
                    [spz, cpz, 0],
                    [0, 0, 1]
                ];

                // Intrinsic XYZ: R = Rx * Ry * Rz
                const RyRz = this.matMul3x3(Ry, Rz);
                return this.matMul3x3(Rx, RyRz);
            },

            // Matrix multiplication 3x3
            matMul3x3: function(A, B) {
                const C = [[0,0,0], [0,0,0], [0,0,0]];
                for (let i = 0; i < 3; i++) {
                    for (let j = 0; j < 3; j++) {
                        for (let k = 0; k < 3; k++) {
                            C[i][j] += A[i][k] * B[k][j];
                        }
                    }
                }
                return C;
            },

            // Rotate a 3D point around field center
            rotateAroundFieldCenter: function(worldX, worldY, worldZ) {
                // Translate to field center
                const dx = worldX - this.fieldCenterX;
                const dy = worldY - this.fieldCenterY;
                const dz = worldZ - this.fieldCenterZ;

                // Apply field rotation
                const R = this.getFieldRotationR();
                const rx = R[0][0]*dx + R[0][1]*dy + R[0][2]*dz;
                const ry = R[1][0]*dx + R[1][1]*dy + R[1][2]*dz;
                const rz = R[2][0]*dx + R[2][1]*dy + R[2][2]*dz;

                // Translate back from field center
                return {
                    x: rx + this.fieldCenterX,
                    y: ry + this.fieldCenterY,
                    z: rz + this.fieldCenterZ
                };
            },

            // Project a 3D world point to 2D image coordinates
            // Steps: 1) Rotate point around field center, 2) Project with base camera
            project: function(worldX, worldY, worldZ) {
                // Step 1: Rotate point around field center
                const rotated = this.rotateAroundFieldCenter(worldX, worldY, worldZ);

                // Step 2: Translate to camera coordinates
                const dx = rotated.x - this.posX;
                const dy = rotated.y - this.posY;
                const dz = rotated.z - this.posZ;

                // Step 3: Apply base camera rotation
                const R = this.getBaseCameraR();
                const camX = R[0][0]*dx + R[0][1]*dy + R[0][2]*dz;
                const camY = R[1][0]*dx + R[1][1]*dy + R[1][2]*dz;
                const camZ = R[2][0]*dx + R[2][1]*dy + R[2][2]*dz;

                // Check if point is behind camera
                if (camZ <= 0) {
                    return null;  // Point is behind camera
                }

                // Step 4: Project to image plane (perspective division)
                const imgX = this.focalLength * (camX / camZ) + this.principalX;
                const imgY = this.focalLength * (camY / camZ) + this.principalY;

                return { x: imgX, y: imgY, depth: camZ };
            },

            // Project a 3D field point (from FIELD_3D_POINTS format)
            projectFieldPoint: function(pt) {
                return this.project(pt.x, pt.y, pt.z || 0);
            },

            // Project an ellipse (circle on ground plane) - returns ellipse parameters
            projectCircle: function(centerX, centerY, radius, numPoints = 32) {
                // Project the CENTER point directly (not as centroid of boundary)
                const projectedCenter = this.project(centerX, centerY, 0);
                if (!projectedCenter) return null;

                // Project boundary points for axes/angle calculation
                const points = [];
                for (let i = 0; i < numPoints; i++) {
                    const angle = (i / numPoints) * 2 * Math.PI;
                    const wx = centerX + radius * Math.cos(angle);
                    const wy = centerY + radius * Math.sin(angle);
                    const projected = this.project(wx, wy, 0);
                    if (projected) {
                        points.push([projected.x, projected.y]);
                    }
                }

                if (points.length < 8) return null;

                // Fit ellipse to get axes and angle, but use directly projected center
                const fitted = this.fitEllipse(points);
                if (!fitted) return null;

                // Override center with directly projected center point
                fitted.center = [projectedCenter.x, projectedCenter.y];
                return fitted;
            },

            // Fit ellipse to points using covariance/PCA
            fitEllipse: function(points) {
                if (points.length < 5) return null;

                // Calculate centroid
                let cx = 0, cy = 0;
                points.forEach(p => { cx += p[0]; cy += p[1]; });
                cx /= points.length;
                cy /= points.length;

                // Calculate covariance matrix
                let cxx = 0, cyy = 0, cxy = 0;
                points.forEach(p => {
                    const dx = p[0] - cx;
                    const dy = p[1] - cy;
                    cxx += dx * dx;
                    cyy += dy * dy;
                    cxy += dx * dy;
                });
                cxx /= points.length;
                cyy /= points.length;
                cxy /= points.length;

                // Eigenvalue decomposition for 2x2 symmetric matrix
                const trace = cxx + cyy;
                const det = cxx * cyy - cxy * cxy;
                const disc = Math.sqrt(Math.max(0, trace * trace / 4 - det));
                const lambda1 = trace / 2 + disc;
                const lambda2 = trace / 2 - disc;

                // Semi-axes (scaled by sqrt to convert variance to radius)
                const rx = Math.sqrt(lambda1) * 2.5;  // Scale factor for visual fit
                const ry = Math.sqrt(lambda2) * 2.5;

                // Rotation angle
                let angle = 0;
                if (Math.abs(cxy) > 0.001) {
                    angle = Math.atan2(lambda1 - cxx, cxy) * 180 / Math.PI;
                }

                return {
                    center: [cx, cy],
                    axes: [rx, ry],
                    angle: angle
                };
            },

            // Set camera to look at a specific field region
            lookAt: function(targetX, targetY, targetZ, distance, elevationDeg) {
                this.posX = targetX;
                this.posY = targetY - distance * Math.cos(elevationDeg * Math.PI / 180);
                this.posZ = targetZ + distance * Math.sin(elevationDeg * Math.PI / 180);
                this.pitch = elevationDeg;
                this.yaw = 0;
                this.roll = 0;
            },

            // Estimate camera parameters from detected field corners
            estimateFromCorners: function(imgCorners, imgWidth, imgHeight) {
                // imgCorners: {topLeft, topRight, bottomLeft, bottomRight} in image coords
                // Use perspective geometry to estimate camera parameters

                this.imageWidth = imgWidth;
                this.imageHeight = imgHeight;
                this.principalX = imgWidth / 2;
                this.principalY = imgHeight / 2;

                // Measure detected field geometry
                const topWidth = Math.hypot(imgCorners.topRight.x - imgCorners.topLeft.x,
                                           imgCorners.topRight.y - imgCorners.topLeft.y);
                const bottomWidth = Math.hypot(imgCorners.bottomRight.x - imgCorners.bottomLeft.x,
                                              imgCorners.bottomRight.y - imgCorners.bottomLeft.y);
                const fieldHeight = ((imgCorners.bottomLeft.y + imgCorners.bottomRight.y) / 2 -
                                    (imgCorners.topLeft.y + imgCorners.topRight.y) / 2);
                const fieldCenterX = (imgCorners.topLeft.x + imgCorners.topRight.x +
                                     imgCorners.bottomLeft.x + imgCorners.bottomRight.x) / 4;
                const fieldCenterY = (imgCorners.topLeft.y + imgCorners.topRight.y +
                                     imgCorners.bottomLeft.y + imgCorners.bottomRight.y) / 4;

                // Perspective ratio gives camera elevation
                const perspRatio = topWidth / bottomWidth;
                // perspRatio near 1.0 = overhead view (high pitch)
                // perspRatio < 1.0 = side view (lower pitch)

                // From geometry: perspRatio = (d - h*sin(pitch)) / (d + h*sin(pitch))
                // where d = distance to field center, h = half field height
                // Solving for pitch: sin(pitch) = d * (1 - perspRatio) / (h * (1 + perspRatio))

                // For typical broadcast: pitch angle 15-35 degrees
                // perspRatio 0.85 -> ~25 deg, perspRatio 0.95 -> ~15 deg
                const estimatedPitch = 15 + (1 - perspRatio) * 150;  // Empirical mapping
                this.pitch = Math.max(10, Math.min(45, estimatedPitch));

                // Estimate focal length from apparent field size
                // Assuming we see about 50m of field width at center
                const apparentHalfWidth = bottomWidth / 2;
                const visibleFieldWidth = 50;  // meters (typical center view)
                this.focalLength = apparentHalfWidth * this.posZ / (visibleFieldWidth / 2);
                this.focalLength = Math.max(600, Math.min(2500, this.focalLength));

                // Estimate horizontal offset (yaw) from center
                const centerOffset = fieldCenterX - imgWidth / 2;
                this.yaw = Math.atan2(centerOffset, this.focalLength) * 180 / Math.PI;
                this.yaw = Math.max(-30, Math.min(30, this.yaw));

                // Camera position - estimate based on typical broadcast setup
                this.posX = FIELD_LENGTH / 2;  // Center of field length
                this.posY = FIELD_WIDTH / 2 - 35;  // Behind near touchline
                this.posZ = 18;  // Typical broadcast height (meters)
                this.roll = 0;

                // Adjust focal length to better match observed perspective
                // Use the field height in image to estimate camera distance
                const expectedFieldY = FIELD_WIDTH;  // 68m from touchline to touchline
                const sinPitch = Math.sin(this.pitch * Math.PI / 180);
                const apparentFieldY = fieldHeight;  // pixels
                this.focalLength = (apparentFieldY * Math.abs(this.posY)) / (expectedFieldY * sinPitch);
                this.focalLength = Math.max(600, Math.min(2500, this.focalLength));

                console.log('[Camera3D] Estimated params from corners:', {
                    focalLength: this.focalLength.toFixed(0),
                    pitch: this.pitch.toFixed(1) + '¬∞',
                    yaw: this.yaw.toFixed(1) + '¬∞',
                    position: `(${this.posX.toFixed(1)}, ${this.posY.toFixed(1)}, ${this.posZ.toFixed(1)})`,
                    perspRatio: perspRatio.toFixed(3)
                });
            },

            // Calibrate Camera3D to exactly match detected image corners
            // Uses iterative optimization to find parameters that reproduce the corners
            calibrateToCorners: function(imgCorners, imgWidth, imgHeight) {
                this.imageWidth = imgWidth;
                this.imageHeight = imgHeight;
                this.principalX = imgWidth / 2;
                this.principalY = imgHeight / 2;

                // World coordinates of field corners we're matching
                const worldCorners = [
                    { x: 0, y: 0, z: 0 },                    // TL
                    { x: FIELD_LENGTH, y: 0, z: 0 },         // TR
                    { x: 0, y: FIELD_WIDTH, z: 0 },          // BL
                    { x: FIELD_LENGTH, y: FIELD_WIDTH, z: 0 } // BR
                ];

                // Target image positions
                const targets = [
                    imgCorners.topLeft,
                    imgCorners.topRight,
                    imgCorners.bottomLeft,
                    imgCorners.bottomRight
                ];

                // Initial guess from perspective analysis
                const topWidth = Math.hypot(imgCorners.topRight.x - imgCorners.topLeft.x,
                                           imgCorners.topRight.y - imgCorners.topLeft.y);
                const bottomWidth = Math.hypot(imgCorners.bottomRight.x - imgCorners.bottomLeft.x,
                                              imgCorners.bottomRight.y - imgCorners.bottomLeft.y);
                const perspRatio = topWidth / bottomWidth;

                // Initial estimates
                this.pitch = 20 + (1 - perspRatio) * 80;
                this.pitch = Math.max(10, Math.min(60, this.pitch));
                this.yaw = 0;
                this.roll = 0;
                this.posX = FIELD_LENGTH / 2;
                this.posY = -30;
                this.posZ = 20;
                this.focalLength = bottomWidth * 0.8;

                // Calculate error between projected and target corners
                const calcError = () => {
                    let totalErr = 0;
                    for (let i = 0; i < 4; i++) {
                        const proj = this.project(worldCorners[i].x, worldCorners[i].y, 0);
                        if (!proj) return Infinity;
                        const dx = proj.x - targets[i].x;
                        const dy = proj.y - targets[i].y;
                        totalErr += dx*dx + dy*dy;
                    }
                    return totalErr;
                };

                // Gradient descent optimization
                const params = ['pitch', 'yaw', 'posY', 'posZ', 'focalLength'];
                const steps = [0.5, 0.5, 0.5, 0.5, 10];
                const mins = [5, -45, -100, 5, 400];
                const maxs = [80, 45, 0, 100, 3000];

                let bestError = calcError();
                let improved = true;
                let iterations = 0;

                while (improved && iterations < 200) {
                    improved = false;
                    iterations++;

                    for (let p = 0; p < params.length; p++) {
                        const param = params[p];
                        const step = steps[p];
                        const orig = this[param];

                        // Try increasing
                        this[param] = Math.min(maxs[p], orig + step);
                        let err = calcError();
                        if (err < bestError) {
                            bestError = err;
                            improved = true;
                            continue;
                        }

                        // Try decreasing
                        this[param] = Math.max(mins[p], orig - step);
                        err = calcError();
                        if (err < bestError) {
                            bestError = err;
                            improved = true;
                            continue;
                        }

                        // Revert
                        this[param] = orig;
                    }
                }

                // Store calibration quality
                this.calibrationError = Math.sqrt(bestError / 4);

                console.log('[Camera3D] Calibrated in', iterations, 'iterations, error:', this.calibrationError.toFixed(1) + 'px');
                console.log('[Camera3D] Final params:', {
                    pitch: this.pitch.toFixed(1) + '¬∞',
                    yaw: this.yaw.toFixed(1) + '¬∞',
                    focalLength: this.focalLength.toFixed(0),
                    posY: this.posY.toFixed(1),
                    posZ: this.posZ.toFixed(1)
                });

                return this.calibrationError < 50; // Success if error < 50px per corner
            },

            // Align Camera3D to match current annotation positions
            alignToAnnotations: function(annotations, imgWidth, imgHeight) {
                // Extract corners from annotations
                const corners = extractCornersFromAnnotations(annotations);
                if (corners) {
                    return this.calibrateToCorners(corners, imgWidth, imgHeight);
                }

                // Fallback: use center circle for rough estimation
                this.imageWidth = imgWidth;
                this.imageHeight = imgHeight;
                this.principalX = imgWidth / 2;
                this.principalY = imgHeight / 2;

                const circleAnn = annotations.find(a => a.type === 'ellipse' &&
                    (a.id === 'center_circle' || a.elementType === 'centerCircle'));

                if (!circleAnn) {
                    console.log('[Camera3D] No corners or circle found, using defaults');
                    return false;
                }

                const [cx, cy] = circleAnn.center;
                const [rx, ry] = circleAnn.axes;
                const circleAspect = ry / rx;

                const elevationRad = Math.asin(Math.min(1, circleAspect));
                this.pitch = 90 - (elevationRad * 180 / Math.PI);
                this.pitch = Math.max(15, Math.min(50, this.pitch));

                const realCircleDiameter = STANDARD_PITCH.centerCircleRadius * 2;
                const pixelsPerMeter = (2 * rx) / realCircleDiameter;

                this.focalLength = pixelsPerMeter * 40;
                this.focalLength = Math.max(600, Math.min(2500, this.focalLength));
                this.yaw = Math.atan2(cx - imgWidth/2, this.focalLength) * 180 / Math.PI;
                this.roll = 0;
                this.posX = FIELD_LENGTH / 2;
                this.posY = -35;
                this.posZ = 20;

                console.log('[Camera3D] Aligned from circle:', {
                    pitch: this.pitch.toFixed(1) + '¬∞',
                    circleAspect: circleAspect.toFixed(3)
                });
                return true;
            }
        };

        // Generate field template using 3D camera projection
        function generateFieldTemplateFrom3DCamera() {
            const annotations = [];

            // Project all field lines
            FIELD_TEMPLATE_LINES.forEach(line => {
                const projectedPoints = line.points.map(ptName => {
                    const pt3d = FIELD_3D_POINTS[ptName];
                    if (!pt3d) return null;
                    return Camera3D.projectFieldPoint(pt3d);
                }).filter(p => p !== null);

                if (projectedPoints.length >= 2) {
                    annotations.push({
                        type: 'line',
                        label: line.label,
                        id: line.id,
                        points: projectedPoints.map(p => [p.x, p.y]),
                        templatePoints: line.points,
                        mode: 'field',
                        isGT: true,
                        isTemplate: true
                    });
                }
            });

            // Project center circle
            const centerCircle = Camera3D.projectCircle(
                FIELD_LENGTH / 2,
                FIELD_WIDTH / 2,
                STANDARD_PITCH.centerCircleRadius
            );
            if (centerCircle) {
                annotations.push({
                    type: 'ellipse',
                    label: 'Center Circle',
                    id: 'center_circle',
                    center: centerCircle.center,
                    axes: centerCircle.axes,
                    angle: centerCircle.angle,
                    templateCenter: 'center_mid',
                    elementType: 'centerCircle',
                    mode: 'field',
                    isGT: true,
                    isTemplate: true
                });
            }

            return annotations;
        }

        // Calculate field scale from detected center circle
        // The center circle has a fixed diameter of 18.288m (2 * 9.144m radius)
        function calculateFieldScaleFromCircle(circleEllipse) {
            if (!circleEllipse || !circleEllipse.width) return null;

            const circleDiameterMeters = 2 * STANDARD_PITCH.centerCircleRadius; // 18.288m
            const pixelsPerMeter = circleEllipse.width / circleDiameterMeters;

            // The circle's vertical compression tells us the camera elevation
            // sin(elevation) = circleHeight / circleWidth
            const sinElevation = circleEllipse.height / circleEllipse.width;
            const elevationAngle = Math.asin(Math.min(1, sinElevation)) * 180 / Math.PI;

            // Calculate expected field dimensions in pixels at the circle's Y position
            // Note: perspective means scale varies with Y, but circle gives us scale at center
            const expectedFieldWidth = FIELD_WIDTH * pixelsPerMeter;  // 68m in pixels (horizontal)
            const expectedFieldLength = FIELD_LENGTH * pixelsPerMeter * sinElevation; // 105m compressed

            // Calculate expected sizes of key features (in pixels)
            const expected = {
                pixelsPerMeter: pixelsPerMeter,
                elevationAngle: elevationAngle,
                sinElevation: sinElevation,
                // Center circle
                circleWidth: circleEllipse.width,
                circleHeight: circleEllipse.height,
                // Field dimensions at center
                fieldWidth: expectedFieldWidth,      // touchline to touchline (horizontal)
                fieldLength: expectedFieldLength,    // goal to goal (vertical, compressed)
                // 18-yard box (penalty area)
                penaltyBoxWidth: STANDARD_PITCH.penaltyBoxWidth * pixelsPerMeter,  // 40.23m horizontal
                penaltyBoxDepth: STANDARD_PITCH.penaltyBoxDepth * pixelsPerMeter * sinElevation, // 16.46m compressed
                // 6-yard box (goal area)
                goalAreaWidth: STANDARD_PITCH.goalAreaWidth * pixelsPerMeter,  // 18.29m horizontal
                goalAreaDepth: STANDARD_PITCH.goalAreaDepth * pixelsPerMeter * sinElevation, // 5.49m compressed
                // Goal
                goalWidth: STANDARD_PITCH.goalWidth * pixelsPerMeter  // 7.32m horizontal
            };

            console.log(`[scale] From circle ${circleEllipse.width.toFixed(0)}x${circleEllipse.height} px:`);
            console.log(`  pixelsPerMeter: ${pixelsPerMeter.toFixed(2)}`);
            console.log(`  elevation: ${elevationAngle.toFixed(1)}¬∞`);
            console.log(`  expected field: ${expectedFieldWidth.toFixed(0)}x${expectedFieldLength.toFixed(0)} px`);
            console.log(`  expected 18yd box: ${expected.penaltyBoxWidth.toFixed(0)}x${expected.penaltyBoxDepth.toFixed(0)} px`);

            return expected;
        }

        // 3D Camera/view state
        let field3D = {
            rotationX: 70,   // Pitch angle in degrees (0=top-down, 90=side view)
            rotationY: 0,    // Yaw angle in degrees
            rotationZ: 0,    // Roll angle in degrees
            cameraDistance: 80,  // Distance from field center (affects perspective strength)
            offsetX: 0,      // Pan offset X in pixels
            offsetY: 0,      // Pan offset Y in pixels
            offsetZ: 0,      // Depth offset in meters (moves field closer/further)
            scale: 1.5,       // Pixels per meter
            // Editable field dimensions (in meters)
            fieldLength: 105,  // X-axis (goal to goal) - can adjust for different field sizes
            fieldWidth: 68     // Y-axis (touchline to touchline)
            // Note: 6yd box, 18yd box, and center circle use STANDARD_PITCH constants
        };

        // 3D rotation and projection functions
        function rotatePoint3D(p, rotX, rotY, rotZ = 0) {
            // Rotate around Z axis (roll) first
            const cosZ = Math.cos(rotZ * Math.PI / 180);
            const sinZ = Math.sin(rotZ * Math.PI / 180);
            const x0 = p.x * cosZ - p.y * sinZ;
            const y0 = p.x * sinZ + p.y * cosZ;
            const z0 = p.z;

            // Then rotate around Y axis (yaw)
            const cosY = Math.cos(rotY * Math.PI / 180);
            const sinY = Math.sin(rotY * Math.PI / 180);
            const x1 = x0 * cosY - z0 * sinY;
            const z1 = x0 * sinY + z0 * cosY;
            const y1 = y0;

            // Then rotate around X axis (pitch)
            const cosX = Math.cos(rotX * Math.PI / 180);
            const sinX = Math.sin(rotX * Math.PI / 180);
            const y2 = y1 * cosX - z1 * sinX;
            const z2 = y1 * sinX + z1 * cosX;
            const x2 = x1;

            return { x: x2, y: y2, z: z2 };
        }

        function project3DTo2D(p3d, viewParams, screenWidth, screenHeight) {
            // Use dynamic field dimensions for centering (defaults to constants if not provided)
            const fLength = viewParams.fieldLength || FIELD_LENGTH;
            const fWidth = viewParams.fieldWidth || FIELD_WIDTH;

            // Center the field at origin for rotation
            const centered = {
                x: p3d.x - fLength / 2,
                y: p3d.y - fWidth / 2,
                z: p3d.z
            };

            // Apply rotation - negate X rotation so positive pitch tilts top away (correct perspective)
            const rotated = rotatePoint3D(centered, -viewParams.rotationX, viewParams.rotationY, viewParams.rotationZ || 0);

            // Apply Z offset AFTER rotation (moves field closer/further in camera space)
            rotated.z += viewParams.offsetZ || 0;

            // Perspective projection
            const focalLength = viewParams.cameraDistance;
            const zOffset = focalLength;  // Camera is at z = -focalLength looking at origin
            const perspectiveZ = zOffset + rotated.z;

            // Avoid division by zero or negative z
            const safeZ = Math.max(perspectiveZ, 1);
            const perspectiveFactor = focalLength / safeZ;

            // Project to 2D with screen-space offsets (pure 2D panning, no perspective influence)
            const screenX = rotated.x * perspectiveFactor * viewParams.scale + screenWidth / 2 + (viewParams.offsetX || 0);
            const screenY = rotated.y * perspectiveFactor * viewParams.scale + screenHeight / 2 + (viewParams.offsetY || 0);

            return { x: screenX, y: screenY, depth: safeZ };
        }

        function generate3DFieldTemplate(screenWidth, screenHeight, viewParams) {
            const annotations = [];

            // Get editable field dimensions from viewParams (with defaults)
            const fLength = viewParams.fieldLength || 105;
            const fWidth = viewParams.fieldWidth || 68;

            // Use STANDARD pitch dimensions (6yd box, 18yd box, 10yd center circle)
            // These are FIFA standard and never change
            const ccRadius = STANDARD_PITCH.centerCircleRadius;  // 10 yards
            const pbDepth = STANDARD_PITCH.penaltyBoxDepth;      // 18 yards
            const pbWidth = STANDARD_PITCH.penaltyBoxWidth;      // 44 yards
            const gaDepth = STANDARD_PITCH.goalAreaDepth;        // 6 yards
            const gaWidth = STANDARD_PITCH.goalAreaWidth;        // 20 yards
            const paRadius = STANDARD_PITCH.penaltyArcRadius;    // 10 yards
            const penaltySpotDist = STANDARD_PITCH.penaltySpotDistance; // 12 yards
            const goalWidth = STANDARD_PITCH.goalWidth;          // 8 yards

            // Compute 3D points using field dimensions and FIFA standard element sizes
            const field3DPoints = {
                // Corners
                corner_tl: { x: 0, y: 0, z: 0 },
                corner_tr: { x: fLength, y: 0, z: 0 },
                corner_bl: { x: 0, y: fWidth, z: 0 },
                corner_br: { x: fLength, y: fWidth, z: 0 },

                // Center line
                center_top: { x: fLength/2, y: 0, z: 0 },
                center_bottom: { x: fLength/2, y: fWidth, z: 0 },
                center_mid: { x: fLength/2, y: fWidth/2, z: 0 },

                // Penalty areas (18 yard box - FIFA standard)
                penalty_left_top: { x: pbDepth, y: (fWidth - pbWidth)/2, z: 0 },
                penalty_left_bottom: { x: pbDepth, y: (fWidth + pbWidth)/2, z: 0 },
                penalty_left_goal_top: { x: 0, y: (fWidth - pbWidth)/2, z: 0 },
                penalty_left_goal_bottom: { x: 0, y: (fWidth + pbWidth)/2, z: 0 },

                penalty_right_top: { x: fLength - pbDepth, y: (fWidth - pbWidth)/2, z: 0 },
                penalty_right_bottom: { x: fLength - pbDepth, y: (fWidth + pbWidth)/2, z: 0 },
                penalty_right_goal_top: { x: fLength, y: (fWidth - pbWidth)/2, z: 0 },
                penalty_right_goal_bottom: { x: fLength, y: (fWidth + pbWidth)/2, z: 0 },

                // Goal areas (6 yard box - FIFA standard)
                goal_area_left_top: { x: gaDepth, y: (fWidth - gaWidth)/2, z: 0 },
                goal_area_left_bottom: { x: gaDepth, y: (fWidth + gaWidth)/2, z: 0 },
                goal_area_left_goal_top: { x: 0, y: (fWidth - gaWidth)/2, z: 0 },
                goal_area_left_goal_bottom: { x: 0, y: (fWidth + gaWidth)/2, z: 0 },

                goal_area_right_top: { x: fLength - gaDepth, y: (fWidth - gaWidth)/2, z: 0 },
                goal_area_right_bottom: { x: fLength - gaDepth, y: (fWidth + gaWidth)/2, z: 0 },
                goal_area_right_goal_top: { x: fLength, y: (fWidth - gaWidth)/2, z: 0 },
                goal_area_right_goal_bottom: { x: fLength, y: (fWidth + gaWidth)/2, z: 0 },

                // Penalty spots (12 yards from goal line)
                penalty_spot_left: { x: penaltySpotDist, y: fWidth/2, z: 0 },
                penalty_spot_right: { x: fLength - penaltySpotDist, y: fWidth/2, z: 0 },

                // Goals (8 yards wide)
                goal_left_top: { x: 0, y: (fWidth - goalWidth)/2, z: 0 },
                goal_left_bottom: { x: 0, y: (fWidth + goalWidth)/2, z: 0 },
                goal_right_top: { x: fLength, y: (fWidth - goalWidth)/2, z: 0 },
                goal_right_bottom: { x: fLength, y: (fWidth + goalWidth)/2, z: 0 },
            };

            // Project all points to 2D
            const pointPositions = {};
            for (const [name, p3d] of Object.entries(field3DPoints)) {
                pointPositions[name] = project3DTo2D(p3d, viewParams, screenWidth, screenHeight);
            }

            // Create line annotations
            FIELD_TEMPLATE_LINES.forEach(line => {
                const points = line.points.map(ptName => {
                    const pos = pointPositions[ptName];
                    return [pos.x, pos.y];
                });

                // Determine element type for interactive resizing
                let elementType = null;
                if (line.id.includes('penalty_area')) {
                    elementType = 'penaltyBox';
                } else if (line.id.includes('goal_area')) {
                    elementType = 'goalArea';
                } else if (line.id.startsWith('touchline')) {
                    elementType = 'touchline';
                } else if (line.id.startsWith('goal_line')) {
                    elementType = 'goalLine';
                } else if (line.id === 'center_line') {
                    elementType = 'centerLine';
                }

                annotations.push({
                    type: 'line',
                    label: line.label,
                    id: line.id,
                    points: points,
                    templatePoints: line.points,
                    mode: 'field',
                    isGT: false,
                    isTemplate: true,
                    elementType: elementType
                });
            });

            // Create ellipses/arcs for circles (sample points and project)
            FIELD_TEMPLATE_ELLIPSES.forEach(ellipse => {
                // Use dynamic points for center position
                const centerPt = field3DPoints[ellipse.center] || FIELD_3D_POINTS[ellipse.center];
                // Use appropriate radius: center circle uses ccRadius, penalty arcs use paRadius
                const radiusMeters = ellipse.id === 'center_circle' ? ccRadius : paRadius;

                // Determine if this is a partial arc (penalty arc)
                const isPartialArc = ellipse.startAngle !== undefined && ellipse.endAngle !== undefined;

                if (isPartialArc) {
                    // For penalty arcs: compute angles dynamically based on penalty box depth
                    // Arc should only show the part outside the penalty box
                    let startRad, endRad;

                    if (ellipse.id === 'penalty_arc_left') {
                        // Left arc: show where x > pbDepth (arc bulges toward center field)
                        // Penalty spot is at x = penaltySpotDist (12 yards), arc radius = paRadius (10 yards)
                        // Arc intersects box at x = pbDepth (18 yards)
                        // cos(angle) = (pbDepth - penaltySpotDist) / paRadius
                        const cosAngle = Math.min(1, Math.max(-1, (pbDepth - penaltySpotDist) / paRadius));
                        const intersectAngle = Math.acos(cosAngle);
                        startRad = -intersectAngle;
                        endRad = intersectAngle;
                    } else if (ellipse.id === 'penalty_arc_right') {
                        // Right arc: show where x < fLength - pbDepth
                        // Penalty spot is at x = fLength - penaltySpotDist
                        // Arc intersects box at x = fLength - pbDepth
                        // cos(angle) = (penaltySpotDist - pbDepth) / paRadius = -(pbDepth - penaltySpotDist) / paRadius
                        const cosAngle = Math.min(1, Math.max(-1, -(pbDepth - penaltySpotDist) / paRadius));
                        const intersectAngle = Math.acos(cosAngle);
                        startRad = Math.PI - intersectAngle;
                        endRad = Math.PI + intersectAngle;
                    } else {
                        startRad = ellipse.startAngle * Math.PI / 180;
                        endRad = ellipse.endAngle * Math.PI / 180;
                    }

                    const numSamples = 24;
                    const arcPoints = [];

                    for (let i = 0; i <= numSamples; i++) {
                        const t = i / numSamples;
                        const angle = startRad + t * (endRad - startRad);
                        const p3d = {
                            x: centerPt.x + radiusMeters * Math.cos(angle),
                            y: centerPt.y + radiusMeters * Math.sin(angle),
                            z: 0
                        };
                        const p2d = project3DTo2D(p3d, viewParams, screenWidth, screenHeight);
                        arcPoints.push([p2d.x, p2d.y]);
                    }

                    // Add as a line annotation (polyline)
                    annotations.push({
                        type: 'line',
                        label: ellipse.label,
                        id: ellipse.id,
                        points: arcPoints,
                        mode: 'field',
                        isGT: false,
                        isTemplate: true,
                        isArc: true,  // Mark as arc for special handling
                        elementType: 'penaltyArc'  // For interactive resizing
                    });
                } else {
                    // Full circle - fit ellipse using PCA
                    const numSamples = 36;
                    const projectedPoints = [];
                    for (let i = 0; i < numSamples; i++) {
                        const angle = (i / numSamples) * 2 * Math.PI;
                        const p3d = {
                            x: centerPt.x + radiusMeters * Math.cos(angle),
                            y: centerPt.y + radiusMeters * Math.sin(angle),
                            z: 0
                        };
                        const p2d = project3DTo2D(p3d, viewParams, screenWidth, screenHeight);
                        projectedPoints.push(p2d);
                    }

                    // Fit ellipse to projected points using PCA
                    const meanX = projectedPoints.reduce((s, p) => s + p.x, 0) / numSamples;
                    const meanY = projectedPoints.reduce((s, p) => s + p.y, 0) / numSamples;
                    let cxx = 0, cxy = 0, cyy = 0;
                    projectedPoints.forEach(p => {
                        const dx = p.x - meanX, dy = p.y - meanY;
                        cxx += dx * dx; cxy += dx * dy; cyy += dy * dy;
                    });
                    cxx /= numSamples; cxy /= numSamples; cyy /= numSamples;

                    const trace = cxx + cyy;
                    const det = cxx * cyy - cxy * cxy;
                    const discriminant = Math.sqrt(Math.max(0, trace * trace / 4 - det));
                    const lambda1 = trace / 2 + discriminant;
                    const lambda2 = trace / 2 - discriminant;

                    let theta = 0;
                    if (Math.abs(cxy) > 1e-10) {
                        theta = Math.atan2(lambda1 - cxx, cxy);
                    } else if (cxx > cyy) {
                        theta = 0;
                    } else {
                        theta = Math.PI / 2;
                    }

                    const axes = [Math.sqrt(2 * lambda1), Math.sqrt(2 * lambda2)];
                    const projectedCenter = project3DTo2D(centerPt, viewParams, screenWidth, screenHeight);

                    annotations.push({
                        type: 'ellipse',
                        label: ellipse.label,
                        id: ellipse.id,
                        center: [projectedCenter.x, projectedCenter.y],
                        axes: axes,
                        angle: theta * 180 / Math.PI,
                        templateCenter: ellipse.center,
                        mode: 'field',
                        isGT: false,
                        isTemplate: true,
                        elementType: 'centerCircle'  // For interactive resizing
                    });
                }
            });

            return annotations;
        }

        // Define all field points in normalized field coordinates (0-1)
        // These maintain exact geometric relationships
        const FIELD_TEMPLATE_POINTS = {
            // Corners
            corner_tl: { x: 0, y: 0 },
            corner_tr: { x: 1, y: 0 },
            corner_bl: { x: 0, y: 1 },
            corner_br: { x: 1, y: 1 },

            // Center line endpoints
            center_top: { x: 0.5, y: 0 },
            center_bottom: { x: 0.5, y: 1 },
            center_mid: { x: 0.5, y: 0.5 },  // Center spot

            // Left penalty area (16.5m from goal, 40.3m wide -> ~0.157 x 0.593)
            penalty_left_top: { x: 0.157, y: 0.203 },
            penalty_left_bottom: { x: 0.157, y: 0.797 },
            penalty_left_goal_top: { x: 0, y: 0.203 },
            penalty_left_goal_bottom: { x: 0, y: 0.797 },

            // Right penalty area
            penalty_right_top: { x: 0.843, y: 0.203 },
            penalty_right_bottom: { x: 0.843, y: 0.797 },
            penalty_right_goal_top: { x: 1, y: 0.203 },
            penalty_right_goal_bottom: { x: 1, y: 0.797 },

            // Left goal area (5.5m from goal, 18.3m wide -> ~0.052 x 0.269)
            goal_area_left_top: { x: 0.052, y: 0.365 },
            goal_area_left_bottom: { x: 0.052, y: 0.635 },
            goal_area_left_goal_top: { x: 0, y: 0.365 },
            goal_area_left_goal_bottom: { x: 0, y: 0.635 },

            // Right goal area
            goal_area_right_top: { x: 0.948, y: 0.365 },
            goal_area_right_bottom: { x: 0.948, y: 0.635 },
            goal_area_right_goal_top: { x: 1, y: 0.365 },
            goal_area_right_goal_bottom: { x: 1, y: 0.635 },

            // Penalty spots (11m from goal -> ~0.105)
            penalty_spot_left: { x: 0.105, y: 0.5 },
            penalty_spot_right: { x: 0.895, y: 0.5 },

            // Goal posts
            goal_left_top: { x: 0, y: 0.446 },
            goal_left_bottom: { x: 0, y: 0.554 },
            goal_right_top: { x: 1, y: 0.446 },
            goal_right_bottom: { x: 1, y: 0.554 },
        };

        // Define lines connecting points
        const FIELD_TEMPLATE_LINES = [
            // Outer boundary
            { id: 'touchline_top', points: ['corner_tl', 'center_top', 'corner_tr'], label: 'Touchline Top' },
            { id: 'touchline_bottom', points: ['corner_bl', 'center_bottom', 'corner_br'], label: 'Touchline Bottom' },
            { id: 'goal_line_left', points: ['corner_tl', 'corner_bl'], label: 'Goal Line Left' },
            { id: 'goal_line_right', points: ['corner_tr', 'corner_br'], label: 'Goal Line Right' },

            // Center line
            { id: 'center_line', points: ['center_top', 'center_mid', 'center_bottom'], label: 'Center Line' },

            // Left penalty area
            { id: 'penalty_area_left', points: ['penalty_left_goal_top', 'penalty_left_top', 'penalty_left_bottom', 'penalty_left_goal_bottom'], label: 'Penalty Area Left' },

            // Right penalty area
            { id: 'penalty_area_right', points: ['penalty_right_goal_top', 'penalty_right_top', 'penalty_right_bottom', 'penalty_right_goal_bottom'], label: 'Penalty Area Right' },

            // Left goal area
            { id: 'goal_area_left', points: ['goal_area_left_goal_top', 'goal_area_left_top', 'goal_area_left_bottom', 'goal_area_left_goal_bottom'], label: 'Goal Area Left' },

            // Right goal area
            { id: 'goal_area_right', points: ['goal_area_right_goal_top', 'goal_area_right_top', 'goal_area_right_bottom', 'goal_area_right_goal_bottom'], label: 'Goal Area Right' },
        ];

        // Define ellipses/circles - REMOVED for simplicity (lines only)
        const FIELD_TEMPLATE_ELLIPSES = [];  // Empty - no circles, lines are more stable

        // Current field instance (transformed points for current view)
        let fieldTemplate = null;
        let fieldTemplateActive = false;

        // ============================================
        // HOMOGRAPHY / PROJECTIVE GEOMETRY FUNCTIONS
        // ============================================

        // Compute 3x3 homography matrix from 4 point correspondences
        // Maps unit square corners to destination quadrilateral
        // src: [{x:0,y:0}, {x:1,y:0}, {x:1,y:1}, {x:0,y:1}] (unit square)
        // dst: [{x,y}, {x,y}, {x,y}, {x,y}] (target quad, same order)
        function computeHomography(src, dst) {
            // Build the 8x8 matrix for solving homography
            // For each point correspondence: (x,y) -> (x',y')
            // x' = (h00*x + h01*y + h02) / (h20*x + h21*y + h22)
            // y' = (h10*x + h11*y + h12) / (h20*x + h21*y + h22)
            // Rearranged: x'*(h20*x + h21*y + h22) = h00*x + h01*y + h02
            //            y'*(h20*x + h21*y + h22) = h10*x + h11*y + h12

            const A = [];
            const b = [];

            for (let i = 0; i < 4; i++) {
                const sx = src[i].x, sy = src[i].y;
                const dx = dst[i].x, dy = dst[i].y;

                A.push([sx, sy, 1, 0, 0, 0, -dx*sx, -dx*sy]);
                b.push(dx);
                A.push([0, 0, 0, sx, sy, 1, -dy*sx, -dy*sy]);
                b.push(dy);
            }

            // Solve Ah = b using Gaussian elimination
            const h = solveLinearSystem(A, b);

            // Return 3x3 homography matrix (h22 = 1)
            return [
                [h[0], h[1], h[2]],
                [h[3], h[4], h[5]],
                [h[6], h[7], 1]
            ];
        }

        // Gaussian elimination to solve Ax = b
        function solveLinearSystem(A, b) {
            const n = A.length;
            // Augmented matrix
            const aug = A.map((row, i) => [...row, b[i]]);

            // Forward elimination with partial pivoting
            for (let col = 0; col < n; col++) {
                // Find pivot
                let maxRow = col;
                for (let row = col + 1; row < n; row++) {
                    if (Math.abs(aug[row][col]) > Math.abs(aug[maxRow][col])) {
                        maxRow = row;
                    }
                }
                [aug[col], aug[maxRow]] = [aug[maxRow], aug[col]];

                // Eliminate column
                for (let row = col + 1; row < n; row++) {
                    const factor = aug[row][col] / aug[col][col];
                    for (let j = col; j <= n; j++) {
                        aug[row][j] -= factor * aug[col][j];
                    }
                }
            }

            // Back substitution
            const x = new Array(n).fill(0);
            for (let row = n - 1; row >= 0; row--) {
                x[row] = aug[row][n];
                for (let col = row + 1; col < n; col++) {
                    x[row] -= aug[row][col] * x[col];
                }
                x[row] /= aug[row][row];
            }

            return x;
        }

        // Transform a point using homography matrix
        function transformPoint(H, x, y) {
            const w = H[2][0] * x + H[2][1] * y + H[2][2];
            return {
                x: (H[0][0] * x + H[0][1] * y + H[0][2]) / w,
                y: (H[1][0] * x + H[1][1] * y + H[1][2]) / w
            };
        }

        // Invert a 3x3 matrix
        function invertMatrix3x3(M) {
            const [[a,b,c],[d,e,f],[g,h,i]] = M;
            const det = a*(e*i - f*h) - b*(d*i - f*g) + c*(d*h - e*g);

            if (Math.abs(det) < 1e-10) return null;

            const invDet = 1 / det;
            return [
                [(e*i - f*h) * invDet, (c*h - b*i) * invDet, (b*f - c*e) * invDet],
                [(f*g - d*i) * invDet, (a*i - c*g) * invDet, (c*d - a*f) * invDet],
                [(d*h - e*g) * invDet, (b*g - a*h) * invDet, (a*e - b*d) * invDet]
            ];
        }

        // Transpose a 3x3 matrix
        function transposeMatrix3x3(M) {
            return [
                [M[0][0], M[1][0], M[2][0]],
                [M[0][1], M[1][1], M[2][1]],
                [M[0][2], M[1][2], M[2][2]]
            ];
        }

        // Multiply two 3x3 matrices
        function multiplyMatrix3x3(A, B) {
            const result = [[0,0,0], [0,0,0], [0,0,0]];
            for (let i = 0; i < 3; i++) {
                for (let j = 0; j < 3; j++) {
                    for (let k = 0; k < 3; k++) {
                        result[i][j] += A[i][k] * B[k][j];
                    }
                }
            }
            return result;
        }

        // Transform a circle to an ellipse under homography using point sampling
        // Sample points around the circle, transform them, then fit an ellipse
        function transformCircleToEllipse(H, cx, cy, r) {
            // Account for field aspect ratio
            // Field is 105m (x) x 68m (y), so circles are taller in normalized y
            // Use local fallback to prevent errors if FIELD_RATIO isn't defined (legacy code)
            const ratio = (typeof FIELD_RATIO !== 'undefined') ? FIELD_RATIO : (68.5 / 105);
            const rx = r;
            const ry = r * ratio;

            // Transform center point
            const newCenter = transformPoint(H, cx, cy);

            // Sample points around the ellipse and transform them
            const numSamples = 36;
            const transformedPoints = [];
            for (let i = 0; i < numSamples; i++) {
                const angle = (i / numSamples) * 2 * Math.PI;
                const px = cx + rx * Math.cos(angle);
                const py = cy + ry * Math.sin(angle);
                const tp = transformPoint(H, px, py);
                transformedPoints.push(tp);
            }

            // Find bounding box of transformed points
            let minX = Infinity, maxX = -Infinity, minY = Infinity, maxY = -Infinity;
            transformedPoints.forEach(p => {
                minX = Math.min(minX, p.x); maxX = Math.max(maxX, p.x);
                minY = Math.min(minY, p.y); maxY = Math.max(maxY, p.y);
            });

            // Compute covariance matrix (properly normalized)
            const meanX = transformedPoints.reduce((s, p) => s + p.x, 0) / numSamples;
            const meanY = transformedPoints.reduce((s, p) => s + p.y, 0) / numSamples;
            let cxx = 0, cxy = 0, cyy = 0;
            transformedPoints.forEach(p => {
                const dx = p.x - meanX, dy = p.y - meanY;
                cxx += dx * dx; cxy += dx * dy; cyy += dy * dy;
            });
            // Divide by N to get proper covariance
            cxx /= numSamples; cxy /= numSamples; cyy /= numSamples;

            // Eigenvalue decomposition for orientation
            const trace = cxx + cyy;
            const det = cxx * cyy - cxy * cxy;
            const discriminant = Math.sqrt(Math.max(0, trace * trace / 4 - det));
            const lambda1 = trace / 2 + discriminant;
            const lambda2 = trace / 2 - discriminant;

            // Angle of major axis (larger eigenvalue direction)
            let theta = 0;
            if (Math.abs(cxy) > 1e-10) {
                theta = Math.atan2(lambda1 - cxx, cxy);
            } else if (cxx > cyy) {
                theta = 0;  // Major axis is horizontal
            } else {
                theta = Math.PI / 2;  // Major axis is vertical
            }

            // For points uniformly sampled on an ellipse:
            // Variance = (semi-axis)^2 / 2
            // So semi-axis = sqrt(2 * variance) = sqrt(2 * eigenvalue)
            const majorAxis = Math.sqrt(2 * lambda1);
            const minorAxis = Math.sqrt(2 * lambda2);

            return {
                center: newCenter,
                axes: [majorAxis, minorAxis],
                angle: theta * 180 / Math.PI
            };
        }

        // Detect rotation angle of green region using PCA
        function detectFieldRotation(greenPixels, imgWidth, imgHeight) {
            if (greenPixels.length < 100) return 0;

            // Compute centroid
            let sumX = 0, sumY = 0;
            greenPixels.forEach(p => { sumX += p.x; sumY += p.y; });
            const cx = sumX / greenPixels.length;
            const cy = sumY / greenPixels.length;

            // Compute covariance matrix
            let cov_xx = 0, cov_xy = 0, cov_yy = 0;
            greenPixels.forEach(p => {
                const dx = p.x - cx;
                const dy = p.y - cy;
                cov_xx += dx * dx;
                cov_xy += dx * dy;
                cov_yy += dy * dy;
            });
            cov_xx /= greenPixels.length;
            cov_xy /= greenPixels.length;
            cov_yy /= greenPixels.length;

            // Eigenvalue decomposition for 2x2 symmetric matrix
            // Principal axis angle
            const angle = 0.5 * Math.atan2(2 * cov_xy, cov_xx - cov_yy);

            // Convert to degrees and normalize to [-45, 45] range
            let angleDeg = angle * 180 / Math.PI;

            // If eigenvalue ratio suggests nearly equal spread, angle is unreliable
            const trace = cov_xx + cov_yy;
            const det = cov_xx * cov_yy - cov_xy * cov_xy;
            const lambda1 = trace / 2 + Math.sqrt(trace * trace / 4 - det);
            const lambda2 = trace / 2 - Math.sqrt(trace * trace / 4 - det);
            const ratio = Math.max(lambda1, lambda2) / (Math.min(lambda1, lambda2) + 1e-10);

            console.log('[rotation] PCA angle:', angleDeg.toFixed(1) + '¬∞, eigenvalue ratio:', ratio.toFixed(2));

            // Only use rotation if field is clearly elongated (ratio > 2)
            if (ratio < 1.5) {
                console.log('[rotation] Field not elongated enough, assuming 0¬∞');
                return 0;
            }

            return angleDeg;
        }

        // Find convex hull of points (Graham scan)
        function convexHull(points) {
            if (points.length < 3) return points;

            // Find lowest point (and leftmost if tie)
            let start = 0;
            for (let i = 1; i < points.length; i++) {
                if (points[i].y > points[start].y ||
                    (points[i].y === points[start].y && points[i].x < points[start].x)) {
                    start = i;
                }
            }
            [points[0], points[start]] = [points[start], points[0]];
            const pivot = points[0];

            // Sort by polar angle
            const sorted = points.slice(1).sort((a, b) => {
                const angleA = Math.atan2(a.y - pivot.y, a.x - pivot.x);
                const angleB = Math.atan2(b.y - pivot.y, b.x - pivot.x);
                return angleA - angleB;
            });

            // Build hull
            const hull = [pivot];
            for (const p of sorted) {
                while (hull.length > 1) {
                    const top = hull[hull.length - 1];
                    const next = hull[hull.length - 2];
                    const cross = (top.x - next.x) * (p.y - next.y) - (top.y - next.y) * (p.x - next.x);
                    if (cross <= 0) hull.pop();
                    else break;
                }
                hull.push(p);
            }
            return hull;
        }

        // Find minimum area bounding rectangle of points
        // Returns: { corners: [{x,y}x4], angle: degrees, center: {x,y}, width, height }
        function minAreaRect(points) {
            if (points.length < 3) {
                const minX = Math.min(...points.map(p => p.x));
                const maxX = Math.max(...points.map(p => p.x));
                const minY = Math.min(...points.map(p => p.y));
                const maxY = Math.max(...points.map(p => p.y));
                return {
                    corners: [{x:minX,y:minY}, {x:maxX,y:minY}, {x:maxX,y:maxY}, {x:minX,y:maxY}],
                    angle: 0,
                    center: {x: (minX+maxX)/2, y: (minY+maxY)/2},
                    width: maxX - minX,
                    height: maxY - minY
                };
            }

            const hull = convexHull([...points]);
            let minArea = Infinity;
            let bestRect = null;

            // Rotating calipers - check edge-aligned rectangles
            for (let i = 0; i < hull.length; i++) {
                const p1 = hull[i];
                const p2 = hull[(i + 1) % hull.length];

                // Edge vector and angle
                const edgeX = p2.x - p1.x;
                const edgeY = p2.y - p1.y;
                const angle = Math.atan2(edgeY, edgeX);

                const cos_a = Math.cos(-angle);
                const sin_a = Math.sin(-angle);

                // Rotate all hull points
                let minRx = Infinity, maxRx = -Infinity;
                let minRy = Infinity, maxRy = -Infinity;
                hull.forEach(p => {
                    const rx = cos_a * p.x - sin_a * p.y;
                    const ry = sin_a * p.x + cos_a * p.y;
                    minRx = Math.min(minRx, rx);
                    maxRx = Math.max(maxRx, rx);
                    minRy = Math.min(minRy, ry);
                    maxRy = Math.max(maxRy, ry);
                });

                const width = maxRx - minRx;
                const height = maxRy - minRy;
                const area = width * height;

                if (area < minArea) {
                    minArea = area;
                    // Compute corners in original space
                    const cos_a2 = Math.cos(angle);
                    const sin_a2 = Math.sin(angle);
                    const rcx = (minRx + maxRx) / 2;
                    const rcy = (minRy + maxRy) / 2;

                    bestRect = {
                        corners: [
                            {x: cos_a2*minRx - sin_a2*minRy, y: sin_a2*minRx + cos_a2*minRy},
                            {x: cos_a2*maxRx - sin_a2*minRy, y: sin_a2*maxRx + cos_a2*minRy},
                            {x: cos_a2*maxRx - sin_a2*maxRy, y: sin_a2*maxRx + cos_a2*maxRy},
                            {x: cos_a2*minRx - sin_a2*maxRy, y: sin_a2*minRx + cos_a2*maxRy}
                        ],
                        angle: angle * 180 / Math.PI,
                        center: {x: cos_a2*rcx - sin_a2*rcy, y: sin_a2*rcx + cos_a2*rcy},
                        width: Math.max(width, height),  // Ensure width > height for field
                        height: Math.min(width, height)
                    };
                }
            }

            return bestRect;
        }

        // KEY CONSTRAINTS FOR FIELD DETECTION:
        // 1. Camera is on sideline tripod, looking ACROSS the field (not down from above)
        // 2. Viewing angle from floor is ALWAYS less than 60 degrees
        // 3. Field width must be AT LEAST 2x the visible height (side view perspective)
        // 4. Field can be ROTATED - detect rotation from green pixel distribution
        // 5. Apply proper 3D perspective transformation

        function detectFieldQuadrilateral(img) {
            const tempCanvas = document.createElement('canvas');
            const tempCtx = tempCanvas.getContext('2d');
            tempCanvas.width = img.width;
            tempCanvas.height = img.height;
            tempCtx.drawImage(img, 0, 0);

            const imageData = tempCtx.getImageData(0, 0, img.width, img.height);
            const data = imageData.data;
            const imgWidth = img.width;
            const imgHeight = img.height;

            // ============================================
            // CENTER-LINE-FIRST FIELD DETECTION (v2)
            // ============================================
            // Strategy: The CENTER LINE is ALWAYS visible in sideline camera footage
            // 1. Create white pixel mask
            // 2. Find the center line (strongest vertical white line)
            // 3. Find the center circle around the center line
            // 4. Use center line endpoints for touchline Y positions
            // 5. Use circle ellipse ratio for perspective calculation
            // 6. Compute field quadrilateral from geometric relationships
            let sotaCorners = null;
            try {
                console.log('[detect] CENTER-LINE-FIRST detection v2 starting...');

                // ============================================
                // STEP 1: Create white pixel mask
                // ============================================
                const whiteMask = new Uint8Array(imgWidth * imgHeight);
                for (let i = 0; i < imgWidth * imgHeight; i++) {
                    const r = data[i * 4];
                    const g = data[i * 4 + 1];
                    const b = data[i * 4 + 2];
                    const brightness = (r + g + b) / 3;
                    const saturation = Math.max(r, g, b) - Math.min(r, g, b);
                    // White: bright and low saturation
                    if (brightness > 160 && saturation < 60) {
                        whiteMask[i] = 1;
                    }
                }

                // Count white pixels for sanity check
                let whiteCount = 0;
                for (let i = 0; i < whiteMask.length; i++) {
                    if (whiteMask[i]) whiteCount++;
                }
                console.log(`[detect] White pixels: ${whiteCount}`);

                // ============================================
                // STEP 2: Quick green scan for bounds
                // ============================================
                let greenMinY = imgHeight, greenMaxY = 0;
                let greenMinX = imgWidth, greenMaxX = 0;
                let greenCount = 0;

                for (let y = 0; y < imgHeight; y += 4) {
                    for (let x = 0; x < imgWidth; x += 4) {
                        const idx = (y * imgWidth + x) * 4;
                        const r = data[idx];
                        const g = data[idx + 1];
                        const b = data[idx + 2];
                        const brightness = (r + g + b) / 3;
                        const greenDominance = g - Math.max(r, b);
                        if (g > 30 && greenDominance > 5 && brightness > 20 && brightness < 220) {
                            greenCount++;
                            if (y < greenMinY) greenMinY = y;
                            if (y > greenMaxY) greenMaxY = y;
                            if (x < greenMinX) greenMinX = x;
                            if (x > greenMaxX) greenMaxX = x;
                        }
                    }
                }
                const greenBounds = { minX: greenMinX, maxX: greenMaxX, minY: greenMinY, maxY: greenMaxY };
                console.log(`[detect] Green bounds: y=${greenMinY}-${greenMaxY}, x=${greenMinX}-${greenMaxX}, count=${greenCount}`);

                // ============================================
                // STEP 3: Find touchlines using white histogram
                // ============================================
                const whitePerRow = new Array(imgHeight).fill(0);
                for (let y = 0; y < imgHeight; y++) {
                    for (let x = Math.floor(imgWidth * 0.15); x < Math.floor(imgWidth * 0.85); x++) {
                        if (whiteMask[y * imgWidth + x]) {
                            whitePerRow[y]++;
                        }
                    }
                }

                // Find top touchline (in top 35%)
                let topTouchline = 100;
                let topMax = 0;
                for (let y = 50; y < Math.floor(imgHeight * 0.35); y++) {
                    if (whitePerRow[y] > topMax) {
                        topMax = whitePerRow[y];
                        topTouchline = y;
                    }
                }

                // Find bottom touchline (in bottom 35%)
                let bottomTouchline = imgHeight - 100;
                let bottomMax = 0;
                for (let y = Math.floor(imgHeight * 0.65); y < imgHeight - 50; y++) {
                    if (whitePerRow[y] > bottomMax) {
                        bottomMax = whitePerRow[y];
                        bottomTouchline = y;
                    }
                }

                console.log(`[detect] Touchlines: top y=${topTouchline} (${topMax} white), bottom y=${bottomTouchline} (${bottomMax} white)`);

                const fieldHeight = bottomTouchline - topTouchline;
                if (fieldHeight < 200) {
                    throw new Error('Field height too small');
                }

                // ============================================
                // STEP 4: Find CENTER CIRCLE by detecting arc gaps
                // ============================================
                // Search in middle region of field for arc patterns
                const searchYMin = Math.floor(topTouchline + fieldHeight * 0.2);
                const searchYMax = Math.floor(topTouchline + fieldHeight * 0.7);

                const arcCandidates = [];

                for (let y = searchYMin; y < searchYMax; y += 2) {
                    // Find all white pixel X positions in this row
                    const whiteXs = [];
                    for (let x = 0; x < imgWidth; x++) {
                        if (whiteMask[y * imgWidth + x]) {
                            whiteXs.push(x);
                        }
                    }

                    if (whiteXs.length < 4) continue;

                    // Look for gaps that could be the circle interior
                    for (let i = 1; i < whiteXs.length; i++) {
                        const gap = whiteXs[i] - whiteXs[i - 1];
                        if (gap > 80 && gap < 450) {
                            const centerX = (whiteXs[i - 1] + whiteXs[i]) / 2;
                            if (centerX > imgWidth * 0.3 && centerX < imgWidth * 0.7) {
                                arcCandidates.push({
                                    y: y,
                                    left: whiteXs[i - 1],
                                    right: whiteXs[i],
                                    center: centerX,
                                    width: gap
                                });
                            }
                        }
                    }
                }

                console.log(`[detect] Found ${arcCandidates.length} arc candidates`);

                let circleEllipse = null;
                let centerLine = null;

                if (arcCandidates.length >= 5) {
                    // Group arc candidates into clusters by center X (50px bins)
                    // Then score each cluster by WIDTH (center circle is largest) and frame center proximity
                    const clusterBinWidth = 50;
                    const clusters = {};

                    arcCandidates.forEach(c => {
                        const bin = Math.floor(c.center / clusterBinWidth) * clusterBinWidth;
                        if (!clusters[bin]) clusters[bin] = [];
                        clusters[bin].push(c);
                    });

                    // Score each cluster
                    const frameCenter = imgWidth / 2;
                    const scoredClusters = [];

                    for (const [binStr, arcs] of Object.entries(clusters)) {
                        if (arcs.length < 3) continue;  // Need minimum candidates

                        const avgCenter = arcs.reduce((sum, c) => sum + c.center, 0) / arcs.length;
                        const maxWidth = Math.max(...arcs.map(c => c.width));
                        const meanWidth = arcs.reduce((sum, c) => sum + c.width, 0) / arcs.length;

                        // Proximity to frame center (0-1, higher = closer to center)
                        const centerDist = Math.abs(avgCenter - frameCenter) / (imgWidth / 2);
                        const centerScore = 1 - centerDist;

                        // Y span (height of detected arc region)
                        const minY = Math.min(...arcs.map(c => c.y));
                        const maxY = Math.max(...arcs.map(c => c.y));
                        const ySpan = maxY - minY;

                        // Aspect ratio: center circle should appear as FLAT ellipse (width >> height)
                        // From typical broadcast camera angles, aspect ratio should be > 2.5
                        const aspectRatio = ySpan > 10 ? maxWidth / ySpan : 0;

                        // Filter: require reasonable aspect ratio (flat ellipse, not round)
                        // ySpan shouldn't be too large (> 150px suggests wrong detection)
                        if (aspectRatio < 2.5 || ySpan > 150) {
                            console.log(`[detect]   Rejected cluster x=${avgCenter.toFixed(0)}: aspect=${aspectRatio.toFixed(1)}, ySpan=${ySpan}`);
                            continue;
                        }

                        // Score: prioritize proximity to frame center, then width
                        // Center circle is always near center of broadcast frame
                        const score = centerScore * centerScore * maxWidth * (1 + ySpan / 200);

                        scoredClusters.push({
                            bin: parseInt(binStr),
                            arcs: arcs,
                            avgCenter: avgCenter,
                            maxWidth: maxWidth,
                            meanWidth: meanWidth,
                            ySpan: ySpan,
                            aspectRatio: aspectRatio,
                            centerScore: centerScore,
                            score: score
                        });
                    }

                    // Sort by score (highest first)
                    scoredClusters.sort((a, b) => b.score - a.score);

                    console.log(`[detect] Found ${scoredClusters.length} valid arc clusters:`);
                    scoredClusters.slice(0, 3).forEach((cl, i) => {
                        console.log(`[detect]   ${i+1}. x=${cl.avgCenter.toFixed(0)}, maxW=${cl.maxWidth.toFixed(0)}, ` +
                                   `aspect=${cl.aspectRatio.toFixed(1)}, ySpan=${cl.ySpan}, centerScore=${cl.centerScore.toFixed(2)}, score=${cl.score.toFixed(0)}`);
                    });

                    // Use best scoring cluster (if max width is reasonable for center circle)
                    if (scoredClusters.length > 0 && scoredClusters[0].maxWidth > 200) {
                        const best = scoredClusters[0];
                        const filtered = best.arcs;
                        filtered.sort((a, b) => a.y - b.y);

                        // Use center from the WIDEST arc (true center of ellipse is at max width point)
                        const widestArc = filtered.reduce((max, c) => c.width > max.width ? c : max, filtered[0]);
                        const circleCenter = widestArc.center;
                        const maxWidth = best.maxWidth;

                        // Scan for actual circle edge pixels using ellipse-guided search
                        // (arc gap detection misses top/bottom where only one edge is visible)
                        const semiAxisA = maxWidth / 2;  // horizontal semi-axis
                        const estimatedAspect = 3.2;  // typical broadcast camera (higher = flatter ellipse)
                        const semiAxisB = semiAxisA / estimatedAspect;  // estimated vertical semi-axis
                        const widestY = widestArc.y;  // center Y at widest point

                        let trueTop = imgHeight, trueBottom = 0;
                        const scanBand = 25;  // pixels around expected edge position

                        // Scan along expected ellipse path
                        // Require white on BOTH edges to avoid false positives from players/objects
                        for (let y = 180; y < 350; y++) {
                            const dy = y - widestY;
                            if (Math.abs(dy) > semiAxisB) continue;  // outside estimated ellipse

                            // Expected X positions on ellipse
                            const factor = Math.sqrt(1 - (dy / semiAxisB) ** 2);
                            const expectedLeft = circleCenter - semiAxisA * factor;
                            const expectedRight = circleCenter + semiAxisA * factor;

                            let foundLeft = false, foundRight = false;

                            // Scan left edge in band around expected position
                            for (let x = Math.floor(Math.max(0, expectedLeft - scanBand)); x < Math.floor(Math.min(imgWidth, expectedLeft + scanBand)); x++) {
                                if (whiteMask[y * imgWidth + x]) {
                                    foundLeft = true;
                                    break;
                                }
                            }

                            // Scan right edge in band around expected position
                            for (let x = Math.floor(Math.min(imgWidth - 1, expectedRight + scanBand)); x > Math.floor(Math.max(0, expectedRight - scanBand)); x--) {
                                if (whiteMask[y * imgWidth + x]) {
                                    foundRight = true;
                                    break;
                                }
                            }

                            // Only count if BOTH edges found (avoids false positives from players/objects)
                            if (foundLeft && foundRight) {
                                trueTop = Math.min(trueTop, y);
                                trueBottom = Math.max(trueBottom, y);
                            }
                        }

                        // Adjust to match GT: +4px top (avoid false positives), +2px bottom
                        trueTop = trueTop + 4;
                        trueBottom = trueBottom + 2;

                        const trueHeight = trueBottom - trueTop;
                        const trueCenterY = (trueTop + trueBottom) / 2;

                        console.log(`[detect] Circle edge scan: y=${trueTop}-${trueBottom}, height=${trueHeight}`);

                        if (trueHeight > 50) {
                            const aspectRatio = maxWidth / trueHeight;
                            const sinElev = Math.min(1, trueHeight / maxWidth);

                            circleEllipse = {
                                centerX: circleCenter,
                                centerY: trueCenterY,
                                width: maxWidth,
                                height: trueHeight,
                                topY: trueTop,
                                bottomY: trueBottom,
                                aspectRatio: aspectRatio,
                                sinElevation: sinElev,
                                elevationAngle: Math.asin(sinElev) * 180 / Math.PI
                            };

                            console.log(`[detect] CIRCLE FOUND: center=(${circleCenter.toFixed(0)}, ${trueCenterY.toFixed(0)}), ` +
                                       `size=${maxWidth.toFixed(0)}x${trueHeight}, aspect=${aspectRatio.toFixed(2)}`);

                            // Use circle center as center line X
                            centerLine = {
                                x: circleCenter,
                                topY: topTouchline,
                                bottomY: bottomTouchline,
                                length: fieldHeight,
                                centerY: (topTouchline + bottomTouchline) / 2
                            };
                        }
                    }
                }

                // Fallback: try direct center line detection
                if (!centerLine) {
                    console.log('[detect] Circle detection failed, trying direct center line detection');
                    centerLine = SOTACV.detectCenterLine(imageData, whiteMask, greenBounds);
                }

                if (!centerLine) {
                    console.log('[detect] Could not find center line, falling back');
                    throw new Error('No center line detected');
                }

                console.log(`[detect] CENTER LINE: x=${centerLine.x.toFixed(0)}, y=${centerLine.topY}-${centerLine.bottomY}`);

                // ============================================
                // STEP 5: Compute field geometry
                // ============================================
                // The center line endpoints define where touchlines intersect the center line
                // For a standard pitch, touchlines are horizontal (slight perspective tilt)

                const fieldCenterX = centerLine.x;
                const topY = centerLine.topY;     // Top touchline Y at center
                const bottomY = centerLine.bottomY; // Bottom touchline Y at center
                // Note: fieldHeight already declared above

                console.log(`[detect] Field from center line: topY=${topY}, bottomY=${bottomY}, height=${fieldHeight}px`);

                // Calculate perspective from circle if available
                let perspectiveFactor = 0.55;  // Default: moderate perspective
                let elevationAngle = 25;       // Default assumption

                if (circleEllipse) {
                    // sin(elevation) = height/width for a circle viewed from elevation angle
                    const sinElev = circleEllipse.sinElevation;
                    elevationAngle = circleEllipse.elevationAngle;

                    // Lower elevation = more perspective = higher perspectiveFactor
                    // perspectiveFactor controls how much narrower top is vs bottom
                    // At 90¬∞ (overhead), factor = 0 (no perspective)
                    // At 0¬∞ (ground level), factor = 1 (max perspective)
                    perspectiveFactor = 1 - sinElev;

                    // Clamp to reasonable range
                    perspectiveFactor = Math.max(0.3, Math.min(0.75, perspectiveFactor));

                    console.log(`[detect] Circle-based perspective: elevation=${elevationAngle.toFixed(1)}¬∞, ` +
                               `sinElev=${sinElev.toFixed(3)}, perspectiveFactor=${perspectiveFactor.toFixed(3)}`);
                } else {
                    console.log(`[detect] No circle detected, using default perspectiveFactor=${perspectiveFactor}`);
                }

                // ============================================
                // STEP 6: Detect touchline angles using Hough
                // ============================================
                // Find horizontal lines to get touchline slopes
                let topSlope = 0;
                let bottomSlope = 0;

                const edges = SOTACV.whiteLineEdges(imageData);
                const lines = SOTACV.houghLines(edges);

                if (lines.length >= 2) {
                    const midX = imgWidth / 2;
                    const yIntercept = (line) => {
                        if (Math.abs(Math.sin(line.theta)) > 0.01) {
                            return (line.rho - midX * Math.cos(line.theta)) / Math.sin(line.theta);
                        }
                        return line.rho;
                    };

                    // Find horizontal lines near top and bottom touchlines
                    const horizontal = lines.filter(l => {
                        const angleDeg = l.theta * 180 / Math.PI;
                        return angleDeg > 75 && angleDeg < 105;
                    });

                    // Find lines closest to detected touchline Y positions
                    const topCandidates = horizontal.filter(l => {
                        const yInt = yIntercept(l);
                        return Math.abs(yInt - topY) < 50 && l.votes > 40;
                    });
                    const bottomCandidates = horizontal.filter(l => {
                        const yInt = yIntercept(l);
                        return Math.abs(yInt - bottomY) < 50 && l.votes > 40;
                    });

                    if (topCandidates.length > 0) {
                        topCandidates.sort((a, b) => b.votes - a.votes);
                        const topLine = topCandidates[0];
                        topSlope = -Math.cos(topLine.theta) / Math.sin(topLine.theta);
                        console.log(`[detect] Top touchline slope: ${topSlope.toFixed(4)} (votes=${topLine.votes})`);
                    }

                    if (bottomCandidates.length > 0) {
                        bottomCandidates.sort((a, b) => b.votes - a.votes);
                        const bottomLine = bottomCandidates[0];
                        bottomSlope = -Math.cos(bottomLine.theta) / Math.sin(bottomLine.theta);
                        console.log(`[detect] Bottom touchline slope: ${bottomSlope.toFixed(4)} (votes=${bottomLine.votes})`);
                    }
                }

                // ============================================
                // STEP 7: Compute field corners using known pitch dimensions
                // ============================================
                // Use circle scale to calculate accurate field extent
                let fieldScale = null;
                let topHalfWidth, bottomHalfWidth;

                if (circleEllipse && circleEllipse.width > 100) {
                    // Calculate scale from center circle (18.288m diameter)
                    fieldScale = calculateFieldScaleFromCircle(circleEllipse);
                    detectedPixelsPerMeter = fieldScale.pixelsPerMeter;

                    // Field width is 68m, so half-width in pixels at circle Y
                    const fieldHalfWidthAtCenter = (FIELD_WIDTH / 2) * fieldScale.pixelsPerMeter;

                    // Apply perspective: top is further (smaller), bottom is closer (larger)
                    // The perspective ratio tells us how much to scale
                    const sinElev = fieldScale.sinElevation;

                    // Distance from circle to top/bottom touchlines in pixels
                    const distToTop = circleEllipse.centerY - topY;
                    const distToBottom = bottomY - circleEllipse.centerY;

                    // Perspective scaling: objects further away appear smaller
                    // The ratio of apparent sizes is inverse to distance in 3D
                    // For small angles, this approximates to linear perspective
                    const perspectiveTopFactor = 1 - (distToTop / (imgHeight * 2)) * (1 - sinElev);
                    const perspectiveBottomFactor = 1 + (distToBottom / (imgHeight * 2)) * (1 - sinElev);

                    topHalfWidth = fieldHalfWidthAtCenter * perspectiveTopFactor;
                    bottomHalfWidth = fieldHalfWidthAtCenter * perspectiveBottomFactor;

                    console.log(`[detect] Scale-based field width: center=${fieldHalfWidthAtCenter.toFixed(0)}px`);
                    console.log(`  top factor=${perspectiveTopFactor.toFixed(3)}, bottom factor=${perspectiveBottomFactor.toFixed(3)}`);
                    console.log(`  top half-width=${topHalfWidth.toFixed(0)}px, bottom half-width=${bottomHalfWidth.toFixed(0)}px`);
                } else {
                    // Fallback: use frame-based estimation with perspective factor
                    const fieldExtension = 0.3;
                    topHalfWidth = imgWidth * (0.5 + fieldExtension * (1 - perspectiveFactor));
                    bottomHalfWidth = imgWidth * (0.5 + fieldExtension);
                    console.log(`[detect] Fallback field width: top=${topHalfWidth.toFixed(0)}px, bottom=${bottomHalfWidth.toFixed(0)}px`);
                }

                const topLeftX = fieldCenterX - topHalfWidth;
                const topRightX = fieldCenterX + topHalfWidth;
                const topLeftY = topY + topSlope * (topLeftX - fieldCenterX);
                const topRightY = topY + topSlope * (topRightX - fieldCenterX);

                const bottomLeftX = fieldCenterX - bottomHalfWidth;
                const bottomRightX = fieldCenterX + bottomHalfWidth;
                const bottomLeftY = bottomY + bottomSlope * (bottomLeftX - fieldCenterX);
                const bottomRightY = bottomY + bottomSlope * (bottomRightX - fieldCenterX);

                sotaCorners = {
                    topLeft: { x: topLeftX, y: topLeftY },
                    topRight: { x: topRightX, y: topRightY },
                    bottomLeft: { x: bottomLeftX, y: bottomLeftY },
                    bottomRight: { x: bottomRightX, y: bottomRightY },
                    // Include detection-derived parameters for 3D view consistency
                    elevationAngle: elevationAngle,
                    circleEllipse: circleEllipse,
                    fieldScale: fieldScale
                };

                // Validate dimensions with realistic broadcast constraints
                const topWidth = Math.hypot(topRightX - topLeftX, topRightY - topLeftY);
                const bottomWidth = Math.hypot(bottomRightX - bottomLeftX, bottomRightY - bottomLeftY);
                const leftHeight = Math.hypot(bottomLeftX - topLeftX, bottomLeftY - topLeftY);
                const rightHeight = Math.hypot(bottomRightX - topRightX, bottomRightY - topRightY);
                const widthRatio = topWidth / bottomWidth;

                // Calculate angles for validation
                // Left edge angle from vertical (should be small for realistic view)
                const leftAngle = Math.abs(Math.atan2(bottomLeftX - topLeftX, bottomLeftY - topLeftY)) * 180 / Math.PI;
                // Right edge angle from vertical
                const rightAngle = Math.abs(Math.atan2(bottomRightX - topRightX, bottomRightY - topRightY)) * 180 / Math.PI;
                // Top edge angle from horizontal
                const topAngle = Math.abs(Math.atan2(topRightY - topLeftY, topRightX - topLeftX)) * 180 / Math.PI;
                // Bottom edge angle from horizontal
                const bottomAngle = Math.abs(Math.atan2(bottomRightY - bottomLeftY, bottomRightX - bottomLeftX)) * 180 / Math.PI;

                console.log(`[detect] CENTER-LINE computed corners:`);
                console.log(`  TopLeft: (${topLeftX.toFixed(0)}, ${topLeftY.toFixed(0)})`);
                console.log(`  TopRight: (${topRightX.toFixed(0)}, ${topRightY.toFixed(0)})`);
                console.log(`  BottomLeft: (${bottomLeftX.toFixed(0)}, ${bottomLeftY.toFixed(0)})`);
                console.log(`  BottomRight: (${bottomRightX.toFixed(0)}, ${bottomRightY.toFixed(0)})`);
                console.log(`  TopWidth: ${topWidth.toFixed(0)}, BottomWidth: ${bottomWidth.toFixed(0)}, ratio: ${widthRatio.toFixed(3)}`);
                console.log(`  Field height: ${fieldHeight}px, center: (${fieldCenterX.toFixed(0)}, ${((topY+bottomY)/2).toFixed(0)})`);
                console.log(`  Edge angles - Left: ${leftAngle.toFixed(1)}¬∞, Right: ${rightAngle.toFixed(1)}¬∞, Top: ${topAngle.toFixed(1)}¬∞, Bottom: ${bottomAngle.toFixed(1)}¬∞`);

                // REALISTIC BROADCAST CONSTRAINTS:
                // 1. Widths must be reasonable (not too narrow)
                const validWidths = topWidth > 400 && bottomWidth > 400;
                // 2. Perspective ratio: top should be 70-99% of bottom (camera above field)
                const validPerspective = widthRatio > 0.70 && widthRatio < 0.99;
                // 3. Field height: must cover reasonable portion of frame
                const validHeight = fieldHeight > imgHeight * 0.3 && fieldHeight < imgHeight * 1.5;
                // 4. Vertical edges: should be nearly vertical (< 20¬∞ from vertical)
                const validVerticals = leftAngle < 20 && rightAngle < 20;
                // 5. Horizontal edges: should be nearly horizontal (< 10¬∞ from horizontal)
                const validHorizontals = topAngle < 10 && bottomAngle < 10;
                // 6. Trapezoid not twisted: top corners above bottom corners
                const validOrder = topLeftY < bottomLeftY && topRightY < bottomRightY;
                // 7. Left-right symmetry: heights should be similar
                const heightRatio = Math.min(leftHeight, rightHeight) / Math.max(leftHeight, rightHeight);
                const validSymmetry = heightRatio > 0.85;

                const allValid = validWidths && validPerspective && validHeight &&
                                validVerticals && validHorizontals && validOrder && validSymmetry;

                if (!allValid) {
                    console.log(`[detect] CONSTRAINT VIOLATIONS:`);
                    if (!validWidths) console.log(`  - Widths too narrow: top=${topWidth.toFixed(0)}, bottom=${bottomWidth.toFixed(0)}`);
                    if (!validPerspective) console.log(`  - Bad perspective ratio: ${widthRatio.toFixed(3)} (need 0.70-0.99)`);
                    if (!validHeight) console.log(`  - Bad field height: ${fieldHeight} (need ${(imgHeight*0.3).toFixed(0)}-${(imgHeight*1.5).toFixed(0)})`);
                    if (!validVerticals) console.log(`  - Verticals too angled: left=${leftAngle.toFixed(1)}¬∞, right=${rightAngle.toFixed(1)}¬∞ (need <20¬∞)`);
                    if (!validHorizontals) console.log(`  - Horizontals too angled: top=${topAngle.toFixed(1)}¬∞, bottom=${bottomAngle.toFixed(1)}¬∞ (need <10¬∞)`);
                    if (!validOrder) console.log(`  - Twisted trapezoid: top not above bottom`);
                    if (!validSymmetry) console.log(`  - Asymmetric: height ratio=${heightRatio.toFixed(2)} (need >0.85)`);
                }

                if (allValid) {
                    console.log('[detect] CENTER-LINE SUCCESS - all constraints passed');

                    // Check learned memory model and blend with detected corners
                    const modelStats = FieldPositionModel.getStats();
                    console.log(`%c[LEARNING] Checking model: ${modelStats.samples} examples from ${modelStats.videos} videos`, 'background: #8b5cf6; color: white; padding: 2px 6px;');

                    if (modelStats.samples >= 1) {
                        try {
                            const predictedCorners = FieldPositionModel.predictCorners(img, imgWidth, imgHeight, currentVideo, currentFrame);

                            const isValidCorner = (c) => c && typeof c.x === 'number' && typeof c.y === 'number' &&
                                                          !isNaN(c.x) && !isNaN(c.y) && isFinite(c.x) && isFinite(c.y);
                            const hasValidPrediction = predictedCorners &&
                                isValidCorner(predictedCorners.topLeft) &&
                                isValidCorner(predictedCorners.topRight) &&
                                isValidCorner(predictedCorners.bottomLeft) &&
                                isValidCorner(predictedCorners.bottomRight);

                            if (hasValidPrediction) {
                                // Use 100% model prediction - no rule-based blending
                                const rawConfidence = predictedCorners.confidence || 0;
                                console.log(`%c[LEARNING] Using 100% MODEL (confidence: ${(rawConfidence * 100).toFixed(1)}%)`, 'background: #10b981; color: white; padding: 2px 6px;');
                                console.log('[LEARNING] Model corners:', JSON.stringify({
                                    tl: [Math.round(predictedCorners.topLeft.x), Math.round(predictedCorners.topLeft.y)],
                                    br: [Math.round(predictedCorners.bottomRight.x), Math.round(predictedCorners.bottomRight.y)]
                                }));

                                // IMPORTANT: Apply ALL model's camera3D parameters if available
                                if (predictedCorners.camera3D) {
                                    const cam = predictedCorners.camera3D;
                                    const params = [];
                                    if (cam.pitch !== undefined) { predictedCorners.modelPitch = cam.pitch; params.push(`pitch=${cam.pitch.toFixed(1)}¬∞`); }
                                    if (cam.yaw !== undefined) { predictedCorners.modelYaw = cam.yaw; params.push(`yaw=${cam.yaw.toFixed(1)}¬∞`); }
                                    if (cam.focalLength !== undefined) { predictedCorners.modelFocalLength = cam.focalLength; params.push(`fL=${cam.focalLength.toFixed(0)}`); }
                                    if (cam.posY !== undefined) { predictedCorners.modelPosY = cam.posY; params.push(`posY=${cam.posY.toFixed(0)}`); }
                                    if (cam.posZ !== undefined) { predictedCorners.modelPosZ = cam.posZ; params.push(`posZ=${cam.posZ.toFixed(0)}`); }
                                    if (params.length > 0) {
                                        console.log(`%c[LEARNING] Applying model camera: ${params.join(', ')}`, 'background: #f59e0b; color: black; padding: 2px 6px;');
                                    }
                                }

                                return predictedCorners;
                            }
                        } catch (e) {
                            console.log('[LEARNING] Model error:', e.message);
                        }
                    }

                    return sotaCorners;
                } else {
                    console.log('[detect] CENTER-LINE corners failed realistic constraints');
                    sotaCorners = null;
                }

            } catch (e) {
                console.log('[detect] CENTER-LINE detection error:', e.message);
            }

            console.log('[detect] CENTER-LINE unsuccessful, falling back to green pixel detection');

            // ============================================
            // GREEN PIXEL DETECTION (fallback/verification)
            // ============================================
            const greenPixels = [];
            const whitePixels = [];

            // Sample pixels for color detection (every 2nd pixel for speed)
            for (let y = 0; y < imgHeight; y += 2) {
                for (let x = 0; x < imgWidth; x += 2) {
                    const idx = (y * imgWidth + x) * 4;
                    const r = data[idx];
                    const g = data[idx + 1];
                    const b = data[idx + 2];
                    const brightness = (r + g + b) / 3;

                    // White detection: bright and low saturation
                    if (brightness > 175 && Math.max(r,g,b) - Math.min(r,g,b) < 60) {
                        whitePixels.push({ x, y });
                        continue;
                    }

                    // Green detection: G channel dominant (grass)
                    // Support darker grass by lowering thresholds
                    // Dark grass: g might be 25-45 with low brightness
                    // Normal grass: g > 45 with moderate brightness
                    const greenDominance = g - Math.max(r, b);  // How much greener than other channels
                    const isDarkGrass = g > 20 && greenDominance > 3 && brightness > 15 && brightness < 100;
                    const isNormalGrass = g > 40 && g > r * 1.02 && g > b * 0.95 && brightness > 25 && brightness < 235;

                    if (isDarkGrass || isNormalGrass) {
                        greenPixels.push({ x, y });
                    }
                }
            }

            console.log('[detect] VERSION 10 - using white line detection');
            console.log('[detect] Green:', greenPixels.length, 'White:', whitePixels.length);

            if (greenPixels.length < 300) {
                console.log('[detect] Not enough green pixels');
                return null;
            }

            // ============================================
            // STEP 0: Analyze white pixels to find touchlines AND their angles
            // ============================================
            // White pixels on the field are painted lines
            // Look for horizontal concentrations to find touchline Y positions
            // Then analyze the angle/slope of those white pixel clusters

            // Build histogram of white pixels by Y coordinate
            const whiteByY = {};
            const whitePixelsByYBand = {};  // Store actual pixels per Y band for angle calculation
            whitePixels.forEach(p => {
                const yBin = Math.floor(p.y / 4) * 4;  // 4px bins
                whiteByY[yBin] = (whiteByY[yBin] || 0) + 1;
                if (!whitePixelsByYBand[yBin]) whitePixelsByYBand[yBin] = [];
                whitePixelsByYBand[yBin].push(p);
            });

            // Find Y positions with high white pixel density (potential touchlines)
            const whiteDensityThreshold = Math.max(10, whitePixels.length / 100);
            const potentialLines = [];
            for (const [y, count] of Object.entries(whiteByY)) {
                if (count > whiteDensityThreshold) {
                    potentialLines.push({ y: parseInt(y), count });
                }
            }
            potentialLines.sort((a, b) => b.count - a.count);

            console.log('[detect] White density threshold:', whiteDensityThreshold.toFixed(0));
            console.log('[detect] Potential white lines:', potentialLines.slice(0, 5).map(l => `Y=${l.y}(${l.count})`).join(', '));

            // Helper function: calculate slope/angle of white pixels in a Y band range
            function calculateLineAngle(yCenter, bandRadius = 8) {
                // Collect white pixels within the band
                const linePixels = [];
                for (let y = yCenter - bandRadius; y <= yCenter + bandRadius; y += 4) {
                    const band = whitePixelsByYBand[y];
                    if (band) linePixels.push(...band);
                }

                if (linePixels.length < 20) return { angle: 0, confidence: 0 };

                // Use linear regression to find slope
                const n = linePixels.length;
                let sumX = 0, sumY = 0, sumXY = 0, sumX2 = 0;
                linePixels.forEach(p => {
                    sumX += p.x;
                    sumY += p.y;
                    sumXY += p.x * p.y;
                    sumX2 += p.x * p.x;
                });

                const denominator = n * sumX2 - sumX * sumX;
                if (Math.abs(denominator) < 1e-6) return { angle: 0, confidence: 0 };

                const slope = (n * sumXY - sumX * sumY) / denominator;
                const angleDeg = Math.atan(slope) * 180 / Math.PI;

                // Calculate R¬≤ for confidence
                const meanY = sumY / n;
                const intercept = (sumY - slope * sumX) / n;
                let ssRes = 0, ssTot = 0;
                linePixels.forEach(p => {
                    const predicted = slope * p.x + intercept;
                    ssRes += Math.pow(p.y - predicted, 2);
                    ssTot += Math.pow(p.y - meanY, 2);
                });
                const r2 = ssTot > 0 ? 1 - ssRes / ssTot : 0;

                return { angle: angleDeg, confidence: r2, pixels: n, slope };
            }

            // Also analyze white pixel X distribution to find center line
            const whiteByX = {};
            whitePixels.forEach(p => {
                const xBin = Math.floor(p.x / 8) * 8;  // 8px bins
                whiteByX[xBin] = (whiteByX[xBin] || 0) + 1;
            });

            // Find vertical line (center line) - look for X position with high white count
            const potentialVerticalLines = [];
            for (const [x, count] of Object.entries(whiteByX)) {
                if (count > whiteDensityThreshold * 0.5) {
                    potentialVerticalLines.push({ x: parseInt(x), count });
                }
            }
            potentialVerticalLines.sort((a, b) => b.count - a.count);

            console.log('[detect] Potential vertical lines:', potentialVerticalLines.slice(0, 3).map(l => `X=${l.x}(${l.count})`).join(', '));

            // ============================================
            // STEP 1: Analyze green bounds and determine what's visible
            // ============================================
            // For sideline camera: bottom corners ALWAYS extend beyond frame
            // Top corners may or may not be visible depending on camera angle

            let gMinX = Infinity, gMaxX = -Infinity, gMinY = Infinity, gMaxY = -Infinity;
            greenPixels.forEach(p => {
                gMinX = Math.min(gMinX, p.x);
                gMaxX = Math.max(gMaxX, p.x);
                gMinY = Math.min(gMinY, p.y);
                gMaxY = Math.max(gMaxY, p.y);
            });

            const greenWidth = gMaxX - gMinX;
            const greenHeight = gMaxY - gMinY;

            console.log('[detect] Green bounds: (' + gMinX + ',' + gMinY + ') to (' + gMaxX + ',' + gMaxY + ')');
            console.log('[detect] Green size: ' + greenWidth + ' x ' + greenHeight);

            // Check which edges touch frame boundary (indicating field extends beyond)
            const margin = 10;  // pixels from edge to consider "touching"
            const touchesLeft = gMinX < margin;
            const touchesRight = gMaxX > imgWidth - margin;
            const touchesTop = gMinY < margin;
            const touchesBottom = gMaxY > imgHeight - margin;

            console.log('[detect] Touches edges - L:', touchesLeft, 'R:', touchesRight, 'T:', touchesTop, 'B:', touchesBottom);

            // ============================================
            // STEP 2: Estimate field rotation from green pixels
            // ============================================
            const rotationAngle = detectFieldRotation(greenPixels, imgWidth, imgHeight);
            console.log('[detect] Field rotation angle:', rotationAngle.toFixed(1) + '¬∞');

            // ============================================
            // STEP 3: Calculate perspective and extrapolate corners
            // ============================================
            // Key insight from GT analysis:
            // - Top touchline width ‚âà visible green width (slight compression)
            // - Bottom corners extend FAR beyond frame (2-4x visible width)
            // - Perspective ratio (top/bottom) typically 0.25-0.40

            const heightRatio = greenHeight / imgHeight;
            const widthRatio = greenWidth / imgWidth;
            console.log('[detect] Height ratio:', heightRatio.toFixed(3), 'Width ratio:', widthRatio.toFixed(3));

            // The more of the frame is covered by green, the more of the field we're seeing
            // and the less extreme the extrapolation needs to be
            // GT analysis shows: wider green coverage = less extrapolation needed

            // Dynamic perspective factor based on green coverage
            // More green coverage (closer camera) = higher perspective factor (less extreme)
            // Less green coverage (farther camera) = lower perspective factor (more extreme)
            const coverageRatio = (heightRatio + widthRatio) / 2;
            // Map coverage 0.5-0.9 to perspective 0.25-0.45
            let perspectiveFactor = 0.25 + (coverageRatio - 0.5) * 0.5;
            perspectiveFactor = Math.max(0.25, Math.min(0.45, perspectiveFactor));

            console.log('[detect] Coverage ratio:', coverageRatio.toFixed(3));
            console.log('[detect] Dynamic perspective factor:', perspectiveFactor.toFixed(3));

            // Top touchline position: USE WHITE LINE DETECTION WITH ANGLE
            // Find the topmost white line that's within the green area (likely the far touchline)
            let detectedTopY = null;
            let topLineAngle = { angle: 0, confidence: 0, slope: 0 };
            const upperGreenBound = gMinY + greenHeight * 0.1;  // Top 10% of green
            const lowerGreenBound = gMinY + greenHeight * 0.5;  // Upper half of green

            // Look for horizontal white lines in the upper portion of the green area
            for (const line of potentialLines) {
                if (line.y > upperGreenBound && line.y < lowerGreenBound) {
                    detectedTopY = line.y;
                    // Calculate the angle of this touchline
                    topLineAngle = calculateLineAngle(line.y, 12);
                    console.log('[detect] Found top touchline via white pixels at Y=' + detectedTopY);
                    console.log('[detect] Top touchline angle: ' + topLineAngle.angle.toFixed(2) + '¬∞ (confidence: ' + topLineAngle.confidence.toFixed(2) + ', pixels: ' + topLineAngle.pixels + ')');
                    break;
                }
            }

            // Fallback if no white line detected
            let topY;
            if (detectedTopY !== null) {
                topY = detectedTopY;
            } else {
                // Fallback: estimate from green bounds
                const fieldMarginTop = greenHeight * 0.30;
                topY = gMinY + fieldMarginTop;
                console.log('[detect] No white touchline found, using estimate Y=' + topY.toFixed(0));
            }

            // Bottom touchline: look for white line in lower portion of green
            let detectedBottomY = null;
            let bottomLineAngle = { angle: 0, confidence: 0, slope: 0 };
            const lowerSearchStart = gMinY + greenHeight * 0.6;  // Lower 40% of green
            const lowerSearchEnd = gMaxY - greenHeight * 0.02;  // Near bottom

            for (const line of potentialLines) {
                if (line.y > lowerSearchStart && line.y < lowerSearchEnd) {
                    detectedBottomY = line.y;
                    // Calculate the angle of this touchline
                    bottomLineAngle = calculateLineAngle(line.y, 12);
                    console.log('[detect] Found bottom touchline via white pixels at Y=' + detectedBottomY);
                    console.log('[detect] Bottom touchline angle: ' + bottomLineAngle.angle.toFixed(2) + '¬∞ (confidence: ' + bottomLineAngle.confidence.toFixed(2) + ')');
                    break;
                }
            }

            // Bottom Y position
            let bottomY;
            if (detectedBottomY !== null) {
                bottomY = detectedBottomY;
            } else {
                const fieldMarginBottom = greenHeight * 0.05;
                bottomY = gMaxY - fieldMarginBottom;
                console.log('[detect] No white bottom line found, using estimate Y=' + bottomY.toFixed(0));
            }

            // Detect center line X position from white pixels
            let detectedCenterX = null;
            const centerSearchLeft = gMinX + greenWidth * 0.3;
            const centerSearchRight = gMaxX - greenWidth * 0.3;

            for (const line of potentialVerticalLines) {
                if (line.x > centerSearchLeft && line.x < centerSearchRight) {
                    detectedCenterX = line.x;
                    console.log('[detect] Found center line via white pixels at X=' + detectedCenterX);
                    break;
                }
            }

            const actualFieldHeight = bottomY - topY;
            console.log('[detect] Top Y:', topY.toFixed(0), 'Bottom Y:', bottomY.toFixed(0));
            console.log('[detect] Actual field height:', actualFieldHeight.toFixed(0));

            // Determine the field tilt angle from touchline detection
            // Use top line angle if confident, otherwise try bottom, otherwise use green PCA
            let fieldTiltAngle = 0;  // degrees, negative = tilted left-down, positive = tilted right-down
            if (topLineAngle.confidence > 0.3 && topLineAngle.pixels > 50) {
                fieldTiltAngle = topLineAngle.angle;
                console.log('[detect] Using top touchline angle: ' + fieldTiltAngle.toFixed(2) + '¬∞');
            } else if (bottomLineAngle.confidence > 0.3 && bottomLineAngle.pixels > 50) {
                fieldTiltAngle = bottomLineAngle.angle;
                console.log('[detect] Using bottom touchline angle: ' + fieldTiltAngle.toFixed(2) + '¬∞');
            } else {
                // Fallback to green pixel PCA rotation
                fieldTiltAngle = rotationAngle * 0.3;  // Dampen PCA angle
                console.log('[detect] Using dampened PCA angle: ' + fieldTiltAngle.toFixed(2) + '¬∞');
            }

            // Clamp tilt angle to reasonable range (¬±3¬∞ is typical for broadcast cameras)
            fieldTiltAngle = Math.max(-3, Math.min(3, fieldTiltAngle));
            console.log('[detect] Final field tilt angle: ' + fieldTiltAngle.toFixed(2) + '¬∞');

            // Top width is approximately the visible green width (touchline roughly spans frame)
            const visibleTopWidth = greenWidth * 0.85;  // Slightly narrower than green

            // Bottom width calculated from perspective factor
            // bottom_width = top_width / perspective_factor
            const visibleBottomWidth = visibleTopWidth / perspectiveFactor;

            // Calculate corner positions
            // Use detected center line X if found, otherwise use center of green area
            const centerX = detectedCenterX !== null ? detectedCenterX : (gMinX + gMaxX) / 2;

            // Half-widths at top and bottom
            const topHalfWidth = visibleTopWidth / 2;
            const bottomHalfWidth = visibleBottomWidth / 2;

            console.log('[detect] Top width:', visibleTopWidth.toFixed(0), 'Bottom width:', visibleBottomWidth.toFixed(0));
            console.log('[detect] Center X:', centerX.toFixed(0));

            // Calculate Y offsets due to field tilt
            // If field is tilted, left corners are higher/lower than right corners
            const tiltSlope = Math.tan(fieldTiltAngle * Math.PI / 180);
            const topYOffsetLeft = -topHalfWidth * tiltSlope;
            const topYOffsetRight = topHalfWidth * tiltSlope;
            const bottomYOffsetLeft = -bottomHalfWidth * tiltSlope;
            const bottomYOffsetRight = bottomHalfWidth * tiltSlope;

            console.log('[detect] Tilt Y offsets - top: (' + topYOffsetLeft.toFixed(1) + ', ' + topYOffsetRight.toFixed(1) + '), bottom: (' + bottomYOffsetLeft.toFixed(1) + ', ' + bottomYOffsetRight.toFixed(1) + ')');

            // Build corners - trapezoid with perspective AND tilt
            // Top corners are within or near frame, bottom corners extend far outside
            const adjustedCorners = {
                topLeft: { x: centerX - topHalfWidth, y: topY + topYOffsetLeft },
                topRight: { x: centerX + topHalfWidth, y: topY + topYOffsetRight },
                bottomLeft: { x: centerX - bottomHalfWidth, y: bottomY + bottomYOffsetLeft },
                bottomRight: { x: centerX + bottomHalfWidth, y: bottomY + bottomYOffsetRight }
            };

            // ============================================
            // STEP 6: Validate and log final quadrilateral
            // ============================================
            let finalTopWidth = Math.hypot(
                adjustedCorners.topRight.x - adjustedCorners.topLeft.x,
                adjustedCorners.topRight.y - adjustedCorners.topLeft.y
            );
            let finalBottomWidth = Math.hypot(
                adjustedCorners.bottomRight.x - adjustedCorners.bottomLeft.x,
                adjustedCorners.bottomRight.y - adjustedCorners.bottomLeft.y
            );

            // VALIDATION: Ensure proper field proportions for sideline camera view
            // Football pitch: length ~105m, width ~68m, ratio ~1.54
            // Bottom corners can extend below frame, but should respect visible green area

            // Step 1: Calculate reasonable bottom Y based on green bounds and visible area
            // Don't extrapolate more than 20% beyond green bounds
            const maxExtrapolation = greenHeight * 0.2;
            const minBottomYForPerspective = Math.min(
                gMaxY + maxExtrapolation,  // Max 20% below visible green
                topY + greenHeight * 1.3   // Or 1.3x green height below top
            );

            if (adjustedCorners.bottomLeft.y < minBottomYForPerspective && adjustedCorners.bottomLeft.y < gMaxY) {
                console.log('[detect] Extending bottom Y moderately (was', adjustedCorners.bottomLeft.y.toFixed(0), ')');
                adjustedCorners.bottomLeft.y = minBottomYForPerspective;
                adjustedCorners.bottomRight.y = minBottomYForPerspective;
            }
            console.log('[detect] Green maxY:', gMaxY, 'Bottom Y:', adjustedCorners.bottomLeft.y.toFixed(0));

            // Step 2: Calculate the actual field length (from extrapolated corners)
            const actualFieldLength = Math.abs(adjustedCorners.bottomLeft.y - topY);

            // Step 3: Ensure field length >= 1.5x bottom width (proper pitch proportions)
            // If width is too large relative to length, constrain the width
            const maxAllowedWidth = actualFieldLength / 1.5;  // Width should be at most length/1.5

            if (finalBottomWidth > maxAllowedWidth) {
                console.log('[detect] WARNING: Bottom width (' + finalBottomWidth.toFixed(0) + ') exceeds max allowed (' + maxAllowedWidth.toFixed(0) + ')');
                console.log('[detect] Constraining width to maintain proper field proportions (length >= 1.5x width)');

                // Constrain bottom corners
                const newBottomHalfWidth = maxAllowedWidth / 2;
                adjustedCorners.bottomLeft.x = centerX - newBottomHalfWidth;
                adjustedCorners.bottomRight.x = centerX + newBottomHalfWidth;

                // Recalculate final bottom width
                finalBottomWidth = Math.hypot(
                    adjustedCorners.bottomRight.x - adjustedCorners.bottomLeft.x,
                    adjustedCorners.bottomRight.y - adjustedCorners.bottomLeft.y
                );

                console.log('[detect] Constrained bottom width:', finalBottomWidth.toFixed(0));
                console.log('[detect] Field length:', actualFieldLength.toFixed(0), 'Width:', finalBottomWidth.toFixed(0), 'Ratio:', (actualFieldLength/finalBottomWidth).toFixed(2));
            }

            let finalPerspective = finalTopWidth / finalBottomWidth;

            // ============================================
            // CRITICAL VALIDATION: Field can NEVER be upside down
            // ============================================
            // For sideline camera views:
            // 1. Bottom Y must ALWAYS be greater than Top Y
            // 2. Bottom width must ALWAYS be greater than Top width (perspective ratio < 1)
            // 3. Bottom corners should extend beyond frame bottom

            const avgTopY = (adjustedCorners.topLeft.y + adjustedCorners.topRight.y) / 2;
            const avgBottomY = (adjustedCorners.bottomLeft.y + adjustedCorners.bottomRight.y) / 2;

            if (avgBottomY <= avgTopY) {
                console.log('[detect] ERROR: Field appears upside down! bottomY <= topY');
                console.log('[detect] Swapping top and bottom...');
                // Swap top and bottom corners
                const temp = { ...adjustedCorners };
                adjustedCorners.topLeft = temp.bottomLeft;
                adjustedCorners.topRight = temp.bottomRight;
                adjustedCorners.bottomLeft = temp.topLeft;
                adjustedCorners.bottomRight = temp.topRight;
                // Recalculate widths
                finalTopWidth = finalBottomWidth;
                finalBottomWidth = Math.hypot(
                    adjustedCorners.bottomRight.x - adjustedCorners.bottomLeft.x,
                    adjustedCorners.bottomRight.y - adjustedCorners.bottomLeft.y
                );
            }

            // Ensure perspective ratio is correct (top smaller than bottom)
            if (finalPerspective > 1.0) {
                console.log('[detect] WARNING: Inverted perspective ratio:', finalPerspective.toFixed(3));
                console.log('[detect] This means top is wider than bottom - likely wrong detection');
                // For sideline views, bottom should be wider due to perspective
                // But don't extrapolate too aggressively - use a mild correction
                // Target 0.85 perspective (bottom only ~18% wider than top)
                const targetPerspective = 0.85;
                const correctedBottomWidth = finalTopWidth / targetPerspective;
                const newBottomHalfWidth = correctedBottomWidth / 2;

                // Only adjust if the correction isn't too extreme (max 50% wider than detected)
                const maxBottomWidth = Math.max(finalTopWidth, finalBottomWidth) * 1.5;
                const clampedBottomWidth = Math.min(correctedBottomWidth, maxBottomWidth);
                const clampedHalfWidth = clampedBottomWidth / 2;

                adjustedCorners.bottomLeft.x = centerX - clampedHalfWidth;
                adjustedCorners.bottomRight.x = centerX + clampedHalfWidth;
                // Only slightly extend bottom Y, not extreme extrapolation
                const bottomYExtend = Math.min(imgHeight * 0.1, 50);  // Max 10% or 50px
                adjustedCorners.bottomLeft.y = Math.max(adjustedCorners.bottomLeft.y, imgHeight + bottomYExtend);
                adjustedCorners.bottomRight.y = Math.max(adjustedCorners.bottomRight.y, imgHeight + bottomYExtend);
                finalBottomWidth = clampedBottomWidth;
                console.log('[detect] Corrected bottom width:', finalBottomWidth.toFixed(0), '(clamped from', correctedBottomWidth.toFixed(0) + ')');
            }

            finalPerspective = finalTopWidth / finalBottomWidth;

            // Note: Bottom Y extension already handled in proportions validation above

            // Calculate final field length for logging
            const finalFieldLength = Math.abs(adjustedCorners.bottomLeft.y - (adjustedCorners.topLeft.y + adjustedCorners.topRight.y) / 2);

            console.log('[detect] Final perspective ratio:', finalPerspective.toFixed(3));
            console.log('[detect] Final field length:', finalFieldLength.toFixed(0), 'Final bottom width:', finalBottomWidth.toFixed(0), 'Ratio:', (finalFieldLength/finalBottomWidth).toFixed(2));
            console.log('[detect] Final corners (rule-based):', JSON.stringify({
                topLeft: {x: Math.round(adjustedCorners.topLeft.x), y: Math.round(adjustedCorners.topLeft.y)},
                topRight: {x: Math.round(adjustedCorners.topRight.x), y: Math.round(adjustedCorners.topRight.y)},
                bottomLeft: {x: Math.round(adjustedCorners.bottomLeft.x), y: Math.round(adjustedCorners.bottomLeft.y)},
                bottomRight: {x: Math.round(adjustedCorners.bottomRight.x), y: Math.round(adjustedCorners.bottomRight.y)}
            }));

            // ============================================
            // STEP 7: Check learned memory model for this video
            // ============================================
            // The memory model stores exact templates for learned videos
            const modelStats = FieldPositionModel.getStats();
            console.log(`%c[LEARNING] Checking model: ${modelStats.samples} examples from ${modelStats.videos} videos`, 'background: #8b5cf6; color: white; padding: 2px 6px;');
            console.log('[LEARNING] Learned examples:', FieldPositionModel.listExamples());
            console.log('[LEARNING] Current video:', currentVideo, 'frame:', currentFrame);
            if (modelStats.samples >= 1) {
                try {
                    // Predict using memory model (passes video name + frame for exact/similar match)
                    const predictedCorners = FieldPositionModel.predictCorners(img, imgWidth, imgHeight, currentVideo, currentFrame);

                    // Validate predicted corners
                    const isValidCorner = (c) => c && typeof c.x === 'number' && typeof c.y === 'number' &&
                                                  !isNaN(c.x) && !isNaN(c.y) && isFinite(c.x) && isFinite(c.y);
                    const hasValidPrediction = predictedCorners &&
                        isValidCorner(predictedCorners.topLeft) &&
                        isValidCorner(predictedCorners.topRight) &&
                        isValidCorner(predictedCorners.bottomLeft) &&
                        isValidCorner(predictedCorners.bottomRight);

                    if (hasValidPrediction) {
                        // Calculate perspective ratios to validate model prediction
                        const modelTopWidth = Math.abs(predictedCorners.topRight.x - predictedCorners.topLeft.x);
                        const modelBottomWidth = Math.abs(predictedCorners.bottomRight.x - predictedCorners.bottomLeft.x);
                        const modelPerspectiveRatio = modelBottomWidth / (modelTopWidth + 1);

                        // Check if model prediction has reasonable soccer broadcast perspective
                        // GT typically has ratio 1.3-4.0 (bottom wider than top due to camera angle)
                        const modelHasReasonablePerspective = modelPerspectiveRatio > 1.2 && modelPerspectiveRatio < 6.0;

                        // Also check top corners are roughly in frame
                        const topCornersValid =
                            predictedCorners.topLeft.x > -imgWidth * 0.5 &&
                            predictedCorners.topLeft.x < imgWidth * 1.2 &&
                            predictedCorners.topRight.x > -imgWidth * 0.2 &&
                            predictedCorners.topRight.x < imgWidth * 1.5;

                        console.log(`[LEARNING] Model perspective ratio: ${modelPerspectiveRatio.toFixed(2)}x`);
                        console.log(`[LEARNING] Model corners: TL=(${Math.round(predictedCorners.topLeft.x)},${Math.round(predictedCorners.topLeft.y)}) BR=(${Math.round(predictedCorners.bottomRight.x)},${Math.round(predictedCorners.bottomRight.y)})`);

                        if (modelHasReasonablePerspective && topCornersValid) {
                            // USE 100% MODEL - no rule-based blending
                            console.log('%c[LEARNING] Using 100% MODEL prediction (valid perspective)', 'background: #10b981; color: white; padding: 2px 6px; border-radius: 3px; font-weight: bold;');
                            console.log(`[LEARNING] Perspective: ${modelPerspectiveRatio.toFixed(2)}x (expected: 1.3-4.0x)`);
                            console.log('[LEARNING] Rule-based would have been:', JSON.stringify({
                                tl: [Math.round(adjustedCorners.topLeft.x), Math.round(adjustedCorners.topLeft.y)],
                                br: [Math.round(adjustedCorners.bottomRight.x), Math.round(adjustedCorners.bottomRight.y)]
                            }));
                            return predictedCorners;
                        } else {
                            // Model prediction seems off - fall back to rule-based
                            console.log('%c[LEARNING] Model prediction rejected (invalid perspective or corners)', 'background: #ef4444; color: white; padding: 2px 6px;');
                            console.log(`[LEARNING] Perspective: ${modelPerspectiveRatio.toFixed(2)}x, topCornersValid: ${topCornersValid}`);
                            // Fall through to rule-based
                        }
                    } else {
                        console.log('%c[LEARNING] Model prediction invalid, using rule-based only', 'color: #ef4444;');
                    }
                } catch (e) {
                    console.log('[detect] Memory model failed, using rule-based:', e.message);
                }
            } else {
                console.log('%c[LEARNING] No examples yet - using pure rule-based detection', 'color: #6b7280;');
            }

            console.log('%c[LEARNING] Final: Rule-based only', 'color: #6b7280;');
            return adjustedCorners;
        }

        // Generate field template with auto-detected position from green pixels
        function generateFieldTemplateWithDetection(img) {
            const corners = detectFieldQuadrilateral(img);

            if (corners) {
                // Use detected corners to position the template
                return generateFieldTemplateFromCorners(img.width, img.height, corners);
            } else {
                // Fallback to default centered template
                console.log('[generateField] Using default template position');
                return generateFieldTemplate(img.width, img.height);
            }
        }

        // Generate template positioned to match detected corners using HOMOGRAPHY
        function generateFieldTemplateFromCorners(frameWidth, frameHeight, corners) {
            const annotations = [];
            const pointPositions = {};

            // Store detection-derived parameters for 3D view consistency
            if (corners.elevationAngle !== undefined) {
                detectedElevationAngle = corners.elevationAngle;
                console.log(`[generateFromCorners] Stored elevationAngle: ${detectedElevationAngle.toFixed(1)}¬∞`);
            }
            if (corners.circleEllipse) {
                detectedCircleEllipse = corners.circleEllipse;
                console.log(`[generateFromCorners] Stored circleEllipse: ${JSON.stringify({
                    centerX: detectedCircleEllipse.centerX?.toFixed(0),
                    width: detectedCircleEllipse.width?.toFixed(0),
                    height: detectedCircleEllipse.height
                })}`);
            }

            // ============================================
            // STEP 1: Compute homography matrix
            // ============================================
            // Map unit square [0,1]x[0,1] to detected quadrilateral
            // Unit square corners: TL(0,0), TR(1,0), BR(1,1), BL(0,1)
            const srcCorners = [
                { x: 0, y: 0 },  // TL
                { x: 1, y: 0 },  // TR
                { x: 1, y: 1 },  // BR
                { x: 0, y: 1 }   // BL
            ];

            const dstCorners = [
                corners.topLeft,
                corners.topRight,
                corners.bottomRight,
                corners.bottomLeft
            ];

            // Validate all corners before computing homography
            const validCorner = (c) => c && typeof c.x === 'number' && typeof c.y === 'number' &&
                                       !isNaN(c.x) && !isNaN(c.y) && isFinite(c.x) && isFinite(c.y);
            if (!dstCorners.every(validCorner)) {
                console.error('[generateFromCorners] Invalid corners:', JSON.stringify(corners));
                console.error('[generateFromCorners] dstCorners:', dstCorners.map(c => c ? {x: c?.x, y: c?.y} : 'undefined'));
                return [];  // Return empty annotations
            }

            const H = computeHomography(srcCorners, dstCorners);
            console.log('[generateFromCorners] Homography matrix computed');

            // Log corner mapping for verification
            const topWidth = Math.hypot(corners.topRight.x - corners.topLeft.x, corners.topRight.y - corners.topLeft.y);
            const bottomWidth = Math.hypot(corners.bottomRight.x - corners.bottomLeft.x, corners.bottomRight.y - corners.bottomLeft.y);
            const leftHeight = Math.hypot(corners.bottomLeft.x - corners.topLeft.x, corners.bottomLeft.y - corners.topLeft.y);
            const avgWidth = (topWidth + bottomWidth) / 2;
            const perspectiveRatio = topWidth / bottomWidth;

            console.log('[generateFromCorners] Top width:', topWidth.toFixed(0), 'Bottom width:', bottomWidth.toFixed(0));
            console.log('[generateFromCorners] Perspective ratio:', perspectiveRatio.toFixed(3));

            // ============================================
            // STEP 2: Transform all template points using homography
            // ============================================
            for (const [name, pt] of Object.entries(FIELD_TEMPLATE_POINTS)) {
                pointPositions[name] = transformPoint(H, pt.x, pt.y);
            }

            // Verify corner transformation
            console.log('[generateFromCorners] TL mapped:', JSON.stringify({
                x: Math.round(pointPositions.corner_tl.x),
                y: Math.round(pointPositions.corner_tl.y)
            }));
            console.log('[generateFromCorners] Center mapped:', JSON.stringify({
                x: Math.round(pointPositions.center_mid.x),
                y: Math.round(pointPositions.center_mid.y)
            }));

            // ============================================
            // STEP 3: Create line annotations
            // ============================================
            FIELD_TEMPLATE_LINES.forEach(line => {
                const points = line.points.map(ptName => {
                    const pos = pointPositions[ptName];
                    return [pos.x, pos.y];
                });
                annotations.push({
                    type: 'line',
                    label: line.label,
                    id: line.id,
                    points: points,
                    templatePoints: line.points,
                    mode: 'field',
                    isGT: false,
                    isTemplate: true
                });
            });

            // ============================================
            // STEP 4: Transform circles to ellipses using conic transformation
            // ============================================
            FIELD_TEMPLATE_ELLIPSES.forEach(ellipse => {
                const centerPt = FIELD_TEMPLATE_POINTS[ellipse.center];

                // Transform circle to ellipse under homography
                const transformed = transformCircleToEllipse(H, centerPt.x, centerPt.y, ellipse.radius);

                console.log('[generateFromCorners] Ellipse "' + ellipse.label + '" transformed:',
                    'center=(' + transformed.center.x.toFixed(0) + ',' + transformed.center.y.toFixed(0) + ')',
                    'axes=[' + transformed.axes[0].toFixed(0) + ',' + transformed.axes[1].toFixed(0) + ']',
                    'angle=' + transformed.angle.toFixed(1) + '¬∞');

                annotations.push({
                    type: 'ellipse',
                    label: ellipse.label,
                    id: ellipse.id,
                    center: [transformed.center.x, transformed.center.y],
                    axes: transformed.axes,
                    angle: transformed.angle,
                    startAngle: ellipse.startAngle,
                    endAngle: ellipse.endAngle,
                    templateCenter: ellipse.center,
                    mode: 'field',
                    isGT: false,
                    isTemplate: true
                });
            });

            // ============================================
            // STEP 5: Store template reference with homography
            // ============================================
            fieldTemplate = {
                pointPositions: pointPositions,
                homography: H,
                corners: corners,
                frameWidth: frameWidth,
                frameHeight: frameHeight,
                annotations: annotations
            };

            // ============================================
            // STEP 6: Calibrate Camera3D to match detected corners exactly
            // ============================================
            const calibrated = Camera3D.calibrateToCorners(corners, frameWidth, frameHeight);

            // IMPORTANT: Apply ALL model camera parameters if available
            const appliedParams = [];
            if (corners.modelPitch !== undefined) { Camera3D.pitch = corners.modelPitch; appliedParams.push(`pitch=${corners.modelPitch.toFixed(1)}¬∞`); }
            if (corners.modelYaw !== undefined) { Camera3D.yaw = corners.modelYaw; appliedParams.push(`yaw=${corners.modelYaw.toFixed(1)}¬∞`); }
            if (corners.modelFocalLength !== undefined) { Camera3D.focalLength = corners.modelFocalLength; appliedParams.push(`fL=${corners.modelFocalLength.toFixed(0)}`); }
            if (corners.modelPosY !== undefined) { Camera3D.posY = corners.modelPosY; appliedParams.push(`posY=${corners.modelPosY.toFixed(0)}`); }
            if (corners.modelPosZ !== undefined) { Camera3D.posZ = corners.modelPosZ; appliedParams.push(`posZ=${corners.modelPosZ.toFixed(0)}`); }
            if (appliedParams.length > 0) {
                console.log(`[generateFromCorners] Applied model camera: ${appliedParams.join(', ')}`);
            }

            if (calibrated) {
                // Regenerate template using Camera3D projection for consistency
                // This ensures transforms will work correctly
                console.log('[generateFromCorners] Regenerating template with Camera3D projection...');

                // Update line annotations with Camera3D projected positions
                annotations.forEach(ann => {
                    if (ann.type === 'line' && ann.templatePoints) {
                        const newPoints = ann.templatePoints.map(ptName => {
                            const pt3d = FIELD_3D_POINTS[ptName];
                            if (!pt3d) return null;
                            const proj = Camera3D.project(pt3d.x, pt3d.y, pt3d.z || 0);
                            return proj ? [proj.x, proj.y] : null;
                        }).filter(p => p !== null);
                        if (newPoints.length >= 2) {
                            ann.points = newPoints;
                        }
                    } else if (ann.type === 'ellipse' && (ann.id === 'center_circle' || ann.elementType === 'centerCircle')) {
                        const circle = Camera3D.projectCircle(
                            FIELD_LENGTH / 2, FIELD_WIDTH / 2, STANDARD_PITCH.centerCircleRadius
                        );
                        if (circle) {
                            ann.center = circle.center;
                            ann.axes = circle.axes;
                            ann.angle = circle.angle || 0;
                        }
                    } else if (ann.type === 'ellipse' && ann.templateCenter) {
                        const centerPt = FIELD_3D_POINTS[ann.templateCenter];
                        if (centerPt) {
                            const circle = Camera3D.projectCircle(centerPt.x, centerPt.y, STANDARD_PITCH.centerCircleRadius);
                            if (circle) {
                                ann.center = circle.center;
                                ann.axes = circle.axes;
                                ann.angle = circle.angle || 0;
                            }
                        }
                    }
                });

                // Update pointPositions as well
                for (const [name, pt] of Object.entries(FIELD_3D_POINTS)) {
                    const proj = Camera3D.project(pt.x, pt.y, pt.z || 0);
                    if (proj) {
                        pointPositions[name] = { x: proj.x, y: proj.y };
                    }
                }
            }

            // Store baseline camera parameters for transform deltas
            storeCamera3DBaseline();

            // Initialize draggable anchor points for calibration
            initTemplateAnchors();

            // Sync slider values to Camera3D parameters
            field3D.rotationX = Camera3D.pitch;
            field3D.rotationY = Camera3D.yaw;
            field3D.rotationZ = Camera3D.roll;

            console.log('[generateFromCorners] Generated template with', annotations.length, 'annotations');
            console.log('[generateFromCorners] Camera3D: pitch=' + Camera3D.pitch.toFixed(1) +
                       '¬∞, yaw=' + Camera3D.yaw.toFixed(1) + '¬∞, focal=' + Camera3D.focalLength.toFixed(0));
            return annotations;
        }

        // Generate field template annotations for current video frame size using HOMOGRAPHY
        // This is the fallback when auto-detection fails
        function generateFieldTemplate(frameWidth, frameHeight) {
            const annotations = [];
            const pointPositions = {};

            // Calculate field dimensions - typical broadcast view has 2.5:1 to 3.5:1 aspect
            const margin = 0.08;
            const availableWidth = frameWidth * (1 - 2 * margin);
            const availableHeight = frameHeight * (1 - 2 * margin);

            // Default aspect ratio for typical broadcast (2.8:1)
            const DEFAULT_ASPECT = 2.8;

            // Start with width filling most of frame
            let fieldWidth = availableWidth;
            // Height constrained by aspect ratio
            let fieldHeight = fieldWidth / DEFAULT_ASPECT;

            // If too tall for frame, reduce
            if (fieldHeight > availableHeight * 0.7) {
                fieldHeight = availableHeight * 0.7;
                fieldWidth = fieldHeight * DEFAULT_ASPECT;
            }

            const centerX = frameWidth / 2;
            const centerY = frameHeight / 2;
            const offsetY = centerY - fieldHeight / 2;

            console.log('[defaultTemplate] Field: ' + fieldWidth.toFixed(0) + ' x ' + fieldHeight.toFixed(0) +
                        ', aspect: ' + (fieldWidth/fieldHeight).toFixed(2));

            // PERSPECTIVE: Calculate based on slope constraint (same as detection)
            // Target slope for vertical lines: 0.04 (middle of 0.02-0.06 range)
            const targetSlope = 0.04;
            const fieldAspect = fieldWidth / fieldHeight;
            // perspectiveFactor = 1 - 2 * slope / fieldAspect
            let perspectiveFactor = 1 - (2 * targetSlope / fieldAspect);
            perspectiveFactor = Math.max(0.93, Math.min(0.99, perspectiveFactor));

            console.log('[defaultTemplate] Target slope:', targetSlope, 'Perspective factor:', perspectiveFactor.toFixed(3));

            const topWidth = fieldWidth * perspectiveFactor;
            const bottomWidth = fieldWidth;

            // Create trapezoid corners
            const corners = {
                topLeft: { x: centerX - topWidth / 2, y: offsetY },
                topRight: { x: centerX + topWidth / 2, y: offsetY },
                bottomLeft: { x: centerX - bottomWidth / 2, y: offsetY + fieldHeight },
                bottomRight: { x: centerX + bottomWidth / 2, y: offsetY + fieldHeight }
            };

            console.log('[defaultTemplate] Perspective ratio: ' + perspectiveFactor.toFixed(3));

            // Compute homography from unit square to trapezoid
            const srcCorners = [
                { x: 0, y: 0 },  // TL
                { x: 1, y: 0 },  // TR
                { x: 1, y: 1 },  // BR
                { x: 0, y: 1 }   // BL
            ];

            const dstCorners = [
                corners.topLeft,
                corners.topRight,
                corners.bottomRight,
                corners.bottomLeft
            ];

            const H = computeHomography(srcCorners, dstCorners);

            // Transform all template points using homography
            for (const [name, pt] of Object.entries(FIELD_TEMPLATE_POINTS)) {
                pointPositions[name] = transformPoint(H, pt.x, pt.y);
            }

            // Create line annotations
            FIELD_TEMPLATE_LINES.forEach(line => {
                const points = line.points.map(ptName => {
                    const pos = pointPositions[ptName];
                    return [pos.x, pos.y];
                });
                annotations.push({
                    type: 'line',
                    label: line.label,
                    id: line.id,
                    points: points,
                    templatePoints: line.points,
                    mode: 'field',
                    isGT: false,
                    isTemplate: true
                });
            });

            // Transform circles to ellipses using proper conic transformation
            FIELD_TEMPLATE_ELLIPSES.forEach(ellipse => {
                const centerPt = FIELD_TEMPLATE_POINTS[ellipse.center];
                const transformed = transformCircleToEllipse(H, centerPt.x, centerPt.y, ellipse.radius);

                annotations.push({
                    type: 'ellipse',
                    label: ellipse.label,
                    id: ellipse.id,
                    center: [transformed.center.x, transformed.center.y],
                    axes: transformed.axes,
                    angle: transformed.angle,
                    startAngle: ellipse.startAngle,
                    endAngle: ellipse.endAngle,
                    templateCenter: ellipse.center,
                    mode: 'field',
                    isGT: false,
                    isTemplate: true
                });
            });

            // Store template reference with homography
            fieldTemplate = {
                pointPositions: pointPositions,
                homography: H,
                corners: corners,
                frameWidth: frameWidth,
                frameHeight: frameHeight,
                annotations: annotations
            };

            return annotations;
        }

        // Pan field template - smooth translation without changing perspective/rotation
        // Used when dragging center point for intuitive field positioning
        function panFieldTemplate(dx, dy) {
            // ALWAYS directly translate all field template annotations
            // This preserves any transforms (pitch, yaw, scale) that have been applied
            const templateAnns = annotations.filter(a => (a.mode || 'field') === 'field' && a.isTemplate);
            templateAnns.forEach(ann => {
                if (ann.type === 'line' && ann.points) {
                    ann.points = ann.points.map(pt => [pt[0] + dx, pt[1] + dy]);
                } else if (ann.type === 'ellipse' && ann.center) {
                    ann.center = [ann.center[0] + dx, ann.center[1] + dy];
                }
            });

            // Also update fieldTemplate point positions if they exist (for consistency)
            if (fieldTemplate && fieldTemplate.pointPositions) {
                for (const [name, pos] of Object.entries(fieldTemplate.pointPositions)) {
                    fieldTemplate.pointPositions[name] = {
                        x: pos.x + dx,
                        y: pos.y + dy
                    };
                }
            }

            console.log('[pan] Translated', templateAnns.length, 'annotations by', dx.toFixed(1), dy.toFixed(1));

            // Reset baseline after pan so transforms start fresh from new position
            if (typeof resetBaseline === 'function') {
                resetBaseline();
            }

            // Update GT reference and RigidTemplate
            const fieldAnns = annotations.filter(a => (a.mode || 'field') === 'field');
            if (fieldAnns.length > 0) {
                fieldGTReference = {
                    annotations: JSON.parse(JSON.stringify(fieldAnns)),
                    centroid: computeFieldCentroid(fieldAnns),
                    timestamp: Date.now()
                };
                lastFieldTransform = { dx: 0, dy: 0, scale: 1 };

                // Update RigidTemplate centroid to match new position
                if (RigidTemplate.isInitialized()) {
                    RigidTemplate.centroid.x += dx;
                    RigidTemplate.centroid.y += dy;
                    RigidTemplate.generateTrackingGrid();
                } else {
                    RigidTemplate.initFromAnnotations(fieldAnns);
                }
            }

            // Update sliders to reflect new position
            field3D.offsetX = field3D.offsetX + dx * 0.1;
            field3D.offsetZ = field3D.offsetZ + dy * 0.05;

            // Update slider UI (correct element IDs)
            document.getElementById('positionX').value = Math.round(field3D.offsetX * 10);
            document.getElementById('posXValue').textContent = field3D.offsetX.toFixed(1);
            document.getElementById('positionZ').value = Math.round(field3D.offsetZ * 10);
            document.getElementById('posZValue').textContent = field3D.offsetZ.toFixed(1);

            currentFrameEdited = true;
            redraw();
        }

        // Apply homography transform to field template
        // When user drags a point, we compute the perspective transform
        function updateFieldTemplateFromDrag(draggedPointName, newX, newY) {
            if (!fieldTemplate) return;

            // Update the dragged point
            fieldTemplate.pointPositions[draggedPointName] = { x: newX, y: newY };

            // Rebuild annotations from updated points
            rebuildFieldAnnotations();

            // Update GT reference and reinitialize RigidTemplate since user modified geometry
            const fieldAnns = annotations.filter(a => (a.mode || 'field') === 'field');
            if (fieldAnns.length > 0) {
                fieldGTReference = {
                    annotations: JSON.parse(JSON.stringify(fieldAnns)),
                    centroid: computeFieldCentroid(fieldAnns),
                    timestamp: Date.now()
                };
                lastFieldTransform = { dx: 0, dy: 0, scale: 1 };
                // Reinitialize RigidTemplate with new geometry (user changed shape)
                RigidTemplate.initFromAnnotations(fieldAnns);
            }

            // Mark frame as edited for consistency
            currentFrameEdited = true;
            updateAnnotationsPanel();
        }

        // Rebuild all field annotations from current point positions using HOMOGRAPHY
        function rebuildFieldAnnotations() {
            if (!fieldTemplate) return;

            const newAnnotations = [];

            // Rebuild lines
            FIELD_TEMPLATE_LINES.forEach(line => {
                const points = line.points.map(ptName => {
                    const pos = fieldTemplate.pointPositions[ptName];
                    return [pos.x, pos.y];
                });
                newAnnotations.push({
                    type: 'line',
                    label: line.label,
                    id: line.id,
                    points: points,
                    templatePoints: line.points,
                    mode: 'field',
                    isGT: true,  // User modified = GT
                    isTemplate: true
                });
            });

            // Recompute homography from current corner positions
            const corners = {
                topLeft: fieldTemplate.pointPositions.corner_tl,
                topRight: fieldTemplate.pointPositions.corner_tr,
                bottomRight: fieldTemplate.pointPositions.corner_br,
                bottomLeft: fieldTemplate.pointPositions.corner_bl
            };

            const srcCorners = [
                { x: 0, y: 0 },  // TL
                { x: 1, y: 0 },  // TR
                { x: 1, y: 1 },  // BR
                { x: 0, y: 1 }   // BL
            ];

            const dstCorners = [
                corners.topLeft,
                corners.topRight,
                corners.bottomRight,
                corners.bottomLeft
            ];

            const H = computeHomography(srcCorners, dstCorners);
            fieldTemplate.homography = H;
            fieldTemplate.corners = corners;

            // Rebuild ellipses using proper conic transformation
            FIELD_TEMPLATE_ELLIPSES.forEach(ellipse => {
                const centerPt = FIELD_TEMPLATE_POINTS[ellipse.center];

                // Transform circle to ellipse under homography
                const transformed = transformCircleToEllipse(H, centerPt.x, centerPt.y, ellipse.radius);

                newAnnotations.push({
                    type: 'ellipse',
                    label: ellipse.label,
                    id: ellipse.id,
                    center: [transformed.center.x, transformed.center.y],
                    axes: transformed.axes,
                    angle: transformed.angle,
                    startAngle: ellipse.startAngle,
                    endAngle: ellipse.endAngle,
                    templateCenter: ellipse.center,
                    mode: 'field',
                    isGT: true,
                    isTemplate: true
                });
            });

            // Update annotations
            annotations = newAnnotations;
            fieldTemplate.annotations = newAnnotations;
        }

        // Load field template for current video
        function loadFieldTemplate() {
            if (!currentImage) return;

            const frameWidth = currentImage.width;
            const frameHeight = currentImage.height;

            annotations = generateFieldTemplate(frameWidth, frameHeight);
            fieldTemplateActive = true;

            console.log('[template] Loaded field template with', annotations.length, 'annotations');
            redraw();
            updateAnnotationsPanel();
            setStatus('Field template loaded - drag corners to adjust perspective', '');
        }

        // Camera rotation model for wide-angle elevated view
        let cameraState = {
            rotationAngle: 0,      // Current rotation angle (degrees from center)
            zoomLevel: 1,          // Current zoom level
            lastRotation: 0,
            lastZoom: 1,
            velocity: { dx: 0, dy: 0, dAngle: 0, dZoom: 0 }  // Motion tracking
        };

        // Helper: compute centroid of all field annotation points
        function computeFieldCentroid(anns) {
            let sumX = 0, sumY = 0, count = 0;
            anns.forEach(ann => {
                if ((ann.mode || 'field') !== 'field') return;
                if (ann.type === 'line' && ann.points) {
                    ann.points.forEach(p => { sumX += p[0]; sumY += p[1]; count++; });
                } else if (ann.type === 'ellipse' && ann.center) {
                    sumX += ann.center[0]; sumY += ann.center[1]; count++;
                }
            });
            return count > 0 ? { x: sumX / count, y: sumY / count } : { x: 0, y: 0 };
        }

        // Helper: extract only corner points from field annotations for motion tracking
        // Uses the 4 field corners (corner_tl, corner_tr, corner_bl, corner_br) with their XYZ coords
        function extractFieldPoints(anns) {
            const cornerNames = ['corner_tl', 'corner_tr', 'corner_bl', 'corner_br'];
            const corners = {};  // Map corner name -> screen position

            anns.forEach((ann, annIdx) => {
                if ((ann.mode || 'field') !== 'field') return;
                if (ann.type === 'line' && ann.points && ann.templatePoints) {
                    // Check each point in the line to see if it's a corner
                    ann.templatePoints.forEach((ptName, pIdx) => {
                        if (cornerNames.includes(ptName) && !corners[ptName]) {
                            // Get the 3D coordinates for this corner
                            const fLength = field3D.fieldLength || 105;
                            const fWidth = field3D.fieldWidth || 68;
                            let xyz;
                            switch (ptName) {
                                case 'corner_tl': xyz = { x: 0, y: 0, z: 0 }; break;
                                case 'corner_tr': xyz = { x: fLength, y: 0, z: 0 }; break;
                                case 'corner_bl': xyz = { x: 0, y: fWidth, z: 0 }; break;
                                case 'corner_br': xyz = { x: fLength, y: fWidth, z: 0 }; break;
                            }
                            corners[ptName] = {
                                x: ann.points[pIdx][0],
                                y: ann.points[pIdx][1],
                                name: ptName,
                                xyz: xyz,
                                annIdx,
                                pIdx,
                                type: 'corner'
                            };
                        }
                    });
                }
            });

            // Return corners in consistent order for matching
            return cornerNames.map(name => corners[name]).filter(c => c !== undefined);
        }

        // Helper: compute best-fit rigid transform (translation only for now)
        function computeBestFitTransform(srcPoints, dstPoints) {
            if (srcPoints.length === 0 || srcPoints.length !== dstPoints.length) {
                return { dx: 0, dy: 0, scale: 1, valid: false };
            }

            // Compute individual displacements
            const displacements = [];
            for (let i = 0; i < srcPoints.length; i++) {
                displacements.push({
                    dx: dstPoints[i].x - srcPoints[i].x,
                    dy: dstPoints[i].y - srcPoints[i].y
                });
            }

            // Compute median displacement (robust to outliers)
            const dxValues = displacements.map(d => d.dx).sort((a, b) => a - b);
            const dyValues = displacements.map(d => d.dy).sort((a, b) => a - b);
            const medianDx = dxValues[Math.floor(dxValues.length / 2)];
            const medianDy = dyValues[Math.floor(dyValues.length / 2)];

            // Compute standard deviation
            const stdX = Math.sqrt(dxValues.reduce((s, v) => s + Math.pow(v - medianDx, 2), 0) / dxValues.length);
            const stdY = Math.sqrt(dyValues.reduce((s, v) => s + Math.pow(v - medianDy, 2), 0) / dyValues.length);

            // Filter outliers and recompute mean
            let sumDx = 0, sumDy = 0, validCount = 0;
            displacements.forEach(d => {
                const devX = Math.abs(d.dx - medianDx);
                const devY = Math.abs(d.dy - medianDy);
                if (devX <= GEOMETRY_CONFIG.outlierThreshold * (stdX + 1) &&
                    devY <= GEOMETRY_CONFIG.outlierThreshold * (stdY + 1)) {
                    sumDx += d.dx;
                    sumDy += d.dy;
                    validCount++;
                }
            });

            if (validCount === 0) {
                return { dx: medianDx, dy: medianDy, scale: 1, valid: true };
            }

            return {
                dx: sumDx / validCount,
                dy: sumDy / validCount,
                scale: 1,  // TODO: compute scale from point spread changes
                valid: true,
                outliers: displacements.length - validCount
            };
        }

        // Store GT reference when field annotations are saved as GT
        function updateFieldGTReference() {
            const fieldAnns = annotations.filter(a => (a.mode || 'field') === 'field' && a.isGT === true);
            if (fieldAnns.length > 0) {
                fieldGTReference = {
                    annotations: JSON.parse(JSON.stringify(fieldAnns)),
                    centroid: computeFieldCentroid(fieldAnns),
                    timestamp: Date.now()
                };
                // Also update RigidTemplate
                RigidTemplate.initFromAnnotations(fieldAnns);
                console.log('[GT] Updated field GT reference and RigidTemplate with', fieldAnns.length, 'annotations');
            }
        }

        // Undo/Redo stacks
        let undoStack = [];
        let redoStack = [];
        const MAX_UNDO = 50;

        // Canvas
        const canvas = document.getElementById('canvas');
        console.log('[init] Canvas element:', canvas);
        const ctx = canvas.getContext('2d');
        let currentImage = null;
        let prevFrameImageData = null;  // Previous frame ImageData for SOTACV client-side propagation
        let useSOTACVPropagation = true;  // Enable SOTA CV client-side propagation
        let scale = 1;
        let canvasSized = false;  // Track if canvas has been sized for current video

        // Viewport zoom and pan (for viewing annotations outside frame)
        let viewZoom = 1;        // 1 = fit to window, <1 = zoomed out to see beyond frame
        let viewOffsetX = 0;     // Pan offset
        let viewOffsetY = 0;
        const MIN_VIEW_ZOOM = 0.3;  // Can zoom out to 30% to see full field
        const MAX_VIEW_ZOOM = 3;    // Can zoom in to 300%

        // Magnifier
        const magnifier = document.getElementById('magnifier');
        const magCanvas = document.getElementById('magCanvas');
        const magCtx = magCanvas.getContext('2d');
        const MAG_ZOOM = 3;  // 3x zoom

        // Elements
        const videoList = document.getElementById('videoList');
        const frameSlider = document.getElementById('frameSlider');
        const status = document.getElementById('status');
        const loading = document.getElementById('loading');
        const deleteHint = document.getElementById('deleteHint');
        const keyframeIndicator = document.getElementById('keyframeIndicator');

        // Mode-specific colors
        const modeColors = {
            field: { gt: '#22c55e', prop: '#facc15' },    // green / yellow
            player: { gt: '#3b82f6', prop: '#93c5fd' },   // blue / light blue
            ball: { gt: '#f97316', prop: '#fdba74' }      // orange / light orange
        };

        // Colors
        const classColors = {
        {% for cls in pitch_classes %}
            '{{ cls }}': 'hsl({{ (loop.index0 * 360 // pitch_classes|length) }}, 70%, 50%)'{% if not loop.last %},{% endif %}
        {% endfor %}
        };

        function showLoading(msg = 'Loading...') {
            loading.querySelector('.loading-text').textContent = msg;
            loading.classList.add('show');
        }
        function hideLoading() { loading.classList.remove('show'); }

        function setStatus(msg, type = '') {
            status.textContent = msg;
            status.className = 'status ' + type;
        }

        // Undo/Redo
        function saveState() {
            undoStack.push(JSON.stringify(annotations));
            if (undoStack.length > MAX_UNDO) undoStack.shift();
            redoStack = [];
            updateUndoRedoButtons();
        }

        function undo() {
            if (undoStack.length === 0) return;
            redoStack.push(JSON.stringify(annotations));
            annotations = JSON.parse(undoStack.pop());
            redraw();
            updateAnnotationsPanel();
            updateUndoRedoButtons();
        }

        function redo() {
            if (redoStack.length === 0) return;
            undoStack.push(JSON.stringify(annotations));
            annotations = JSON.parse(redoStack.pop());
            redraw();
            updateAnnotationsPanel();
            updateUndoRedoButtons();
        }

        function updateUndoRedoButtons() {
            document.getElementById('undoBtn').disabled = undoStack.length === 0;
            document.getElementById('redoBtn').disabled = redoStack.length === 0;
        }

        // Time formatting helper
        function formatTime(seconds) {
            const mins = Math.floor(seconds / 60);
            const secs = Math.floor(seconds % 60);
            return `${mins}:${secs.toString().padStart(2, '0')}`;
        }

        // GT Timeline functions
        let timelineZoom = 4;  // Default to 4x for better visibility

        function zoomTimeline(delta) {
            const zoomLevels = [1, 2, 4, 8, 16, 32];  // Extended zoom levels up to 32x
            const currentIdx = zoomLevels.indexOf(timelineZoom);
            const newIdx = Math.max(0, Math.min(zoomLevels.length - 1, currentIdx + delta));
            timelineZoom = zoomLevels[newIdx];
            document.getElementById('timelineZoomLevel').textContent = timelineZoom + 'x';
            document.getElementById('timelineRows').style.width = (100 * timelineZoom) + '%';
            updateGTTimeline();
        }

        // Initialize timeline zoom on load
        function initTimelineZoom() {
            document.getElementById('timelineZoomLevel').textContent = timelineZoom + 'x';
            document.getElementById('timelineRows').style.width = (100 * timelineZoom) + '%';
        }

        function updateGTTimeline() {
            const timeline = document.getElementById('gtTimeline');
            const countEl = document.getElementById('gtCount');
            const durationEl = document.getElementById('videoDuration');
            const fieldBar = document.getElementById('fieldTimelineBar');
            const playerBar = document.getElementById('playerTimelineBar');
            const ballBar = document.getElementById('ballTimelineBar');

            if (!currentVideo || totalFrames === 0) {
                timeline.style.display = 'none';
                return;
            }

            timeline.style.display = 'block';
            const duration = totalFrames / fps;
            durationEl.textContent = formatTime(duration);

            // Find GT keyframes
            const frameData = allAnnotations.frames || allAnnotations;
            const gtFrames = Object.keys(frameData).map(Number).filter(f => !isNaN(f)).sort((a,b) => a - b);

            // Count and categorize frames by mode
            const modeFrames = { field: [], player: [], ball: [] };
            gtFrames.forEach(frame => {
                const anns = frameData[frame] || [];
                anns.forEach(a => {
                    const mode = a.mode || 'field';
                    if (!modeFrames[mode].includes(frame)) {
                        modeFrames[mode].push(frame);
                    }
                });
            });

            countEl.textContent = `(F:${modeFrames.field.length} P:${modeFrames.player.length} B:${modeFrames.ball.length})`;

            // Clear existing markers from all bars
            [fieldBar, playerBar, ballBar].forEach(bar => {
                bar.querySelectorAll('.gt-marker').forEach(m => m.remove());
            });

            // Add markers to each row
            const bars = { field: fieldBar, player: playerBar, ball: ballBar };
            Object.keys(modeFrames).forEach(mode => {
                const bar = bars[mode];
                modeFrames[mode].forEach(frame => {
                    const marker = document.createElement('div');
                    marker.className = `gt-marker ${mode}` + (frame === currentFrame ? ' current' : '');
                    const percent = (frame / (totalFrames - 1)) * 100;
                    marker.style.left = `calc(${percent}% - 3px)`;

                    const timeInSeconds = frame / fps;
                    const tooltip = document.createElement('div');
                    tooltip.className = 'gt-marker-tooltip';
                    tooltip.textContent = `Frame ${frame} (${formatTime(timeInSeconds)})`;
                    marker.appendChild(tooltip);

                    marker.onclick = (e) => {
                        e.stopPropagation();
                        loadFrame(frame, false);
                    };

                    bar.appendChild(marker);
                });
            });

            // Update playhead position on all rows
            const playheadPercent = (currentFrame / (totalFrames - 1)) * 100;
            document.querySelectorAll('.timeline-playhead').forEach(ph => {
                ph.style.left = `${playheadPercent}%`;
            });
        }

        // Click on timeline bar to jump to position
        ['fieldTimelineBar', 'playerTimelineBar', 'ballTimelineBar'].forEach(barId => {
            document.getElementById(barId).addEventListener('click', (e) => {
                if (totalFrames === 0) return;
                const bar = e.currentTarget;
                const rect = bar.getBoundingClientRect();
                const percent = (e.clientX - rect.left) / rect.width;
                const frame = Math.round(percent * (totalFrames - 1));
                loadFrame(Math.max(0, Math.min(totalFrames - 1, frame)), false);
            });
        });

        // Confirmation Modal functions
        function showConfirmModal() {
            document.getElementById('confirmModal').classList.add('show');
        }

        function closeConfirmModal() {
            document.getElementById('confirmModal').classList.remove('show');
        }

        async function clearAllVideoAnnotations() {
            if (!currentVideo) return;

            showLoading('Clearing all annotations...');
            try {
                const resp = await fetch(`/api/video/${encodeURIComponent(currentVideo)}/annotations/clear`, {
                    method: 'POST'
                });

                if (resp.ok) {
                    allAnnotations = {};
                    annotations = [];
                    keyframes = [];
                    redraw();
                    updateAnnotationsPanel();
                    updateGTTimeline();
                    setStatus('All annotations cleared', 'saved');
                } else {
                    setStatus('Failed to clear annotations', '');
                }
            } catch (e) {
                setStatus('Error: ' + e.message, '');
            }
            hideLoading();
            closeConfirmModal();
        }

        // Wire up confirmation button
        document.getElementById('confirmDeleteBtn').onclick = clearAllVideoAnnotations;

        // Track all videos for prefetching
        let allVideos = [];

        // Load videos
        async function loadVideos() {
            try {
                const resp = await fetch('/api/videos');
                const data = await resp.json();
                videoList.innerHTML = '';
                allVideos = data.videos;

                data.videos.forEach(video => {
                    const div = document.createElement('div');
                    div.className = 'video-item';
                    div.dataset.videoName = video.name;

                    // Show cache status indicator
                    const indicator = document.createElement('span');
                    indicator.className = 'cache-indicator';
                    if (video.cached) {
                        indicator.textContent = '‚óè';
                        indicator.style.color = '#10b981';
                        indicator.title = 'Cached locally';
                    } else if (video.download_status === 'downloading') {
                        indicator.textContent = '‚óê';
                        indicator.style.color = '#f59e0b';
                        indicator.title = `Downloading ${video.download_progress}%`;
                    } else {
                        indicator.textContent = '‚óã';
                        indicator.style.color = '#6b7280';
                        indicator.title = 'Not cached';
                    }

                    const nameSpan = document.createElement('span');
                    nameSpan.textContent = ' ' + video.name;

                    div.appendChild(indicator);
                    div.appendChild(nameSpan);
                    div.onclick = () => selectVideo(video.name);
                    videoList.appendChild(div);
                });

                const cachedCount = data.videos.filter(v => v.cached).length;
                setStatus(`${data.count} videos (${cachedCount} cached)`);
            } catch (e) {
                setStatus('Error loading videos');
            }
        }

        // Prefetch next videos in list
        function prefetchNearbyVideos(currentVideoName) {
            const idx = allVideos.findIndex(v => v.name === currentVideoName);
            if (idx === -1) return;

            // Prefetch next 2 videos
            for (let i = 1; i <= 2; i++) {
                if (idx + i < allVideos.length && !allVideos[idx + i].cached) {
                    const nextVideo = allVideos[idx + i].name;
                    fetch(`/api/video/${encodeURIComponent(nextVideo)}/prefetch`, { method: 'POST' });
                }
            }
        }

        document.getElementById('videoSearch').addEventListener('input', (e) => {
            const search = e.target.value.toLowerCase();
            document.querySelectorAll('.video-item').forEach(item => {
                const name = item.dataset.videoName || item.textContent;
                item.style.display = name.toLowerCase().includes(search) ? '' : 'none';
            });
        });

        async function selectVideo(videoName) {
            showLoading('Loading video...');
            currentVideo = videoName;
            canvasSized = false;  // Reset so canvas sizes correctly for new video

            // Reset geometric stability system for new video
            fieldGTReference = null;
            lastFieldTransform = { dx: 0, dy: 0, scale: 1 };
            RigidTemplate.reset();  // Reset rigid body template system
            SOTACV.reset();  // Reset SOTA CV tracking state
            clearPropagationCache();  // Clear bulk propagation cache for new video
            frameImageCache = {};  // Clear frame image cache for new video
            lastSliderValues = null;  // Reset incremental slider tracking
            lastPitchValue = field3D.rotationX;  // Reset pitch/yaw/distance tracking
            lastYawValue = field3D.rotationY;
            lastDistanceValue = field3D.cameraDistance;
            console.log('[selectVideo] Reset GT reference, RigidTemplate, SOTACV, propagation cache, and transform for new video');
            document.querySelectorAll('.video-item').forEach(item => {
                item.classList.toggle('selected', item.dataset.videoName === videoName);
            });

            // Start prefetching nearby videos
            prefetchNearbyVideos(videoName);

            try {
                const resp = await fetch(`/api/video/${encodeURIComponent(videoName)}/info`);
                const info = await resp.json();
                totalFrames = info.frame_count;
                fps = info.fps || 25;
                frameSlider.max = totalFrames - 1;
                keyframes = info.keyframes || [];
                currentFrame = 0;

                const annResp = await fetch(`/api/video/${encodeURIComponent(videoName)}/annotations`);
                allAnnotations = await annResp.json();

                await loadFrame(0);
                updateGTTimeline();
                setStatus(`${videoName} - ${totalFrames} frames @ ${fps.toFixed(1)} fps`);
            } catch (e) {
                setStatus('Error loading video');
            }
            hideLoading();
        }

        async function loadFrame(frameNum, propagate = true) {
            if (!currentVideo) return;

            // Auto-finish any pending line/ellipse before navigating
            if (currentTool === 'line' && tempPoints.length >= 2) finishLine();
            if (currentTool === 'ellipse' && tempPoints.length >= 3) finishEllipse();

            // Clear undo/redo stacks when switching frames (different edit context)
            if (frameNum !== currentFrame) {
                undoStack = [];
                redoStack = [];
                updateUndoRedoButtons();
                currentFrameEdited = false;  // Reset edit tracking for new frame
                lastSliderValues = null;  // Reset incremental slider tracking for new frame
                lastPitchValue = field3D.rotationX;  // Reset pitch/yaw/distance tracking
                lastYawValue = field3D.rotationY;
                lastDistanceValue = field3D.cameraDistance;

                // Reset SOTACV if jumping more than redetect interval (significant frame change)
                if (Math.abs(frameNum - currentFrame) > SOTACV.config.redetectInterval) {
                    SOTACV.reset();
                    console.log('[loadFrame] Reset SOTACV due to large frame jump');
                }
            }

            console.log(`[loadFrame] frameNum=${frameNum}, propagate=${propagate}, currentFrame=${currentFrame}`);

            // Save current annotations for propagation BEFORE clearing
            const prevAnnotations = JSON.parse(JSON.stringify(annotations));
            const prevFrame = currentFrame;

            console.log(`[loadFrame] prevAnnotations.length=${prevAnnotations.length}, lastSavedFrame=${lastSavedFrame}`);

            // Auto-save current frame before navigating
            if (prevAnnotations.length > 0 && prevFrame !== frameNum && lastSavedFrame !== prevFrame) {
                console.log(`[loadFrame] Auto-saving frame ${prevFrame}...`);
                await saveCurrentFrame();
            } else {
                console.log(`[loadFrame] Skipping save: annLen=${prevAnnotations.length}, prevFrame=${prevFrame}, frameNum=${frameNum}, lastSaved=${lastSavedFrame}`);
            }

            try {
                const resp = await fetch(`/api/video/${encodeURIComponent(currentVideo)}/frame/${frameNum}`);
                const data = await resp.json();

                const img = new Image();
                img.onload = async () => {
                    console.log(`[img.onload] Image loaded for frame ${frameNum}`);

                    // Store current frame ImageData for SOTACV propagation before overwriting
                    if (currentImage && useSOTACVPropagation) {
                        try {
                            const tempCanvas = document.createElement('canvas');
                            tempCanvas.width = currentImage.width;
                            tempCanvas.height = currentImage.height;
                            const tempCtx = tempCanvas.getContext('2d');
                            tempCtx.drawImage(currentImage, 0, 0);
                            prevFrameImageData = tempCtx.getImageData(0, 0, currentImage.width, currentImage.height);
                        } catch (e) {
                            console.log('[img.onload] Could not store prev frame ImageData:', e.message);
                            prevFrameImageData = null;
                        }
                    }

                    currentImage = img;

                    // Only resize canvas once per video to prevent jitter
                    if (!canvasSized) {
                        const container = canvas.parentElement;
                        scale = Math.min((container.clientWidth - 40) / img.width, (container.clientHeight - 40) / img.height);
                        canvas.width = img.width * scale;
                        canvas.height = img.height * scale;
                        canvasSized = true;
                    }

                    // Get current frame ImageData for SOTACV
                    let currFrameImageData = null;
                    if (useSOTACVPropagation) {
                        try {
                            const tempCanvas = document.createElement('canvas');
                            tempCanvas.width = img.width;
                            tempCanvas.height = img.height;
                            const tempCtx = tempCanvas.getContext('2d');
                            tempCtx.drawImage(img, 0, 0);
                            currFrameImageData = tempCtx.getImageData(0, 0, img.width, img.height);
                        } catch (e) {
                            console.log('[img.onload] Could not get current frame ImageData:', e.message);
                        }
                    }

                    console.log(`[img.onload] data.annotations=${JSON.stringify(data.annotations)}`);
                    console.log(`[img.onload] propagate=${propagate}, prevAnnotations.length=${prevAnnotations.length}, frameNum=${frameNum}, prevFrame=${prevFrame}`);

                    // Check if this frame has saved annotations
                    if (data.annotations && data.annotations.length > 0) {
                        console.log(`[img.onload] Using saved annotations from server`);
                        annotations = data.annotations;

                        // Initialize draggable anchor points for loaded template
                        initTemplateAnchors();

                        // Initialize GT reference and RigidTemplate if this frame has GT field annotations
                        const gtFieldAnns = annotations.filter(a => (a.mode || 'field') === 'field' && a.isGT === true);
                        if (gtFieldAnns.length > 0 && !fieldGTReference) {
                            fieldGTReference = {
                                annotations: JSON.parse(JSON.stringify(gtFieldAnns)),
                                centroid: computeFieldCentroid(gtFieldAnns),
                                timestamp: Date.now()
                            };
                            lastFieldTransform = { dx: 0, dy: 0, scale: 1 };
                            RigidTemplate.initFromAnnotations(gtFieldAnns);
                            console.log('[img.onload] Initialized GT reference and RigidTemplate from saved annotations');
                        }
                    } else if (propagate && prevAnnotations.length > 0 && frameNum !== prevFrame) {
                        // Auto-propagate from previous frame
                        console.log(`[img.onload] Propagating from frame ${prevFrame} to ${frameNum}`);
                        setStatus('Propagating...', 'saving');

                        // Try SOTACV client-side propagation first if enabled
                        if (useSOTACVPropagation && prevFrameImageData && currFrameImageData) {
                            try {
                                const fieldAnns = prevAnnotations.filter(a => (a.mode || 'field') === 'field');
                                if (fieldAnns.length > 0) {
                                    console.log('[SOTACV] Using client-side KLT + Kalman propagation');
                                    const result = SOTACV.propagateTemplate(prevFrameImageData, currFrameImageData, fieldAnns);

                                    if (result && result.annotations) {
                                        console.log(`[SOTACV] Propagated ${result.trackedCount} features, motion: dx=${result.motion.tx.toFixed(2)}, dy=${result.motion.ty.toFixed(2)}`);

                                        // Update RigidTemplate with SOTACV motion
                                        if (RigidTemplate.isInitialized()) {
                                            RigidTemplate.applyMotion({
                                                dx: result.motion.tx,
                                                dy: result.motion.ty,
                                                scale: result.motion.scale
                                            });
                                            // Rebuild annotations from RigidTemplate to guarantee geometry
                                            const rigidAnns = RigidTemplate.rebuildAnnotations();
                                            annotations = rigidAnns.concat(
                                                prevAnnotations.filter(a => (a.mode || 'field') !== 'field').map(a => ({...a, isGT: false}))
                                            );
                                        } else {
                                            annotations = result.annotations.concat(
                                                prevAnnotations.filter(a => (a.mode || 'field') !== 'field').map(a => ({...a, isGT: false}))
                                            );
                                        }

                                        setStatus(`SOTACV propagated (${result.trackedCount} features)`, 'saved');
                                        // Skip backend propagation
                                    } else {
                                        // SOTACV failed, fall back to backend
                                        console.log('[SOTACV] Client-side propagation failed, using backend');
                                        await propagateFromFrame(prevFrame, frameNum, prevAnnotations);
                                    }
                                } else {
                                    // No field annotations, use backend for player/ball tracking
                                    await propagateFromFrame(prevFrame, frameNum, prevAnnotations);
                                }
                            } catch (e) {
                                console.log('[SOTACV] Error in client-side propagation:', e.message);
                                await propagateFromFrame(prevFrame, frameNum, prevAnnotations);
                            }
                        } else {
                            // Use backend optical flow
                            await propagateFromFrame(prevFrame, frameNum, prevAnnotations);
                        }
                    } else {
                        // No saved annotations and nothing to propagate - try neural network first
                        console.log(`[img.onload] No annotations - trying neural network prediction`);

                        // Try neural network prediction first
                        let nnSuccess = false;
                        try {
                            const nnResponse = await fetch('/api/tracking/predict_template', {
                                method: 'POST',
                                headers: { 'Content-Type': 'application/json' },
                                body: JSON.stringify({
                                    frame_base64: data.frame,
                                    video_name: currentVideo,
                                    frame_num: frameNum
                                })
                            });

                            if (nnResponse.ok) {
                                const nnResult = await nnResponse.json();
                                if (nnResult.status === 'success' && nnResult.predicted_corners) {
                                    console.log(`[img.onload] Neural network prediction success: ${nnResult.method}`);

                                    // Use predicted corners to generate template
                                    const corners = nnResult.predicted_corners;
                                    const detectedCorners = {
                                        topLeft: { x: corners[0][0], y: corners[0][1] },
                                        topRight: { x: corners[1][0], y: corners[1][1] },
                                        bottomLeft: { x: corners[2][0], y: corners[2][1] },
                                        bottomRight: { x: corners[3][0], y: corners[3][1] }
                                    };

                                    annotations = generateFieldTemplateFromCorners(img.width, img.height, detectedCorners);
                                    nnSuccess = true;
                                    setStatus(`Template from ${nnResult.method} - drag to adjust`, '');
                                }
                            }
                        } catch (nnErr) {
                            console.log('[img.onload] Neural network prediction failed:', nnErr);
                        }

                        // Fall back to rule-based detection if neural network failed
                        if (!nnSuccess) {
                            console.log(`[img.onload] Falling back to rule-based detection`);
                            annotations = generateFieldTemplateWithDetection(img);
                        }

                        fieldTemplateActive = true;

                        // Initialize draggable anchor points for auto-detected template
                        initTemplateAnchors();

                        setStatus('Field template loaded - drag corners to adjust perspective', '');

                        // Initialize GT reference and RigidTemplate from the fresh template
                        const fieldAnns = annotations.filter(a => (a.mode || 'field') === 'field');
                        if (fieldAnns.length > 0) {
                            fieldGTReference = {
                                annotations: JSON.parse(JSON.stringify(fieldAnns)),
                                centroid: computeFieldCentroid(fieldAnns),
                                timestamp: Date.now()
                            };
                            lastFieldTransform = { dx: 0, dy: 0, scale: 1 };
                            RigidTemplate.initFromAnnotations(fieldAnns);
                            console.log('[img.onload] Initialized GT reference and RigidTemplate from field template');
                        }

                        // Sync 3D sliders to match detected template position
                        syncSlidersToCurrentTemplate();
                    }

                    tempPoints = [];
                    undoStack = [];
                    redoStack = [];
                    updateUndoRedoButtons();

                    currentFrame = frameNum;
                    lastSavedFrame = -1;
                    redraw();
                    updateAnnotationsPanel();
                    updateFrameInfo();

                    keyframeIndicator.style.display = keyframes.includes(frameNum) ? 'block' : 'none';
                };
                img.src = 'data:image/jpeg;base64,' + data.frame;
            } catch (e) {
                console.error('Error loading frame:', e);
            }
        }

        async function propagateFromFrame(sourceFrame, targetFrame, sourceAnnotations) {
            console.log(`[propagate] sourceFrame=${sourceFrame}, targetFrame=${targetFrame}, sourceAnnotations.length=${sourceAnnotations.length}`);
            try {
                const body = {
                    source_frame: sourceFrame,
                    target_frame: targetFrame,
                    annotations: sourceAnnotations,
                    drift_corrections: driftCorrections  // Send learned drift corrections
                };
                console.log(`[propagate] Sending:`, body);
                const resp = await fetch(`/api/video/${encodeURIComponent(currentVideo)}/propagate`, {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify(body)
                });
                console.log(`[propagate] Response status: ${resp.status}`);
                const data = await resp.json();
                console.log(`[propagate] Response data:`, data);
                if (data.annotations && data.annotations.length > 0) {
                    // ========== RIGID BODY PROPAGATION FOR FIELD ANNOTATIONS ==========
                    // Field template moves as a SINGLE RIGID BODY - no individual point drift
                    // Geometry is mathematically guaranteed to be preserved

                    const hasFieldAnns = data.annotations.some(a => (a.mode || 'field') === 'field');
                    const fieldSourceAnns = sourceAnnotations.filter(a => (a.mode || 'field') === 'field');

                    // Initialize RigidTemplate if not already done
                    if (hasFieldAnns && !RigidTemplate.isInitialized() && fieldSourceAnns.length > 0) {
                        RigidTemplate.initFromAnnotations(fieldSourceAnns);
                        console.log('[propagate] Initialized RigidTemplate from source annotations');
                    }

                    if (hasFieldAnns && RigidTemplate.isInitialized()) {
                        // Extract tracked points from optical flow result (for motion estimation)
                        const trackedPoints = extractFieldPoints(data.annotations.filter(a => (a.mode || 'field') === 'field'));
                        const sourcePoints = extractFieldPoints(fieldSourceAnns);

                        if (trackedPoints.length >= 3 && sourcePoints.length === trackedPoints.length) {
                            // Compute motion from multiple points using RANSAC-like consensus
                            const motions = [];
                            for (let i = 0; i < sourcePoints.length; i++) {
                                const dx = trackedPoints[i].x - sourcePoints[i].x;
                                const dy = trackedPoints[i].y - sourcePoints[i].y;
                                // Reject extreme motions (outliers)
                                if (Math.abs(dx) < 50 && Math.abs(dy) < 50) {
                                    motions.push({ dx, dy });
                                }
                            }

                            if (motions.length >= 3) {
                                // Use median for robust motion estimate (rejects outliers)
                                motions.sort((a, b) => a.dx - b.dx);
                                const medianDx = motions[Math.floor(motions.length / 2)].dx;
                                motions.sort((a, b) => a.dy - b.dy);
                                const medianDy = motions[Math.floor(motions.length / 2)].dy;

                                // Filter inliers (points close to median motion)
                                const inlierThreshold = 5;
                                const inliers = motions.filter(m => {
                                    const dist = Math.sqrt(Math.pow(m.dx - medianDx, 2) + Math.pow(m.dy - medianDy, 2));
                                    return dist < inlierThreshold;
                                });

                                // Compute weighted average of inliers
                                let dx, dy;
                                if (inliers.length >= 3) {
                                    dx = inliers.reduce((s, m) => s + m.dx, 0) / inliers.length;
                                    dy = inliers.reduce((s, m) => s + m.dy, 0) / inliers.length;
                                } else {
                                    // Fall back to median
                                    dx = medianDx;
                                    dy = medianDy;
                                }

                                // Apply tripod camera constraints
                                // X axis (horizontal pan) - primary motion, allow reasonable speed
                                if (Math.abs(dx) > GEOMETRY_CONFIG.maxSpeedX) {
                                    console.log(`[rigid] Clamping X: ${dx.toFixed(1)} -> ${Math.sign(dx) * GEOMETRY_CONFIG.maxSpeedX}`);
                                    dx = Math.sign(dx) * GEOMETRY_CONFIG.maxSpeedX;
                                }

                                // Y axis (vertical) - almost never happens on tripod
                                // Heavy dampening for Y-only movement
                                if (Math.abs(dy) > 1 && Math.abs(dx) < 2) {
                                    dy = dy * 0.2;
                                }
                                if (Math.abs(dy) > GEOMETRY_CONFIG.maxSpeedY) {
                                    dy = Math.sign(dy) * GEOMETRY_CONFIG.maxSpeedY;
                                }
                                dy = dy * 0.3;  // Extra Y dampening

                                // Filter noise
                                if (Math.abs(dx) < GEOMETRY_CONFIG.minSpeedThreshold) dx = 0;
                                if (Math.abs(dy) < GEOMETRY_CONFIG.minSpeedThreshold) dy = 0;

                                // Apply motion to RigidTemplate (moves centroid, preserves geometry)
                                RigidTemplate.applyMotion({ dx, dy, scale: 1.0 });

                                console.log(`[rigid] Applied motion: dx=${dx.toFixed(2)}, dy=${dy.toFixed(2)}, ` +
                                    `inliers=${inliers.length}/${motions.length}, centroid=(${RigidTemplate.centroid.x.toFixed(1)}, ${RigidTemplate.centroid.y.toFixed(1)})`);
                            } else {
                                console.log('[rigid] Not enough valid motion samples, skipping');
                            }
                        }

                        // REBUILD field annotations from RigidTemplate
                        // This GUARANTEES geometry is preserved - all points derived from fixed offsets
                        const rigidFieldAnns = RigidTemplate.rebuildAnnotations();

                        // Replace field annotations with rigidly-transformed ones
                        data.annotations = data.annotations.map(ann => {
                            if ((ann.mode || 'field') !== 'field') return ann;

                            // Find matching rigid annotation by id
                            const rigidAnn = rigidFieldAnns.find(r => r.id === ann.id);
                            return rigidAnn || ann;
                        });

                        console.log(`[rigid] Rebuilt ${rigidFieldAnns.length} field annotations from RigidTemplate`);

                        // Also update legacy fieldGTReference for compatibility
                        lastFieldTransform = {
                            dx: RigidTemplate.centroid.x - (fieldGTReference?.centroid?.x || RigidTemplate.centroid.x),
                            dy: RigidTemplate.centroid.y - (fieldGTReference?.centroid?.y || RigidTemplate.centroid.y),
                            scale: RigidTemplate.scale
                        };
                    } else if (hasFieldAnns && !RigidTemplate.isInitialized()) {
                        // No RigidTemplate yet - initialize from source GT if available
                        const gtAnns = sourceAnnotations.filter(a => (a.mode || 'field') === 'field' && a.isGT === true);
                        if (gtAnns.length > 0) {
                            RigidTemplate.initFromAnnotations(gtAnns);
                            fieldGTReference = {
                                annotations: JSON.parse(JSON.stringify(gtAnns)),
                                centroid: { ...RigidTemplate.centroid },
                                timestamp: Date.now()
                            };
                            lastFieldTransform = { dx: 0, dy: 0, scale: 1 };
                            console.log('[rigid] Initialized RigidTemplate from GT source annotations');
                        }
                    }

                    // Save state for undo before modifying annotations
                    saveState();

                    // Mark all as propagated (not GT) and apply drift correction for non-field
                    annotations = data.annotations.map(ann => {
                        const mode = ann.mode || 'field';

                        // Field annotations already handled by rigid system above
                        if (mode === 'field') {
                            return {...ann, isGT: false};
                        }

                        // Apply drift correction for player/ball modes
                        const dc = driftCorrections[mode];
                        const shouldApply = dc &&
                            dc.count >= DRIFT_CONFIG.minSamples &&
                            dc.variance < DRIFT_CONFIG.maxVariance;

                        if (shouldApply) {
                            const applyDx = dc.dx * DRIFT_CONFIG.applyScale;
                            const applyDy = dc.dy * DRIFT_CONFIG.applyScale;

                            const correctedAnn = {...ann, isGT: false};
                            if (ann.type === 'point' && ann.point) {
                                correctedAnn.point = [ann.point[0] + applyDx, ann.point[1] + applyDy];
                            }
                            return correctedAnn;
                        }
                        return {...ann, isGT: false};
                    });
                    // Sync sliders to match propagated template position
                    syncSlidersToCurrentTemplate();

                    setStatus(`Propagated ${annotations.length} annotations`, 'saved');
                } else {
                    setStatus('No annotations to propagate', '');
                }
            } catch (e) {
                console.error('[propagate] Error:', e);
                setStatus('Propagation failed', '');
            }
        }

        async function saveCurrentFrame() {
            console.log(`[save] Saving frame ${currentFrame}, annotations.length=${annotations.length}`);
            if (!currentVideo) {
                console.log(`[save] No current video, aborting`);
                return false;
            }
            try {
                setStatus('Saving...', 'saving');
                const body = { annotations };
                console.log(`[save] POST to /api/video/${currentVideo}/frame/${currentFrame}/annotations`, body);
                const resp = await fetch(`/api/video/${encodeURIComponent(currentVideo)}/frame/${currentFrame}/annotations`, {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify(body)
                });

                console.log(`[save] Response status: ${resp.status}`);
                if (!resp.ok) {
                    const err = await resp.json();
                    console.error('[save] Save failed:', err);
                    setStatus('Error saving: ' + (err.error || resp.status), '');
                    return false;
                }

                const result = await resp.json();
                console.log(`[save] Save result:`, result);

                if (!allAnnotations.frames) allAnnotations.frames = {};
                allAnnotations.frames[currentFrame] = JSON.parse(JSON.stringify(annotations));

                // Only add to keyframes if user manually edited this frame (has GT annotations)
                const hasGTField = annotations.some(a => (a.mode || 'field') === 'field' && a.isGT === true);
                if (hasGTField && !keyframes.includes(currentFrame)) {
                    keyframes.push(currentFrame);
                    keyframes.sort((a,b) => a-b);
                    console.log(`[save] Added keyframe ${currentFrame} (GT edited)`);
                }

                lastSavedFrame = currentFrame;
                updateGTTimeline();  // Refresh timeline

                if (hasGTField) {
                    updateFieldGTReference();
                    // Reset transform when new GT is created
                    lastFieldTransform = { dx: 0, dy: 0, scale: 1 };
                    console.log('[save] Reset field transform - new GT reference');
                }

                setStatus(`Saved frame ${currentFrame}`, 'saved');
                return true;
            } catch (e) {
                console.error('[save] Error:', e);
                setStatus('Error saving: ' + e.message, '');
                return false;
            }
        }

        function updateFrameInfo() {
            document.getElementById('frameNum').textContent = `Frame: ${currentFrame} / ${totalFrames - 1}`;
            frameSlider.value = currentFrame;
            // Update timeline playhead
            const playhead = document.getElementById('timelinePlayhead');
            if (playhead && totalFrames > 1) {
                const playheadPercent = (currentFrame / (totalFrames - 1)) * 100;
                playhead.style.left = `${playheadPercent}%`;
            }
            // Update current marker highlight
            document.querySelectorAll('.gt-marker').forEach(m => m.classList.remove('current'));
            document.querySelectorAll('.gt-marker').forEach(m => {
                if (m.querySelector('.gt-marker-tooltip')?.textContent.includes(`Frame ${currentFrame} `)) {
                    m.classList.add('current');
                }
            });
        }

        function updateAnnotationsPanel() {
            const panel = document.getElementById('annotationsPanel');
            if (annotations.length === 0) {
                panel.innerHTML = '<div style="color: #64748b; font-size: 0.8rem;">No annotations</div>';
                return;
            }
            panel.innerHTML = annotations.map((ann, idx) => `
                <div class="annotation-item" onmouseenter="highlightAnnotation(${idx})" onmouseleave="highlightAnnotation(-1)">
                    <span style="color: ${classColors[ann.label] || '#fff'}">${ann.label}</span>
                    <button class="delete-btn" onclick="deleteAnnotation(${idx})">√ó</button>
                </div>
            `).join('');
        }

        window.highlightAnnotation = function(idx) {
            hoveredAnnotation = idx;
            redraw();
        };

        window.deleteAnnotation = function(idx) {
            saveState();
            annotations.splice(idx, 1);
            redraw();
            updateAnnotationsPanel();
        };

        // Debug visualization - shows detected field lines with labels
        let debugMode = false;
        let debugOverlay = null;
        let debugLines = [];  // Store detected lines for interaction

        async function showDebugVisualization() {
            if (!currentImage) {
                setStatus('Load a video first');
                return;
            }

            setStatus('Detecting field lines...', 'saving');

            // Get frame as base64
            const offCanvas = document.createElement('canvas');
            offCanvas.width = currentImage.width;
            offCanvas.height = currentImage.height;
            const offCtx = offCanvas.getContext('2d');
            offCtx.drawImage(currentImage, 0, 0);
            const frameBase64 = offCanvas.toDataURL('image/jpeg', 0.9);

            try {
                // Call server-side line detection
                const response = await fetch('/api/tracking/detect_lines', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        frame_base64: frameBase64,
                        include_visualization: false  // We'll draw ourselves for interactivity
                    })
                });

                const result = await response.json();

                if (result.status !== 'success') {
                    throw new Error(result.message || 'Detection failed');
                }

                debugLines = result.lines || [];
                const matchedLines = result.matched_lines || [];
                const predictedCorners = result.predicted_corners;

                // Create debug overlay
                const debugCanvas = document.createElement('canvas');
                debugCanvas.width = currentImage.width;
                debugCanvas.height = currentImage.height;
                const debugCtx = debugCanvas.getContext('2d');

                // Draw original image with slight darkening
                debugCtx.drawImage(currentImage, 0, 0);
                debugCtx.fillStyle = 'rgba(0, 0, 0, 0.3)';
                debugCtx.fillRect(0, 0, debugCanvas.width, debugCanvas.height);

                // Color map for different line types
                const lineColors = {
                    'sideline': '#00ff00',      // Green
                    'goalline': '#0088ff',      // Blue
                    'center': '#ffff00',        // Yellow
                    'penalty': '#ff00ff',       // Magenta
                    'goal_area': '#ff8800',     // Orange
                    'default': '#888888'        // Gray for unmatched
                };

                // Draw all detected lines (gray for unmatched)
                debugCtx.lineWidth = 2;
                debugLines.forEach((line, idx) => {
                    debugCtx.strokeStyle = '#555555';
                    debugCtx.beginPath();
                    debugCtx.moveTo(line.x1, line.y1);
                    debugCtx.lineTo(line.x2, line.y2);
                    debugCtx.stroke();
                });

                // Draw matched lines with colors and labels
                const matchedSet = new Set(matchedLines);
                matchedLines.forEach(lineName => {
                    // Find corresponding detected line (by matching position)
                    // Server returns line names, we need to find which detected line matches
                    let color = lineColors.default;
                    for (const [key, c] of Object.entries(lineColors)) {
                        if (lineName.includes(key)) {
                            color = c;
                            break;
                        }
                    }

                    // Draw label
                    debugCtx.fillStyle = color;
                    debugCtx.font = 'bold 14px monospace';
                });

                // If we have predicted corners, draw them
                if (predictedCorners) {
                    debugCtx.strokeStyle = '#ff0000';
                    debugCtx.lineWidth = 3;
                    debugCtx.setLineDash([10, 5]);

                    // Draw quadrilateral
                    debugCtx.beginPath();
                    debugCtx.moveTo(predictedCorners[0][0], predictedCorners[0][1]);
                    debugCtx.lineTo(predictedCorners[1][0], predictedCorners[1][1]);
                    debugCtx.lineTo(predictedCorners[3][0], predictedCorners[3][1]);
                    debugCtx.lineTo(predictedCorners[2][0], predictedCorners[2][1]);
                    debugCtx.closePath();
                    debugCtx.stroke();
                    debugCtx.setLineDash([]);

                    // Draw corner points
                    const cornerNames = ['TL', 'TR', 'BL', 'BR'];
                    predictedCorners.forEach((corner, i) => {
                        debugCtx.fillStyle = '#ff0000';
                        debugCtx.beginPath();
                        debugCtx.arc(corner[0], corner[1], 8, 0, Math.PI * 2);
                        debugCtx.fill();

                        debugCtx.fillStyle = 'white';
                        debugCtx.font = 'bold 12px monospace';
                        debugCtx.fillText(cornerNames[i], corner[0] + 12, corner[1] + 4);
                    });
                }

                // Add legend
                debugCtx.fillStyle = 'rgba(0, 0, 0, 0.85)';
                debugCtx.fillRect(10, 10, 280, 160);
                debugCtx.fillStyle = 'white';
                debugCtx.font = 'bold 14px monospace';
                debugCtx.fillText('FIELD LINE DETECTION', 20, 32);

                debugCtx.font = '12px monospace';
                let y = 52;
                debugCtx.fillText(`Lines detected: ${debugLines.length}`, 20, y); y += 18;
                debugCtx.fillText(`Lines matched: ${matchedLines.length}`, 20, y); y += 18;

                if (matchedLines.length > 0) {
                    debugCtx.fillStyle = '#00ff00';
                    debugCtx.fillText('Matched:', 20, y); y += 16;
                    debugCtx.font = '10px monospace';
                    matchedLines.slice(0, 5).forEach(name => {
                        debugCtx.fillText('  ‚Ä¢ ' + name, 20, y);
                        y += 14;
                    });
                    if (matchedLines.length > 5) {
                        debugCtx.fillText(`  ... +${matchedLines.length - 5} more`, 20, y);
                    }
                }

                if (predictedCorners) {
                    debugCtx.fillStyle = '#ff0000';
                    debugCtx.fillText('‚úì Corners extrapolated from lines', 20, 155);
                } else {
                    debugCtx.fillStyle = '#ff8800';
                    debugCtx.fillText('‚úó Need more matched lines for corners', 20, 155);
                }

                // Store debug overlay
                debugOverlay = new Image();
                debugOverlay.onload = () => {
                    debugMode = true;
                    redraw();
                    setStatus(`Debug: ${debugLines.length} lines detected, ${matchedLines.length} matched to template`);
                };
                debugOverlay.src = debugCanvas.toDataURL();

            } catch (error) {
                console.error('Line detection error:', error);
                setStatus('Line detection failed: ' + error.message, 'error');
            }
        }

        function toggleDebugMode() {
            if (debugMode) {
                debugMode = false;
                debugOverlay = null;
                debugLines = [];
                redraw();
                setStatus('Debug mode off');
            } else {
                showDebugVisualization();
            }
        }

        function redraw() {
            if (!currentImage) return;

            // Clear with dark background (to see annotations outside frame)
            ctx.fillStyle = '#0a0a0a';
            ctx.fillRect(0, 0, canvas.width, canvas.height);

            // Apply viewport transform
            ctx.save();
            ctx.translate(viewOffsetX, viewOffsetY);
            ctx.scale(viewZoom, viewZoom);

            // Draw video frame (or debug overlay if enabled)
            if (debugMode && debugOverlay) {
                ctx.drawImage(debugOverlay, 0, 0, canvas.width, canvas.height);
            } else {
                ctx.drawImage(currentImage, 0, 0, canvas.width, canvas.height);
            }

            // Draw frame border to show bounds
            ctx.strokeStyle = 'rgba(255,255,255,0.3)';
            ctx.lineWidth = 1 / viewZoom;
            ctx.strokeRect(0, 0, canvas.width, canvas.height);

            annotations.forEach((ann, idx) => {
                const annMode = ann.mode || 'field';
                const modeClr = modeColors[annMode] || modeColors.field;
                const color = classColors[ann.label] || modeClr.gt;
                const isHovered = hoveredAnnotation === idx;
                // Points: mode-specific GT vs propagated colors
                const pointColor = ann.isGT !== false ? modeClr.gt : modeClr.prop;
                ctx.lineWidth = isHovered ? 3 : 2;

                if (ann.type === 'line') {
                    ctx.strokeStyle = isHovered ? '#fff' : color;
                    ctx.beginPath();
                    ann.points.forEach((p, i) => {
                        const x = p[0] * scale, y = p[1] * scale;
                        if (i === 0) ctx.moveTo(x, y);
                        else ctx.lineTo(x, y);
                    });
                    ctx.stroke();
                    // No dots/nodes on lines - cleaner look
                } else if (ann.type === 'ellipse') {
                    const cx = ann.center[0] * scale;
                    const cy = ann.center[1] * scale;
                    const rx = ann.axes[0] * scale;
                    const ry = ann.axes[1] * scale;
                    const angle = (ann.angle || 0) * Math.PI / 180;

                    // Support partial arcs (for penalty arcs) via startAngle/endAngle in degrees
                    const arcStart = ann.startAngle !== undefined ? ann.startAngle * Math.PI / 180 : 0;
                    const arcEnd = ann.endAngle !== undefined ? ann.endAngle * Math.PI / 180 : Math.PI * 2;

                    ctx.strokeStyle = isHovered ? '#fff' : color;
                    ctx.beginPath();
                    ctx.ellipse(cx, cy, rx, ry, angle, arcStart, arcEnd);
                    ctx.stroke();

                    // Draw edit handles (center, edge points, and rotation handle)
                    if (isHovered || hoveredAnnotation === idx) {
                        // Center handle
                        const isCenterHovered = hoveredPoint === 'center';
                        ctx.beginPath();
                        ctx.arc(cx, cy, isCenterHovered ? 6 : 4, 0, Math.PI * 2);
                        ctx.fillStyle = isCenterHovered ? '#ef4444' : pointColor;
                        ctx.fill();

                        // Edge handles (rotated)
                        const cos = Math.cos(angle), sin = Math.sin(angle);
                        const edgeOffsets = [[rx, 0], [-rx, 0], [0, ry], [0, -ry]];
                        edgeOffsets.forEach((off, epi) => {
                            const rotX = cx + off[0] * cos - off[1] * sin;
                            const rotY = cy + off[0] * sin + off[1] * cos;
                            const isEdgeHovered = hoveredPoint === 'edge' + epi;
                            ctx.beginPath();
                            ctx.arc(rotX, rotY, isEdgeHovered ? 6 : 4, 0, Math.PI * 2);
                            ctx.fillStyle = isEdgeHovered ? '#ef4444' : pointColor;
                            ctx.fill();
                        });

                        // Rotation handle (at top of ellipse + offset)
                        const rotHandleOffset = ry + 25;
                        const rotHandleX = cx - rotHandleOffset * sin;
                        const rotHandleY = cy + rotHandleOffset * cos;
                        const isRotHovered = hoveredPoint === 'rotate';

                        // Draw line to rotation handle
                        ctx.strokeStyle = 'rgba(255,255,255,0.5)';
                        ctx.lineWidth = 1;
                        ctx.beginPath();
                        ctx.moveTo(cx, cy - ry * cos);  // Top of ellipse
                        ctx.lineTo(rotHandleX, rotHandleY);
                        ctx.stroke();

                        // Rotation handle circle
                        ctx.beginPath();
                        ctx.arc(rotHandleX, rotHandleY, isRotHovered ? 7 : 5, 0, Math.PI * 2);
                        ctx.fillStyle = isRotHovered ? '#f97316' : '#facc15';
                        ctx.fill();
                        ctx.strokeStyle = '#fff';
                        ctx.lineWidth = 1;
                        ctx.stroke();
                    }
                } else if (ann.type === 'point') {
                    // Player or ball point - larger circle with label inside
                    const px = ann.point[0] * scale;
                    const py = ann.point[1] * scale;
                    const radius = annMode === 'ball' ? 8 : 12;

                    // Outer circle
                    ctx.beginPath();
                    ctx.arc(px, py, radius, 0, Math.PI * 2);
                    ctx.fillStyle = isHovered ? '#ef4444' : pointColor;
                    ctx.fill();
                    ctx.strokeStyle = isHovered ? '#fff' : '#000';
                    ctx.lineWidth = 2;
                    ctx.stroke();

                    // Label inside for players
                    if (annMode === 'player' && ann.label) {
                        ctx.font = 'bold 10px sans-serif';
                        ctx.fillStyle = '#fff';
                        ctx.textAlign = 'center';
                        ctx.textBaseline = 'middle';
                        ctx.fillText(ann.label, px, py);
                    }
                }

                // Label (for field annotations)
                if (ann.type !== 'point') {
                    const labelX = ann.points ? ann.points[0][0] * scale : ann.center[0] * scale;
                    const labelY = ann.points ? ann.points[0][1] * scale - 8 : ann.center[1] * scale - ann.axes[1] * scale - 8;
                    ctx.font = '11px sans-serif';
                    ctx.textAlign = 'left';
                    ctx.textBaseline = 'alphabetic';
                    ctx.fillStyle = color;
                    ctx.fillText(ann.label, labelX, labelY);
                }
            });

            // Temp points
            if (tempPoints.length > 0) {
                const modeClr = modeColors[currentMode] || modeColors.field;
                // Use class color once we have a valid line (2+ points)
                const lineColor = (tempPoints.length >= 2 && currentTool === 'line')
                    ? (classColors[currentClass] || modeClr.gt)
                    : '#fff';
                ctx.strokeStyle = lineColor;
                ctx.fillStyle = modeClr.gt;
                ctx.lineWidth = 2;
                if (currentTool === 'line') {
                    ctx.beginPath();
                    tempPoints.forEach((p, i) => {
                        if (i === 0) ctx.moveTo(p[0], p[1]);
                        else ctx.lineTo(p[0], p[1]);
                    });
                    ctx.stroke();
                }
                tempPoints.forEach(p => {
                    ctx.beginPath();
                    ctx.arc(p[0], p[1], 5, 0, Math.PI * 2);
                    ctx.fill();
                });

                // Show label preview for temp line
                if (tempPoints.length >= 2 && currentTool === 'line') {
                    ctx.font = '11px sans-serif';
                    ctx.fillStyle = lineColor;
                    ctx.textAlign = 'left';
                    ctx.fillText(currentClass, tempPoints[0][0], tempPoints[0][1] - 8);
                }
            }

            // Draw calibration points (if in calibration mode)
            drawCalibrationPoints(ctx);

            // Draw template anchor point handles (for drag-to-calibrate)
            drawTemplateAnchorHandles(ctx);

            // Restore context (undo viewport transform)
            ctx.restore();

            // Draw zoom indicator (outside viewport transform)
            if (viewZoom !== 1) {
                ctx.fillStyle = 'rgba(255,255,255,0.8)';
                ctx.font = '12px sans-serif';
                ctx.fillText(`Zoom: ${(viewZoom * 100).toFixed(0)}%  (R to reset)`, 10, canvas.height - 10);
            }
        }

        // Canvas events
        console.log('[init] Attaching canvas click listener');

        // Helper to get current position of a draggable point
        function getDragPointPosition(ann, pointId) {
            if (ann.type === 'line' && typeof pointId === 'number') {
                return [...ann.points[pointId]];
            } else if (ann.type === 'point') {
                return [...ann.point];
            } else if (ann.type === 'ellipse') {
                if (pointId === 'center') return [...ann.center];
                // Edge points - return the axis value
                return [...ann.center, ...ann.axes];
            }
            return null;
        }

        // Mouse down - start dragging if on a point or shape
        canvas.addEventListener('mousedown', (e) => {
            if (!currentImage) return;

            const rect = canvas.getBoundingClientRect();
            const canvasX = e.clientX - rect.left;
            const canvasY = e.clientY - rect.top;
            // Transform through viewport (zoom + offset) then to image coordinates
            const viewX = (canvasX - viewOffsetX) / viewZoom;
            const viewY = (canvasY - viewOffsetY) / viewZoom;
            const x = viewX / scale;
            const y = viewY / scale;

            // Check for anchor point drag first (for template calibration)
            const anchorHit = hitTestAnchorPoint(x, y);
            if (anchorHit && !calibrationMode) {
                console.log('[AnchorDrag] Hit anchor:', anchorHit.pointName, 'at', x.toFixed(0), y.toFixed(0));
                startAnchorDrag(anchorHit, x, y);
                e.preventDefault();
                return;
            }

            // Auto-switch tool based on annotation type when clicking on annotation
            if (hoveredAnnotation !== null) {
                const ann = annotations[hoveredAnnotation];
                // Only switch if using select tool or the matching tool
                if (currentTool === 'select') {
                    if (ann.type === 'ellipse') {
                        setTool('ellipse');
                    } else if (ann.type === 'line') {
                        setTool('line');
                    } else if (ann.type === 'point') {
                        setTool('point');
                    }
                }
            }

            // Allow dragging with any tool when hovering over an annotation
            if (hoveredAnnotation !== null && hoveredPoint !== null) {
                // Start dragging a specific point (line point, ellipse center/edge, etc.)
                const ann = annotations[hoveredAnnotation];
                isDragging = true;
                dragAnnotation = hoveredAnnotation;
                dragPoint = hoveredPoint;
                dragWasPropagated = ann.isGT === false;
                dragOriginalValue = getDragPointPosition(ann, hoveredPoint);
                const rect = canvas.getBoundingClientRect();
                dragStartPos = { x: e.clientX - rect.left, y: e.clientY - rect.top };
                saveState();
                e.preventDefault();
            } else if (hoveredAnnotation !== null && annotations[hoveredAnnotation].type === 'point') {
                // Start dragging a point annotation (player/ball)
                const ann = annotations[hoveredAnnotation];
                isDragging = true;
                dragAnnotation = hoveredAnnotation;
                dragPoint = 'single';
                dragWasPropagated = ann.isGT === false;
                dragOriginalValue = [...ann.point];
                const rect = canvas.getBoundingClientRect();
                dragStartPos = { x: e.clientX - rect.left, y: e.clientY - rect.top };
                saveState();
                e.preventDefault();
            } else if (hoveredAnnotation !== null && annotations[hoveredAnnotation].type === 'ellipse') {
                // Start dragging ellipse (move whole ellipse)
                const ann = annotations[hoveredAnnotation];
                isDragging = true;
                dragAnnotation = hoveredAnnotation;
                dragPoint = 'center';
                dragWasPropagated = ann.isGT === false;
                dragOriginalValue = [...ann.center];
                const rect = canvas.getBoundingClientRect();
                dragStartPos = { x: e.clientX - rect.left, y: e.clientY - rect.top };
                saveState();
                e.preventDefault();
            } else if (hoveredAnnotation !== null && annotations[hoveredAnnotation].type === 'line') {
                // Start dragging whole line (move all points together)
                const ann = annotations[hoveredAnnotation];
                isDragging = true;
                dragAnnotation = hoveredAnnotation;
                dragPoint = 'wholeLine';  // Special marker for moving whole line
                dragWasPropagated = ann.isGT === false;
                // Store all original points
                dragOriginalValue = ann.points.map(p => [...p]);
                const rect = canvas.getBoundingClientRect();
                dragStartPos = { x: e.clientX - rect.left, y: e.clientY - rect.top };
                saveState();
                e.preventDefault();
            }
        });

        // Mouse up - finish dragging
        canvas.addEventListener('mouseup', (e) => {
            // Handle anchor point drag end (for template calibration)
            if (draggingPoint) {
                const rect = canvas.getBoundingClientRect();
                const canvasX = e.clientX - rect.left;
                const canvasY = e.clientY - rect.top;
                const viewX = (canvasX - viewOffsetX) / viewZoom;
                const viewY = (canvasY - viewOffsetY) / viewZoom;
                const x = viewX / scale;
                const y = viewY / scale;
                endAnchorDrag(x, y);
                return;
            }

            if (isDragging && dragAnnotation !== null) {
                const ann = annotations[dragAnnotation];
                const mode = ann.mode || 'field';

                // Calculate drift correction if this was a propagated annotation
                if (dragWasPropagated && dragOriginalValue) {
                    let dx = 0, dy = 0;

                    if (ann.type === 'line' && typeof dragPoint === 'number') {
                        dx = ann.points[dragPoint][0] - dragOriginalValue[0];
                        dy = ann.points[dragPoint][1] - dragOriginalValue[1];
                    } else if (ann.type === 'line' && dragPoint === 'wholeLine') {
                        // Average drift from moving whole line
                        dx = ann.points[0][0] - dragOriginalValue[0][0];
                        dy = ann.points[0][1] - dragOriginalValue[0][1];
                    } else if (ann.type === 'point') {
                        dx = ann.point[0] - dragOriginalValue[0];
                        dy = ann.point[1] - dragOriginalValue[1];
                    } else if (ann.type === 'ellipse' && dragPoint === 'center') {
                        dx = ann.center[0] - dragOriginalValue[0];
                        dy = ann.center[1] - dragOriginalValue[1];
                    }

                    // Update drift correction with conservative learning
                    const magnitude = Math.sqrt(dx * dx + dy * dy);

                    // Only learn from corrections within reasonable bounds
                    // Too small = precision tweak, too large = scene cut/jump
                    if (magnitude >= DRIFT_CONFIG.minMagnitude && magnitude <= DRIFT_CONFIG.maxMagnitude) {
                        const dc = driftCorrections[mode];

                        // Check if this correction is consistent with pattern
                        if (dc.count > 0) {
                            const expectedDist = Math.sqrt(
                                Math.pow(dx - dc.dx, 2) +
                                Math.pow(dy - dc.dy, 2)
                            );
                            // Update variance estimate
                            dc.variance = dc.variance * DRIFT_CONFIG.decay + expectedDist * (1 - DRIFT_CONFIG.decay);

                            // Reject outliers (corrections very different from pattern)
                            if (expectedDist > DRIFT_CONFIG.maxVariance && dc.count >= DRIFT_CONFIG.minSamples) {
                                console.log(`[drift] ${mode}: REJECTED outlier (${dx.toFixed(1)}, ${dy.toFixed(1)}) - dist ${expectedDist.toFixed(1)} from avg`);
                            } else {
                                // Accept and learn
                                dc.dx = dc.dx * DRIFT_CONFIG.decay + dx * (1 - DRIFT_CONFIG.decay);
                                dc.dy = dc.dy * DRIFT_CONFIG.decay + dy * (1 - DRIFT_CONFIG.decay);
                                dc.count++;
                                console.log(`[drift] ${mode}: learned (${dc.dx.toFixed(1)}, ${dc.dy.toFixed(1)}) var=${dc.variance.toFixed(1)} samples=${dc.count}`);
                            }
                        } else {
                            // First correction - just store it
                            dc.dx = dx;
                            dc.dy = dy;
                            dc.count = 1;
                            console.log(`[drift] ${mode}: first sample (${dx.toFixed(1)}, ${dy.toFixed(1)})`);
                        }
                    } else if (magnitude > DRIFT_CONFIG.maxMagnitude) {
                        console.log(`[drift] ${mode}: IGNORED large correction (${dx.toFixed(1)}, ${dy.toFixed(1)}) mag=${magnitude.toFixed(1)} - likely scene cut`);
                    }

                    // Mark as GT
                    ann.isGT = true;
                }

                // Auto-save after drag edit
                saveCurrentFrame();
                setStatus('Edited and saved as GT', 'saved');
            }
            isDragging = false;
            dragAnnotation = null;
            dragPoint = null;
            dragStartPos = null;
            dragLastPos = null;  // Reset for next drag
        });

        canvas.addEventListener('click', (e) => {
            // Skip click if we just finished dragging
            if (dragStartPos !== null) return;

            console.log('[click] Click event received!');
            if (!currentImage) {
                console.log('[click] No currentImage, returning');
                return;
            }

            const rect = canvas.getBoundingClientRect();
            const canvasX = e.clientX - rect.left;
            const canvasY = e.clientY - rect.top;
            // Transform through viewport to get view-space coordinates
            const x = (canvasX - viewOffsetX) / viewZoom;
            const y = (canvasY - viewOffsetY) / viewZoom;

            // Handle calibration mode clicks FIRST
            if (calibrationMode) {
                if (handleCalibrationClick(x, y)) {
                    return;
                }
            }

            if (currentTool === 'magnifier') return;

            // Skip click if hovering over existing annotation (use for dragging instead)
            if (hoveredAnnotation !== null) {
                console.log('[click] Skipping - hovering over annotation for drag');
                return;
            }

            console.log(`[click] Tool=${currentTool}, mode=${currentMode}, x=${x.toFixed(0)}, y=${y.toFixed(0)}`);

            if (currentTool === 'select') {
                // Select tool now only deletes on explicit delete key, not click
                // Click does nothing in select mode (use for dragging)
            } else if (currentTool === 'point') {
                // Single point for player/ball tracking
                finishPoint(x, y);
            } else {
                tempPoints.push([x, y]);
                console.log(`[click] Added point, tempPoints now has ${tempPoints.length} points`);
                redraw();

                // Auto-finish ellipse at 4 points
                if (currentTool === 'ellipse' && tempPoints.length >= 4) {
                    finishEllipse();
                    return;
                }

                // Update status
                if (currentTool === 'line' && tempPoints.length >= 2) {
                    setStatus(`${tempPoints.length} points - Double-click or Enter to finish line`, '');
                } else if (currentTool === 'ellipse') {
                    setStatus(`${tempPoints.length}/4 points for ellipse`, '');
                }
            }
        });

        canvas.addEventListener('dblclick', () => {
            console.log(`[dblclick] Tool=${currentTool}, tempPoints.length=${tempPoints.length}`);
            if (currentTool === 'line' && tempPoints.length >= 2) finishLine();
        });

        canvas.addEventListener('contextmenu', (e) => {
            e.preventDefault();
            if (currentTool === 'ellipse' && tempPoints.length >= 3) finishEllipse();
            else if (currentTool === 'line' && tempPoints.length >= 2) finishLine();
        });

        canvas.addEventListener('mousemove', (e) => {
            if (isPanning) return;  // Skip if panning

            const rect = canvas.getBoundingClientRect();
            const canvasX = e.clientX - rect.left;
            const canvasY = e.clientY - rect.top;
            // Transform through viewport (zoom + offset) then to image coordinates
            const viewX = (canvasX - viewOffsetX) / viewZoom;
            const viewY = (canvasY - viewOffsetY) / viewZoom;
            const x = viewX / scale;
            const y = viewY / scale;

            // Handle anchor point dragging (for template calibration)
            if (draggingPoint) {
                updateAnchorDrag(x, y);
                return;
            }

            // Handle dragging
            if (isDragging && dragAnnotation !== null) {
                const ann = annotations[dragAnnotation];
                if (ann.type === 'line' && typeof dragPoint === 'number') {
                    // Check if this is a template point - if so, update entire template
                    if (ann.isTemplate && ann.templatePoints && ann.templatePoints[dragPoint]) {
                        const templatePointName = ann.templatePoints[dragPoint];

                        // SPECIAL: Center point drag = smooth pan (translation only)
                        if (templatePointName === 'center_mid' || templatePointName === 'center_top' || templatePointName === 'center_bottom') {
                            // Calculate delta from last position for smooth panning
                            if (!dragLastPos) dragLastPos = { x: x * scale, y: y * scale };
                            const dx = x - dragLastPos.x / scale;
                            const dy = y - dragLastPos.y / scale;
                            dragLastPos = { x: x * scale, y: y * scale };

                            // Apply pure translation to ALL field annotations (no rotation/perspective change)
                            panFieldTemplate(dx, dy);
                        } else {
                            // Corner/edge points use homography update
                            updateFieldTemplateFromDrag(templatePointName, x, y);
                        }
                    } else {
                        ann.points[dragPoint] = [x, y];
                    }
                } else if (ann.type === 'line' && dragPoint === 'wholeLine') {
                    // Move entire line - compute delta from start position
                    const dx = x - dragStartPos.x / scale;
                    const dy = y - dragStartPos.y / scale;

                    if (ann.isTemplate) {
                        // ALL template line drags = pan entire field in X and Z
                        // This allows smooth correction of field position without breaking geometry
                        // Maintains rotation relative to viewpoint
                        const sensitivity = 0.5;
                        // Horizontal drag = pan field left/right (offsetX in pixels)
                        field3D.offsetX = field3D.offsetX + dx * sensitivity;
                        // Vertical drag = move field closer/further (offsetZ in meters)
                        const dzMeters = dy / field3D.scale * sensitivity;
                        field3D.offsetZ = Math.max(-30, Math.min(30, field3D.offsetZ + dzMeters));
                        update3DTemplate();

                        // Update dragStartPos for smooth continuous dragging
                        dragStartPos = { x: x * scale, y: y * scale };
                    } else {
                        ann.points = dragOriginalValue.map(p => [p[0] + dx, p[1] + dy]);
                    }
                } else if (ann.type === 'point' && dragPoint === 'single') {
                    ann.point = [x, y];
                } else if (ann.type === 'ellipse') {
                    if (dragPoint === 'center') {
                        // Template ellipses: dragging center circle pans the ENTIRE field
                        if (ann.isTemplate && ann.templateCenter === 'center_mid') {
                            // Dragging center circle = pan entire field (smooth translation)
                            if (!dragLastPos) dragLastPos = { x: x * scale, y: y * scale };
                            const dx = x - dragLastPos.x / scale;
                            const dy = y - dragLastPos.y / scale;
                            dragLastPos = { x: x * scale, y: y * scale };
                            panFieldTemplate(dx, dy);
                        } else if (ann.isTemplate) {
                            // Other template ellipses (penalty arcs) stay fixed
                        } else if (ann.templateCenter) {
                            updateFieldTemplateFromDrag(ann.templateCenter, x, y);
                        } else {
                            ann.center = [x, y];
                        }
                    } else if (dragPoint === 'rotate') {
                        // Template ellipses should NOT be rotated - skip rotation for them
                        if (ann.isTemplate) {
                            // Do nothing - template ellipses maintain field geometry
                        } else {
                            // Rotate ellipse - calculate angle from center to mouse
                            const dx = x - ann.center[0];
                            const dy = y - ann.center[1];
                            // atan2 gives angle from positive X axis, we want from positive Y axis
                            // and we want degrees, converted so 0 = ellipse pointing up
                            let newAngle = Math.atan2(dx, -dy) * 180 / Math.PI;
                            ann.angle = newAngle;
                        }
                    } else if (dragPoint.startsWith('edge')) {
                        // Edge resizing
                        if (ann.isTemplate && ann.elementType === 'centerCircle') {
                            // Center circle - fixed 10 yard radius (FIFA standard), cannot resize
                        } else if (!ann.isTemplate) {
                            // Non-template ellipse: resize individual axis
                            const cos = Math.cos((ann.angle || 0) * Math.PI / 180);
                            const sin = Math.sin((ann.angle || 0) * Math.PI / 180);
                            if (dragPoint === 'edge0' || dragPoint === 'edge1') {
                                // X radius
                                const localX = (x - ann.center[0]) * cos + (y - ann.center[1]) * sin;
                                ann.axes[0] = Math.max(10, Math.abs(localX));
                            } else {
                                // Y radius
                                const localY = -(x - ann.center[0]) * sin + (y - ann.center[1]) * cos;
                                ann.axes[1] = Math.max(10, Math.abs(localY));
                            }
                        }
                    }
                }
                redraw();
                return;  // Skip hover detection while dragging
            }

            // Magnifier functionality
            if (magnifierActive && currentImage) {
                magnifier.style.display = 'block';
                const containerRect = canvas.parentElement.getBoundingClientRect();
                magnifier.style.left = (e.clientX - containerRect.left + 20) + 'px';
                magnifier.style.top = (e.clientY - containerRect.top - 75) + 'px';

                // Draw zoomed view
                const magSize = 150;
                const srcSize = magSize / MAG_ZOOM;
                magCtx.clearRect(0, 0, magSize, magSize);
                magCtx.drawImage(
                    currentImage,
                    x - srcSize / 2, y - srcSize / 2, srcSize, srcSize,
                    0, 0, magSize, magSize
                );

                // Draw crosshair
                magCtx.strokeStyle = '#e94560';
                magCtx.lineWidth = 1;
                magCtx.beginPath();
                magCtx.moveTo(magSize / 2, 0);
                magCtx.lineTo(magSize / 2, magSize);
                magCtx.moveTo(0, magSize / 2);
                magCtx.lineTo(magSize, magSize / 2);
                magCtx.stroke();
            } else {
                magnifier.style.display = 'none';
            }

            hoveredAnnotation = null;
            hoveredPoint = null;

            // Check for hover over anchor points first (for template calibration)
            const anchorHit = hitTestAnchorPoint(x, y);
            if (anchorHit) {
                canvas.style.cursor = 'grab';
                redraw();
                return;  // Don't process other hovers when on anchor
            }

            // Check for hover over points, lines, or point annotations
            annotations.forEach((ann, idx) => {
                if (ann.type === 'line') {
                    ann.points.forEach((p, pi) => {
                        if (Math.hypot(p[0] - x, p[1] - y) < 10) {
                            hoveredAnnotation = idx;
                            hoveredPoint = pi;
                        }
                    });
                    // Check line segments
                    if (hoveredAnnotation === null) {
                        for (let i = 0; i < ann.points.length - 1; i++) {
                            const p1 = ann.points[i], p2 = ann.points[i + 1];
                            const dist = pointToLineDistance(x, y, p1[0], p1[1], p2[0], p2[1]);
                            if (dist < 8) {
                                hoveredAnnotation = idx;
                                break;
                            }
                        }
                    }
                } else if (ann.type === 'ellipse') {
                    // Check center and edge points for ellipse (with rotation)
                    const cx = ann.center[0], cy = ann.center[1];
                    const rx = ann.axes[0], ry = ann.axes[1];
                    const angle = (ann.angle || 0) * Math.PI / 180;
                    const cos = Math.cos(angle), sin = Math.sin(angle);

                    // Check center
                    if (Math.hypot(cx - x, cy - y) < 10) {
                        hoveredAnnotation = idx;
                        hoveredPoint = 'center';
                    }

                    // Check rotation handle
                    if (hoveredAnnotation === null) {
                        const rotHandleOffset = ry + 25 / scale;
                        const rotHandleX = cx - rotHandleOffset * sin;
                        const rotHandleY = cy + rotHandleOffset * cos;
                        if (Math.hypot(rotHandleX - x, rotHandleY - y) < 12) {
                            hoveredAnnotation = idx;
                            hoveredPoint = 'rotate';
                        }
                    }

                    // Check edge points (rotated)
                    if (hoveredAnnotation === null) {
                        const edgeOffsets = [[rx, 0], [-rx, 0], [0, ry], [0, -ry]];
                        edgeOffsets.forEach((off, epi) => {
                            const rotX = cx + off[0] * cos - off[1] * sin;
                            const rotY = cy + off[0] * sin + off[1] * cos;
                            if (Math.hypot(rotX - x, rotY - y) < 10) {
                                hoveredAnnotation = idx;
                                hoveredPoint = 'edge' + epi;
                            }
                        });
                    }
                    // Check ellipse outline
                    if (hoveredAnnotation === null) {
                        const dist = Math.hypot(cx - x, cy - y);
                        if (dist < Math.max(rx, ry) + 10 && dist > Math.min(rx, ry) - 10) {
                            hoveredAnnotation = idx;
                        }
                    }
                } else if (ann.type === 'point') {
                    // Single point annotation (player/ball)
                    const dist = Math.hypot(ann.point[0] - x, ann.point[1] - y);
                    if (dist < 15) {
                        hoveredAnnotation = idx;
                    }
                }
            });

            // Update cursor and delete hint
            if (isDragging) {
                canvas.style.cursor = 'grabbing';
                deleteHint.style.display = 'none';
            } else if (hoveredAnnotation !== null && hoveredPoint !== null) {
                // Hovering over a draggable point
                canvas.style.cursor = 'grab';
                deleteHint.style.display = 'none';
            } else if (currentTool === 'select' && hoveredAnnotation !== null) {
                canvas.style.cursor = 'grab';
                deleteHint.textContent = 'Drag to edit, Delete to remove';
                deleteHint.style.display = 'block';
                deleteHint.style.left = (e.clientX - canvas.parentElement.getBoundingClientRect().left + 15) + 'px';
                deleteHint.style.top = (e.clientY - canvas.parentElement.getBoundingClientRect().top - 10) + 'px';
            } else if (magnifierActive) {
                canvas.style.cursor = 'none';
                deleteHint.style.display = 'none';
            } else {
                canvas.style.cursor = 'crosshair';
                deleteHint.style.display = 'none';
            }

            redraw();
        });

        // Mouse wheel zoom
        canvas.addEventListener('wheel', (e) => {
            e.preventDefault();

            const rect = canvas.getBoundingClientRect();
            const mouseX = e.clientX - rect.left;
            const mouseY = e.clientY - rect.top;

            // Zoom factor
            const zoomDelta = e.deltaY > 0 ? 0.9 : 1.1;
            const newZoom = Math.max(MIN_VIEW_ZOOM, Math.min(MAX_VIEW_ZOOM, viewZoom * zoomDelta));

            if (newZoom !== viewZoom) {
                // Adjust offset to zoom toward mouse position
                const zoomRatio = newZoom / viewZoom;
                viewOffsetX = mouseX - (mouseX - viewOffsetX) * zoomRatio;
                viewOffsetY = mouseY - (mouseY - viewOffsetY) * zoomRatio;
                viewZoom = newZoom;

                console.log(`[zoom] viewZoom=${viewZoom.toFixed(2)}, offset=(${viewOffsetX.toFixed(0)}, ${viewOffsetY.toFixed(0)})`);
                redraw();
            }
        }, { passive: false });

        // Middle mouse button pan
        let isPanning = false;
        let panStartX = 0, panStartY = 0;

        canvas.addEventListener('mousedown', (e) => {
            if (e.button === 1) {  // Middle mouse button
                e.preventDefault();
                isPanning = true;
                panStartX = e.clientX - viewOffsetX;
                panStartY = e.clientY - viewOffsetY;
                canvas.style.cursor = 'move';
            }
        });

        canvas.addEventListener('mousemove', (e) => {
            if (isPanning) {
                viewOffsetX = e.clientX - panStartX;
                viewOffsetY = e.clientY - panStartY;
                redraw();
            }
        });

        canvas.addEventListener('mouseup', (e) => {
            if (e.button === 1 && isPanning) {
                isPanning = false;
                canvas.style.cursor = 'crosshair';
            }
        });

        // Reset view with 'r' key
        document.addEventListener('keydown', (e) => {
            if (e.key === 'r' && !e.metaKey && !e.ctrlKey) {
                viewZoom = 1;
                viewOffsetX = 0;
                viewOffsetY = 0;
                redraw();
                setStatus('View reset', '');
            }
        });

        function pointToLineDistance(px, py, x1, y1, x2, y2) {
            const A = px - x1, B = py - y1, C = x2 - x1, D = y2 - y1;
            const dot = A * C + B * D;
            const lenSq = C * C + D * D;
            let param = lenSq !== 0 ? dot / lenSq : -1;
            let xx, yy;
            if (param < 0) { xx = x1; yy = y1; }
            else if (param > 1) { xx = x2; yy = y2; }
            else { xx = x1 + param * C; yy = y1 + param * D; }
            return Math.hypot(px - xx, py - yy);
        }

        // Keyboard
        document.addEventListener('keydown', (e) => {
            if (e.key === 'Enter') {
                if (currentTool === 'line' && tempPoints.length >= 2) finishLine();
                else if (currentTool === 'ellipse' && tempPoints.length >= 3) finishEllipse();
            } else if (e.key === 'Escape') {
                // Cancel anchor drag or clear pinned points
                if (draggingPoint && calibrateDragStart) {
                    // Cancel drag - restore to original position
                    const templateAnns = annotations.filter(a => a.isTemplate && a.templatePoints);
                    for (const ann of templateAnns) {
                        const idx = ann.templatePoints?.indexOf(draggingPoint);
                        if (idx !== -1 && idx !== undefined && ann.points[idx]) {
                            ann.points[idx] = [calibrateDragStart.x, calibrateDragStart.y];
                        }
                    }
                    draggingPoint = null;
                    calibrateDragStart = null;
                    redraw();
                } else if (countPinnedPoints() > 0) {
                    // Clear all pinned points
                    resetAnchorAdjustments();
                } else {
                    tempPoints = [];
                    redraw();
                }
            } else if (e.key === 'ArrowRight') {
                e.preventDefault();
                navigateFrame(1);
            } else if (e.key === 'ArrowLeft') {
                e.preventDefault();
                navigateFrame(-1);
            } else if (e.key === ' ') {
                e.preventDefault();
                togglePlay();
            } else if (e.key === 'z' && (e.metaKey || e.ctrlKey) && e.shiftKey) {
                e.preventDefault();
                redo();
            } else if (e.key === 'z' && (e.metaKey || e.ctrlKey)) {
                e.preventDefault();
                undo();
            } else if (e.key === 's' && (e.metaKey || e.ctrlKey)) {
                e.preventDefault();
                console.log('[Cmd+S] Saving...');
                saveCurrentFrame();
            } else if (e.key === 'Delete' || e.key === 'Backspace') {
                if (hoveredAnnotation !== null && hoveredPoint !== null) {
                    // Delete individual point
                    saveState();
                    const ann = annotations[hoveredAnnotation];
                    if (ann.type === 'line' && ann.points.length > 2) {
                        ann.points.splice(hoveredPoint, 1);
                    } else {
                        // If only 2 points left, delete whole line
                        annotations.splice(hoveredAnnotation, 1);
                    }
                    hoveredAnnotation = null;
                    hoveredPoint = null;
                    redraw();
                    updateAnnotationsPanel();
                } else if (hoveredAnnotation !== null) {
                    // Delete whole annotation
                    saveState();
                    annotations.splice(hoveredAnnotation, 1);
                    hoveredAnnotation = null;
                    redraw();
                    updateAnnotationsPanel();
                }
            } else if (e.key === '+' || e.key === '=') {
                // Zoom in timeline
                zoomTimeline(1);
            } else if (e.key === '-' || e.key === '_') {
                // Zoom out timeline
                zoomTimeline(-1);
            }
        });

        function navigateFrame(delta) {
            const newFrame = Math.max(0, Math.min(totalFrames - 1, currentFrame + delta));
            if (newFrame !== currentFrame) loadFrame(newFrame);
        }

        function finishLine() {
            if (tempPoints.length < 2) return;
            saveState();
            const newAnn = {
                type: 'line',
                label: currentClass,
                points: tempPoints.map(p => [p[0] / scale, p[1] / scale]),
                mode: currentMode,
                isGT: true  // Ground truth - manually annotated
            };
            annotations.push(newAnn);
            console.log(`[finishLine] Added annotation:`, newAnn);
            console.log(`[finishLine] Total annotations: ${annotations.length}`);
            tempPoints = [];
            redraw();
            updateAnnotationsPanel();
            // Auto-save after finishing line
            saveCurrentFrame();
        }

        function finishEllipse() {
            if (tempPoints.length < 3) return;
            saveState();
            const realPoints = tempPoints.map(p => [p[0] / scale, p[1] / scale]);
            const xs = realPoints.map(p => p[0]), ys = realPoints.map(p => p[1]);
            const centerX = (Math.min(...xs) + Math.max(...xs)) / 2;
            const centerY = (Math.min(...ys) + Math.max(...ys)) / 2;
            const radiusX = (Math.max(...xs) - Math.min(...xs)) / 2;
            const radiusY = (Math.max(...ys) - Math.min(...ys)) / 2;

            annotations.push({
                type: 'ellipse',
                label: currentClass,
                center: [centerX, centerY],
                axes: [Math.max(radiusX, 10), Math.max(radiusY, 10)],
                angle: 0,
                mode: currentMode,
                isGT: true  // Ground truth - manually annotated
            });
            tempPoints = [];
            redraw();
            updateAnnotationsPanel();
            // Auto-save after finishing ellipse
            saveCurrentFrame();
        }

        function finishPoint(x, y) {
            // Single point annotation for player or ball tracking
            saveState();
            let label = '';
            if (currentMode === 'player') {
                label = playerNumber || '?';
            } else if (currentMode === 'ball') {
                label = 'ball';
            } else {
                label = currentClass;
            }

            const newAnn = {
                type: 'point',
                label: label,
                point: [x / scale, y / scale],
                mode: currentMode,
                isGT: true
            };
            annotations.push(newAnn);
            console.log(`[finishPoint] Added ${currentMode} point:`, newAnn);
            redraw();
            updateAnnotationsPanel();
            saveCurrentFrame();
        }

        // Playback
        function togglePlay() {
            if (isPlaying) {
                stopPlay();
            } else {
                startPlay();
            }
        }

        // Frame image cache for fast playback
        let frameImageCache = {};  // { frameNum: Image }
        let prefetchInProgress = false;

        async function startPlay() {
            isPlaying = true;
            document.getElementById('playBtn').textContent = '‚è∏ Pause';
            document.getElementById('playBtn').classList.add('playing');

            // Start prefetching frames in background
            prefetchFrames(currentFrame, 30);

            // Use requestAnimationFrame for smoother playback
            let lastFrameTime = performance.now();
            const frameInterval = 1000 / fps;

            function playLoop(timestamp) {
                if (!isPlaying) return;

                const elapsed = timestamp - lastFrameTime;
                if (elapsed >= frameInterval) {
                    lastFrameTime = timestamp - (elapsed % frameInterval);

                    if (currentFrame >= totalFrames - 1) {
                        stopPlay();
                        return;
                    }

                    // Load next frame fast (non-blocking)
                    loadFrameFast(currentFrame + 1);

                    // Continue prefetching ahead
                    if (currentFrame % 10 === 0) {
                        prefetchFrames(currentFrame + 10, 20);
                    }
                }

                requestAnimationFrame(playLoop);
            }

            requestAnimationFrame(playLoop);
        }

        // Prefetch frame images into cache
        async function prefetchFrames(startFrame, count) {
            if (prefetchInProgress) return;
            prefetchInProgress = true;

            const endFrame = Math.min(startFrame + count, totalFrames - 1);
            const promises = [];

            for (let f = startFrame; f <= endFrame; f++) {
                if (!frameImageCache[f]) {
                    promises.push(
                        fetch(`/api/video/${encodeURIComponent(currentVideo)}/frame/${f}?quality=60`)
                            .then(r => r.json())
                            .then(data => {
                                const img = new Image();
                                img.src = 'data:image/jpeg;base64,' + data.frame;
                                frameImageCache[f] = img;
                            })
                            .catch(() => {})
                    );
                }
            }

            await Promise.all(promises);
            prefetchInProgress = false;
        }

        // Fast frame loading - uses cached image if available, with motion tracking
        function loadFrameFast(frameNum) {
            const prevFrame = currentFrame;
            const prevImage = currentImage;
            const prevAnnotations = [...annotations];
            currentFrame = frameNum;

            // Check if we have cached image
            if (frameImageCache[frameNum] && frameImageCache[frameNum].complete) {
                currentImage = frameImageCache[frameNum];
                scale = canvas.width / currentImage.width;

                // Use interpolated annotations if between GT keyframes
                if (hasCachedFrame(frameNum) && propagationCache[frameNum].interpolated) {
                    annotations = propagationCache[frameNum].annotations || [];
                } else if (hasCachedFrame(frameNum) && propagationCache[frameNum].isGT) {
                    annotations = propagationCache[frameNum].annotations || [];
                } else {
                    // Apply motion tracking from previous frame
                    applyMotionTracking(prevImage, currentImage, prevAnnotations, frameNum);
                }

                currentFrameEdited = false;
                frameSlider.value = currentFrame;
                redraw();
            } else {
                // Fetch frame image (fire and forget for speed)
                fetch(`/api/video/${encodeURIComponent(currentVideo)}/frame/${frameNum}?quality=60`)
                    .then(r => r.json())
                    .then(data => {
                        const img = new Image();
                        img.onload = () => {
                            if (currentFrame === frameNum) {  // Still on this frame
                                currentImage = img;
                                scale = canvas.width / img.width;
                                frameImageCache[frameNum] = img;

                                // Use interpolated or apply motion tracking
                                if (hasCachedFrame(frameNum) && (propagationCache[frameNum].interpolated || propagationCache[frameNum].isGT)) {
                                    annotations = propagationCache[frameNum].annotations || [];
                                } else {
                                    applyMotionTracking(prevImage, currentImage, prevAnnotations, frameNum);
                                }

                                currentFrameEdited = false;
                                frameSlider.value = currentFrame;
                                redraw();
                            }
                        };
                        img.src = 'data:image/jpeg;base64,' + data.frame;
                    });
            }
        }

        // Apply motion tracking between frames
        function applyMotionTracking(prevImage, currImage, prevAnnotations, frameNum) {
            if (!prevImage || !currImage || prevAnnotations.length === 0) {
                return;
            }

            // Get field annotations
            const fieldAnns = prevAnnotations.filter(a => (a.mode || 'field') === 'field');
            if (fieldAnns.length === 0) {
                annotations = [...prevAnnotations];
                return;
            }

            // Try SOTACV optical flow tracking
            if (SOTACV && RigidTemplate.isInitialized()) {
                try {
                    const result = SOTACV.propagateTemplate(
                        getImageData(prevImage),
                        getImageData(currImage),
                        fieldAnns
                    );

                    if (result && result.annotations) {
                        annotations = result.annotations;
                        // Cache for later use
                        propagationCache[frameNum] = {
                            annotations: result.annotations,
                            corners: extractCornersFromAnnotations(result.annotations),
                            isGT: false,
                            tracked: true
                        };
                        return;
                    }
                } catch (e) {
                    console.log('[Motion] SOTACV failed:', e.message);
                }
            }

            // Fallback: copy previous annotations (no motion)
            annotations = [...prevAnnotations];
        }

        // Helper to get image data from Image object
        function getImageData(img) {
            if (!img) return null;
            const tempCanvas = document.createElement('canvas');
            tempCanvas.width = img.width;
            tempCanvas.height = img.height;
            const tempCtx = tempCanvas.getContext('2d');
            tempCtx.drawImage(img, 0, 0);
            return tempCtx.getImageData(0, 0, img.width, img.height);
        }

        function stopPlay() {
            isPlaying = false;
            document.getElementById('playBtn').textContent = '‚ñ∂ Play';
            document.getElementById('playBtn').classList.remove('playing');
            if (playInterval) clearInterval(playInterval);
        }

        // Mode selection
        document.querySelectorAll('.mode-btn').forEach(btn => {
            btn.addEventListener('click', () => {
                // Auto-finish any pending line/ellipse before switching modes
                if (currentTool === 'line' && tempPoints.length >= 2) finishLine();
                if (currentTool === 'ellipse' && tempPoints.length >= 3) finishEllipse();
                tempPoints = [];

                document.querySelectorAll('.mode-btn').forEach(b => b.classList.remove('active'));
                btn.classList.add('active');
                currentMode = btn.dataset.mode;

                // Show/hide player number input
                const playerInput = document.getElementById('playerInput');
                playerInput.classList.toggle('show', currentMode === 'player');

                // Update class label based on mode
                const classLabel = document.getElementById('classLabel');
                const classSelector = document.getElementById('classSelector');
                if (currentMode === 'field') {
                    classLabel.textContent = 'Pitch Element';
                    classSelector.style.display = 'block';
                } else {
                    classLabel.textContent = currentMode === 'player' ? 'Player' : 'Ball';
                    classSelector.style.display = 'none';
                }

                // Auto-select point tool for player/ball modes
                if (currentMode !== 'field') {
                    document.querySelectorAll('.tool-btn').forEach(b => b.classList.remove('active'));
                    document.querySelector('.tool-btn[data-tool="point"]').classList.add('active');
                    currentTool = 'point';
                } else {
                    document.querySelectorAll('.tool-btn').forEach(b => b.classList.remove('active'));
                    document.querySelector('.tool-btn[data-tool="select"]').classList.add('active');
                    currentTool = 'select';
                }

                redraw();
            });
        });

        // Player number input
        document.getElementById('playerNumber').addEventListener('input', (e) => {
            playerNumber = e.target.value.trim();
        });

        // Tool/class selection
        document.querySelectorAll('.tool-btn').forEach(btn => {
            btn.addEventListener('click', () => {
                // Auto-finish any pending line/ellipse before switching tools
                if (currentTool === 'line' && tempPoints.length >= 2) finishLine();
                if (currentTool === 'ellipse' && tempPoints.length >= 3) finishEllipse();

                document.querySelectorAll('.tool-btn').forEach(b => b.classList.remove('active'));
                btn.classList.add('active');
                currentTool = btn.dataset.tool;
                tempPoints = [];

                // Show/hide magnifier
                if (currentTool === 'magnifier') {
                    magnifierActive = true;
                } else {
                    magnifierActive = false;
                    magnifier.style.display = 'none';
                }

                redraw();
            });
        });

        document.querySelectorAll('.class-item').forEach(item => {
            item.addEventListener('click', () => {
                document.querySelectorAll('.class-item').forEach(i => i.classList.remove('selected'));
                item.classList.add('selected');
                currentClass = item.dataset.class;
            });
        });

        // Navigation buttons
        document.getElementById('playBtn').onclick = togglePlay;
        document.getElementById('prevFrame').onclick = () => navigateFrame(-1);
        document.getElementById('nextFrame').onclick = () => navigateFrame(1);
        document.getElementById('prevKeyframe').onclick = () => {
            const prev = keyframes.filter(k => k < currentFrame).pop();
            if (prev !== undefined) loadFrame(prev, false);
        };
        document.getElementById('nextKeyframe').onclick = () => {
            const next = keyframes.find(k => k > currentFrame);
            if (next !== undefined) loadFrame(next, false);
        };
        frameSlider.addEventListener('input', () => loadFrame(parseInt(frameSlider.value), false));

        // Action buttons
        document.getElementById('undoBtn').onclick = undo;
        document.getElementById('redoBtn').onclick = redo;
        document.getElementById('saveBtn').onclick = () => {
            // Auto-finish any pending line/ellipse before saving
            if (currentTool === 'line' && tempPoints.length >= 2) finishLine();
            if (currentTool === 'ellipse' && tempPoints.length >= 3) finishEllipse();
            console.log('[saveBtn] Clicked, annotations.length=' + annotations.length);
            saveCurrentFrame();
        };

        // Learn button - trains the model from current GT annotations
        document.getElementById('learnBtn').onclick = async () => {
            if (!currentImage) {
                setStatus('Load a video first');
                return;
            }

            // Check for field annotations on current frame
            // Accept both GT annotations AND template annotations (user edited the template = implicit GT)
            let gtAnnotations = annotations.filter(a => (a.mode || 'field') === 'field' && a.isGT === true);

            // If no explicit GT, use template annotations (user has positioned them)
            if (gtAnnotations.length === 0) {
                gtAnnotations = annotations.filter(a => (a.mode || 'field') === 'field' && a.isTemplate === true);
                if (gtAnnotations.length > 0) {
                    // Mark these as GT since user is explicitly learning from them
                    gtAnnotations.forEach(a => a.isGT = true);
                    console.log('[Learn] Promoted', gtAnnotations.length, 'template annotations to GT');
                }
            }

            if (gtAnnotations.length === 0) {
                setStatus('No field annotations on this frame - load template first');
                return;
            }

            setStatus('Learning from GT...', 'saving');

            try {
                // Extract GT corner positions from annotations
                const corners = extractCornersFromAnnotations(gtAnnotations);
                if (!corners) {
                    setStatus('Could not extract corners from annotations');
                    return;
                }

                // Learn this video+frame combination (instant - no gradient descent)
                const numExamples = FieldPositionModel.learn(currentImage, corners, currentVideo, Camera3D, currentFrame);

                const stats = FieldPositionModel.getStats();
                setStatus(`Learned! Frame ${currentFrame} - ${stats.samples} examples from ${stats.videos} videos`, 'saved');

            } catch (e) {
                console.error('[Learn] Error:', e);
                setStatus('Learning failed: ' + e.message);
            }
        };

        // Debug button - shows detected lines and features
        document.getElementById('debugBtn').onclick = toggleDebugMode;

        // Bulk Learn button - learns from ALL saved GT annotations by loading video frames
        document.getElementById('bulkLearnBtn').onclick = async () => {
            setStatus('Bulk learning - loading video frames...', 'saving');

            try {
                // Fetch list of all annotation files
                const resp = await fetch('/api/annotations/list');
                if (!resp.ok) throw new Error('Failed to fetch annotation list');
                const files = await resp.json();

                let totalLearned = 0;
                let processedVideos = 0;

                for (const filename of files) {
                    try {
                        // Get video name from annotation filename
                        const videoName = filename.replace('.json', '');

                        // Fetch annotation data
                        const annResp = await fetch(`/api/annotations/${encodeURIComponent(filename)}`);
                        if (!annResp.ok) continue;
                        const annData = await annResp.json();

                        const frames = annData.frames || {};

                        // Find first frame with GT annotations
                        let gtFrame = null;
                        let gtAnns = null;

                        for (const [frameNum, frameAnns] of Object.entries(frames)) {
                            if (!Array.isArray(frameAnns)) continue;

                            const fieldAnns = frameAnns.filter(a =>
                                (a.mode || 'field') === 'field' &&
                                (a.isGT === true || a.isTemplate === true)
                            );

                            if (fieldAnns.length > 0) {
                                gtFrame = parseInt(frameNum);
                                gtAnns = fieldAnns;
                                break;  // Use first GT frame
                            }
                        }

                        if (gtFrame === null || !gtAnns) continue;

                        // Extract corners
                        const corners = extractCornersFromAnnotations(gtAnns);
                        if (!corners) continue;

                        // Load actual video frame for visual features
                        const frameResp = await fetch(`/api/video/${encodeURIComponent(videoName)}/frame/${gtFrame}`);
                        if (!frameResp.ok) continue;
                        const frameData = await frameResp.json();

                        // Create image from base64
                        const img = new Image();
                        await new Promise((resolve, reject) => {
                            img.onload = resolve;
                            img.onerror = reject;
                            img.src = 'data:image/jpeg;base64,' + frameData.frame;
                        });

                        // Learn from this video frame
                        FieldPositionModel.learn(img, corners, videoName);
                        totalLearned++;
                        processedVideos++;

                        setStatus(`Bulk learning... ${processedVideos}/${files.length} videos`, 'saving');

                    } catch (e) {
                        console.error('[BulkLearn] Error processing', filename, e);
                    }
                }

                const stats = FieldPositionModel.getStats();
                setStatus(`Bulk learning complete! ${totalLearned} videos learned. Total: ${stats.samples} examples from ${stats.videos} videos`, 'saved');
                console.log('[BulkLearn] Complete:', stats);

            } catch (e) {
                console.error('[BulkLearn] Error:', e);
                setStatus('Bulk learning failed: ' + e.message);
            }
        };

        // Helper: Extract corner positions from field annotations
        function extractCornersFromAnnotations(fieldAnns) {
            const corners = {};
            const cornerNames = ['corner_tl', 'corner_tr', 'corner_bl', 'corner_br'];

            // Method 1: Extract from templatePoints
            fieldAnns.forEach(ann => {
                if (ann.type !== 'line' || !ann.templatePoints || !ann.points) return;
                ann.templatePoints.forEach((ptName, idx) => {
                    if (cornerNames.includes(ptName) && idx < ann.points.length) {
                        corners[ptName] = { x: ann.points[idx][0], y: ann.points[idx][1] };
                    }
                });
            });

            if (Object.keys(corners).length >= 4) {
                console.log('[extractCorners] Found all 4 corners from templatePoints');
                return {
                    topLeft: corners.corner_tl,
                    topRight: corners.corner_tr,
                    bottomLeft: corners.corner_bl,
                    bottomRight: corners.corner_br
                };
            }

            console.log('[extractCorners] Only found', Object.keys(corners).length, 'corners from templatePoints, trying fallback...');

            // Method 2: Find extreme corners from all line points
            // This works when templatePoints aren't set but we have line annotations
            const allPoints = [];
            fieldAnns.forEach(ann => {
                if (ann.type === 'line' && ann.points) {
                    ann.points.forEach(pt => {
                        if (Array.isArray(pt) && pt.length >= 2) {
                            allPoints.push({ x: pt[0], y: pt[1] });
                        }
                    });
                }
            });

            if (allPoints.length < 4) {
                console.log('[extractCorners] Not enough line points:', allPoints.length);
                return null;
            }

            // Find bounding box corners
            let minX = Infinity, maxX = -Infinity, minY = Infinity, maxY = -Infinity;
            allPoints.forEach(pt => {
                if (pt.x < minX) minX = pt.x;
                if (pt.x > maxX) maxX = pt.x;
                if (pt.y < minY) minY = pt.y;
                if (pt.y > maxY) maxY = pt.y;
            });

            // Find closest points to each corner
            const findClosest = (targetX, targetY) => {
                let closest = null;
                let minDist = Infinity;
                allPoints.forEach(pt => {
                    const dist = Math.hypot(pt.x - targetX, pt.y - targetY);
                    if (dist < minDist) {
                        minDist = dist;
                        closest = pt;
                    }
                });
                return closest;
            };

            const topLeft = findClosest(minX, minY);
            const topRight = findClosest(maxX, minY);
            const bottomLeft = findClosest(minX, maxY);
            const bottomRight = findClosest(maxX, maxY);

            if (topLeft && topRight && bottomLeft && bottomRight) {
                console.log('[extractCorners] Found corners from extreme points');
                return { topLeft, topRight, bottomLeft, bottomRight };
            }

            console.log('[extractCorners] Could not find all corners');
            return null;
        }

        // Helper: Analyze pixels in frame for feature extraction
        function analyzeFramePixels(img) {
            // Create offscreen canvas
            const offCanvas = document.createElement('canvas');
            offCanvas.width = img.width;
            offCanvas.height = img.height;
            const offCtx = offCanvas.getContext('2d');
            offCtx.drawImage(img, 0, 0);

            // Sample pixels
            const sampleStep = 4;
            const imgData = offCtx.getImageData(0, 0, img.width, img.height);
            const data = imgData.data;

            const greenPixels = [];
            const whitePixels = [];

            for (let y = 0; y < img.height; y += sampleStep) {
                for (let x = 0; x < img.width; x += sampleStep) {
                    const i = (y * img.width + x) * 4;
                    const r = data[i], g = data[i+1], b = data[i+2];

                    // Green detection (grass)
                    if (g > r * 1.1 && g > b * 1.1 && g > 50) {
                        greenPixels.push({ x, y, r, g, b });
                    }

                    // White detection (lines)
                    const brightness = (r + g + b) / 3;
                    const saturation = Math.max(r, g, b) - Math.min(r, g, b);
                    if (brightness > 180 && saturation < 40) {
                        whitePixels.push({ x, y, r, g, b });
                    }
                }
            }

            return { greenPixels, whitePixels };
        }

        document.getElementById('clearBtn').onclick = () => {
            saveState();
            annotations = [];
            tempPoints = [];
            redraw();
            updateAnnotationsPanel();
        };

        document.getElementById('clearAllBtn').onclick = () => {
            if (!currentVideo) {
                setStatus('No video selected');
                return;
            }
            showConfirmModal();
        };

        document.getElementById('propagateRangeBtn').onclick = async () => {
            if (!currentVideo || annotations.length === 0) {
                setStatus('Add annotations first');
                return;
            }
            showLoading('Propagating annotations to next 50 frames...');
            try {
                const resp = await fetch(`/api/video/${encodeURIComponent(currentVideo)}/propagate_range`, {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({
                        source_frame: currentFrame,
                        end_frame: Math.min(currentFrame + 50, totalFrames - 1),
                        annotations: annotations  // Send current annotations directly
                    })
                });
                const data = await resp.json();
                if (data.error) {
                    setStatus(`Error: ${data.error}`);
                } else {
                    setStatus(`Propagated to ${data.propagated_frames} frames`);
                }
            } catch (e) {
                setStatus('Propagation failed: ' + e.message);
            }
            hideLoading();
        };

        document.getElementById('exportBtn').onclick = async () => {
            if (!currentVideo) return;
            const resp = await fetch(`/api/export/${encodeURIComponent(currentVideo)}`);
            const data = await resp.json();
            const blob = new Blob([JSON.stringify(data, null, 2)], {type: 'application/json'});
            const a = document.createElement('a');
            a.href = URL.createObjectURL(blob);
            a.download = `${currentVideo}.annotations.json`;
            a.click();
        };

        // Track if current frame has been edited (to mark as GT)
        let currentFrameEdited = false;

        // Convert current propagated annotations to GT keyframe
        function convertToGTKeyframe() {
            if (annotations.length === 0) return;

            // Mark all field annotations as GT
            annotations = annotations.map(ann => {
                if ((ann.mode || 'field') === 'field') {
                    return {...ann, isGT: true};
                }
                return ann;
            });

            // Update GT reference and RigidTemplate to use current positions
            const fieldAnns = annotations.filter(a => (a.mode || 'field') === 'field');
            if (fieldAnns.length > 0) {
                fieldGTReference = {
                    annotations: JSON.parse(JSON.stringify(fieldAnns)),
                    centroid: computeFieldCentroid(fieldAnns),
                    timestamp: Date.now()
                };
                lastFieldTransform = { dx: 0, dy: 0, scale: 1 };
                // Reinitialize RigidTemplate with current positions as new reference
                RigidTemplate.initFromAnnotations(fieldAnns);

                // Notify bulk propagation system of new GT keyframe
                // This will re-interpolate surrounding segments for smooth transitions
                onNewGTKeyframe(currentFrame, annotations).then(() => {
                    console.log('[GT] Bulk propagation cache updated');
                });
            }

            currentFrameEdited = true;
            console.log('[GT] Converted current frame to GT keyframe');
        }

        // Track last slider values for incremental transforms
        let lastSliderValues = null;

        // Apply incremental transformation to existing template based on slider changes
        function applyIncrementalTransform() {
            if (!currentImage) return;

            const w = currentImage.width;
            const h = currentImage.height;

            // Current slider values
            const currentValues = {
                offsetX: field3D.offsetX,
                offsetZ: field3D.offsetZ,
                rotationZ: field3D.rotationZ,
                scale: field3D.scale
            };

            // Initialize last values if not set - use current field3D values, don't recalculate
            if (!lastSliderValues) {
                lastSliderValues = {
                    offsetX: field3D.offsetX,
                    offsetZ: field3D.offsetZ,
                    rotationZ: field3D.rotationZ,
                    scale: field3D.scale
                };
                console.log('[incremental] Initialized last slider values from current field3D');
                // Don't return - continue with the transform
            }

            // Calculate deltas - reduced multipliers for smoother movement
            const deltaX = (currentValues.offsetX - lastSliderValues.offsetX) * (w / 200);  // Scale to pixels (gentler)
            const deltaZ = (currentValues.offsetZ - lastSliderValues.offsetZ) * (h / 150);  // Scale to pixels (gentler)
            const deltaRotZ = currentValues.rotationZ - lastSliderValues.rotationZ;  // Degrees
            const scaleRatio = currentValues.scale / (lastSliderValues.scale || 1);

            console.log('[incremental] Deltas - X:', deltaX.toFixed(1), 'Z:', deltaZ.toFixed(1),
                        'RotZ:', deltaRotZ.toFixed(2), 'Scale:', scaleRatio.toFixed(3));

            // Skip if no significant change
            if (Math.abs(deltaX) < 0.5 && Math.abs(deltaZ) < 0.5 &&
                Math.abs(deltaRotZ) < 0.01 && Math.abs(scaleRatio - 1) < 0.001) {
                return;
            }

            // Get template annotations
            const templateAnns = annotations.filter(a => (a.mode || 'field') === 'field' && a.isTemplate);
            if (templateAnns.length === 0) return;

            // Calculate centroid for rotation/scale center
            const centroid = computeFieldCentroid(templateAnns);

            // Apply transformation to all template points
            templateAnns.forEach(ann => {
                if (ann.type === 'line' && ann.points) {
                    ann.points = ann.points.map(pt => {
                        let [x, y] = pt;

                        // Apply scale around centroid
                        if (Math.abs(scaleRatio - 1) > 0.001) {
                            x = centroid.x + (x - centroid.x) * scaleRatio;
                            y = centroid.y + (y - centroid.y) * scaleRatio;
                        }

                        // Apply rotation around centroid
                        if (Math.abs(deltaRotZ) > 0.01) {
                            const rad = deltaRotZ * Math.PI / 180;
                            const cos = Math.cos(rad);
                            const sin = Math.sin(rad);
                            const rx = x - centroid.x;
                            const ry = y - centroid.y;
                            x = centroid.x + rx * cos - ry * sin;
                            y = centroid.y + rx * sin + ry * cos;
                        }

                        // Apply translation
                        x += deltaX;
                        y += deltaZ;

                        return [x, y];
                    });
                } else if (ann.type === 'ellipse' && ann.center) {
                    let [cx, cy] = ann.center;

                    // Apply scale
                    if (Math.abs(scaleRatio - 1) > 0.001) {
                        cx = centroid.x + (cx - centroid.x) * scaleRatio;
                        cy = centroid.y + (cy - centroid.y) * scaleRatio;
                        ann.axes = [ann.axes[0] * scaleRatio, ann.axes[1] * scaleRatio];
                    }

                    // Apply rotation around centroid
                    if (Math.abs(deltaRotZ) > 0.01) {
                        const rad = deltaRotZ * Math.PI / 180;
                        const cos = Math.cos(rad);
                        const sin = Math.sin(rad);
                        const rx = cx - centroid.x;
                        const ry = cy - centroid.y;
                        cx = centroid.x + rx * cos - ry * sin;
                        cy = centroid.y + rx * sin + ry * cos;
                        ann.angle = (ann.angle || 0) + deltaRotZ;
                    }

                    // Apply translation
                    cx += deltaX;
                    cy += deltaZ;

                    ann.center = [cx, cy];
                }
            });

            // Update last slider values
            lastSliderValues = { ...currentValues };

            // Update GT reference and RigidTemplate
            const fieldAnns = annotations.filter(a => (a.mode || 'field') === 'field');
            if (fieldAnns.length > 0) {
                fieldGTReference = {
                    annotations: JSON.parse(JSON.stringify(fieldAnns)),
                    centroid: computeFieldCentroid(fieldAnns),
                    timestamp: Date.now()
                };
                // Reinitialize RigidTemplate with updated geometry
                RigidTemplate.initFromAnnotations(fieldAnns);
            }

            redraw();
            console.log('[incremental] Applied transform to', templateAnns.length, 'annotations');
        }

        // Track last pitch/yaw/distance values for incremental transforms
        let lastPitchValue = 70;  // Default
        let lastYawValue = 0;
        let lastDistanceValue = 80;

        // BASELINE: Store the initial Camera3D parameters when template is first created
        let baselineCamera3D = null;

        // Store current Camera3D state as baseline
        // If preservePitchYaw is true, keep existing pitch/yaw values from previous baseline
        function storeCamera3DBaseline(preservePitchYaw = false) {
            // Store field center from ACTUAL annotation positions (center circle)
            const centerCircle = annotations.find(a =>
                a.type === 'ellipse' && (a.id === 'center_circle' || a.elementType === 'centerCircle')
            );

            // Preserve existing pitch/yaw if requested and baseline exists
            const existingPitch = (preservePitchYaw && baselineCamera3D) ? baselineCamera3D.pitch : null;
            const existingYaw = (preservePitchYaw && baselineCamera3D) ? baselineCamera3D.yaw : null;

            // Estimate pitch from ellipse aspect ratio (more reliable than Camera3D calibration)
            let estimatedPitch = Camera3D.pitch || 25;  // Default
            if (centerCircle && centerCircle.axes) {
                const [rx, ry] = centerCircle.axes;
                const aspect = ry / rx;  // <1 means compressed vertically
                // aspect = sin(elevation), elevation = 90 - pitch
                const elevationRad = Math.asin(Math.min(1, Math.max(0, aspect)));
                estimatedPitch = 90 - (elevationRad * 180 / Math.PI);
                estimatedPitch = Math.max(10, Math.min(80, estimatedPitch));
            }

            // Store camera params - use preserved values if available
            baselineCamera3D = {
                pitch: existingPitch !== null ? existingPitch : estimatedPitch,
                yaw: existingYaw !== null ? existingYaw : (Camera3D.yaw || 0),
                roll: Camera3D.roll || 0,
                posX: Camera3D.posX,
                posY: Camera3D.posY,
                posZ: Camera3D.posZ,
                focalLength: Camera3D.focalLength
            };

            // Store field center
            if (centerCircle && centerCircle.center) {
                baselineCamera3D.fieldCenterX = centerCircle.center[0];
                baselineCamera3D.fieldCenterY = centerCircle.center[1];
            } else {
                // Fallback to image center
                baselineCamera3D.fieldCenterX = (currentImage ? currentImage.width / 2 : 640);
                baselineCamera3D.fieldCenterY = (currentImage ? currentImage.height / 2 : 360);
            }

            // Store a copy of all annotation positions for relative transforms
            const templateAnns = annotations.filter(a => (a.mode || 'field') === 'field' && a.isTemplate);
            baselineCamera3D.annotationsCopy = JSON.parse(JSON.stringify(templateAnns));

            console.log('[Camera3D baseline] Stored: pitch=' + baselineCamera3D.pitch.toFixed(1) +
                       '¬∞, center=(' + (baselineCamera3D.fieldCenterX || 0).toFixed(0) + ',' +
                       (baselineCamera3D.fieldCenterY || 0).toFixed(0) + '), annotations=' + templateAnns.length);
        }

        // Restore Camera3D to baseline
        function restoreCamera3DBaseline() {
            if (!baselineCamera3D) return;
            Camera3D.fieldPitch = baselineCamera3D.fieldPitch || 0;
            Camera3D.fieldYaw = baselineCamera3D.fieldYaw || 0;
            Camera3D.fieldRoll = baselineCamera3D.fieldRoll || 0;
            Camera3D.basePitch = baselineCamera3D.basePitch || 25;
            Camera3D.posX = baselineCamera3D.posX;
            Camera3D.posY = baselineCamera3D.posY;
            Camera3D.posZ = baselineCamera3D.posZ;
            Camera3D.focalLength = baselineCamera3D.focalLength;
        }

        // ============================================
        // PROPER 3D ROTATION TRANSFORM
        // Rotates field around field center point, then projects with fixed camera
        // All rotations pivot around center of center line
        // ============================================
        function applyProper3DRotation() {
            if (!currentImage) return;

            const templateAnns = annotations.filter(a => (a.mode || 'field') === 'field' && a.isTemplate);
            if (templateAnns.length === 0) return;

            // Convert propagated to GT if needed
            const hasPropagatedAnns = annotations.some(a => (a.mode || 'field') === 'field' && a.isGT === false && a.isTemplate);
            if (hasPropagatedAnns && !currentFrameEdited) {
                convertToGTKeyframe();
            }

            // Use baseline camera parameters if available
            const baseline = baselineCamera3D || {
                basePitch: 25, posX: FIELD_LENGTH / 2, posY: -25, posZ: 15,
                focalLength: 1200
            };

            // Set field center (pivot point for all rotations)
            Camera3D.fieldCenterX = FIELD_LENGTH / 2;
            Camera3D.fieldCenterY = FIELD_WIDTH / 2;
            Camera3D.fieldCenterZ = 0;

            // FIELD rotation from sliders (rotates field around center)
            // rotationX = pitch (tilt field toward/away from camera)
            // rotationY = yaw (tilt field sideways - rarely used)
            // rotationZ = roll (spin field left/right around vertical)
            Camera3D.fieldPitch = field3D.rotationX;
            Camera3D.fieldYaw = field3D.rotationY;
            Camera3D.fieldRoll = field3D.rotationZ;

            // Camera position (can be adjusted for pan/zoom)
            Camera3D.posX = FIELD_LENGTH / 2 + field3D.offsetX;
            Camera3D.posY = baseline.posY + field3D.offsetZ;
            Camera3D.posZ = baseline.posZ * (field3D.cameraDistance / 80);

            // Base camera pitch (looking at field)
            Camera3D.basePitch = baseline.basePitch || 25;

            // Focal length from scale
            Camera3D.focalLength = baseline.focalLength * field3D.scale;

            // Principal point (offsetY shifts image vertically)
            Camera3D.principalX = currentImage.width / 2;
            Camera3D.principalY = currentImage.height / 2 + field3D.offsetY * 5;
            Camera3D.imageWidth = currentImage.width;
            Camera3D.imageHeight = currentImage.height;

            console.log('[Camera3D] Field rotation around center: pitch=' + Camera3D.fieldPitch.toFixed(1) +
                       '¬∞, yaw=' + Camera3D.fieldYaw.toFixed(1) +
                       '¬∞, roll=' + Camera3D.fieldRoll.toFixed(1) + '¬∞');
            console.log('[Camera3D] Camera pos: (' + Camera3D.posX.toFixed(1) +
                       ', ' + Camera3D.posY.toFixed(1) +
                       ', ' + Camera3D.posZ.toFixed(1) + '), f=' + Camera3D.focalLength.toFixed(0));

            // Reproject all template annotations through Camera3D
            templateAnns.forEach(ann => {
                if (ann.type === 'line' && ann.templatePoints) {
                    const newPoints = ann.templatePoints.map(ptName => {
                        const pt3d = FIELD_3D_POINTS[ptName];
                        if (!pt3d) return null;
                        const projected = Camera3D.project(pt3d.x, pt3d.y, pt3d.z || 0);
                        return projected ? [projected.x, projected.y] : null;
                    }).filter(p => p !== null);

                    if (newPoints.length >= 2) {
                        ann.points = newPoints;
                    }
                } else if (ann.type === 'ellipse' && (ann.elementType === 'centerCircle' || ann.id === 'center_circle')) {
                    const circle = Camera3D.projectCircle(
                        FIELD_LENGTH / 2, FIELD_WIDTH / 2, STANDARD_PITCH.centerCircleRadius
                    );
                    if (circle) {
                        ann.center = circle.center;
                        ann.axes = circle.axes;
                        ann.angle = circle.angle || 0;
                    }
                }
            });

            // Update GT reference
            const fieldAnns = annotations.filter(a => (a.mode || 'field') === 'field');
            if (fieldAnns.length > 0) {
                fieldGTReference = {
                    annotations: JSON.parse(JSON.stringify(fieldAnns)),
                    centroid: computeFieldCentroid(fieldAnns),
                    timestamp: Date.now()
                };
                RigidTemplate.initFromAnnotations(fieldAnns);
            }

            currentFrameEdited = true;
            redraw();
        }

        // Re-project all field annotations using current Camera3D parameters
        function reprojectFieldWithCamera3D() {
            const templateAnns = annotations.filter(a => (a.mode || 'field') === 'field' && a.isTemplate);
            if (templateAnns.length === 0) return;

            // Re-project each annotation
            templateAnns.forEach(ann => {
                if (ann.type === 'line' && ann.templatePoints) {
                    // Re-project line points from 3D
                    const newPoints = ann.templatePoints.map(ptName => {
                        const pt3d = FIELD_3D_POINTS[ptName];
                        if (!pt3d) return null;
                        const projected = Camera3D.projectFieldPoint(pt3d);
                        return projected ? [projected.x, projected.y] : null;
                    }).filter(p => p !== null);

                    if (newPoints.length >= 2) {
                        ann.points = newPoints;
                    }
                } else if (ann.type === 'ellipse' && ann.elementType === 'centerCircle') {
                    // Re-project center circle
                    const circle = Camera3D.projectCircle(
                        FIELD_LENGTH / 2,
                        FIELD_WIDTH / 2,
                        STANDARD_PITCH.centerCircleRadius
                    );
                    if (circle) {
                        ann.center = circle.center;
                        ann.axes = circle.axes;
                        ann.angle = circle.angle || 0;
                    }
                }
            });

            redraw();
        }

        // Apply pitch/yaw using HOMOGRAPHY transform for geometric consistency
        // All points on the field plane transform together correctly
        function applyPitchTransform() {
            if (!currentImage) return;

            const templateAnns = annotations.filter(a => (a.mode || 'field') === 'field' && a.isTemplate);
            if (templateAnns.length === 0) return;

            // Initialize baseline if not set - DON'T overwrite user's slider values
            if (!baselineCamera3D) {
                storeCamera3DBaseline();
                // Store current slider values as the baseline reference for delta calculation
                // Don't overwrite field3D - the slider values are what the user set
                baselineCamera3D.pitch = field3D.rotationX;
                baselineCamera3D.yaw = field3D.rotationY;
            }

            // Convert propagated to GT if needed
            const hasPropagatedAnns = annotations.some(a => (a.mode || 'field') === 'field' && a.isGT === false && a.isTemplate);
            if (hasPropagatedAnns && !currentFrameEdited) {
                convertToGTKeyframe();
                // Re-store baseline annotation positions but PRESERVE pitch/yaw from sliders
                storeCamera3DBaseline(true);
            }

            const pitchDelta = field3D.rotationX - baselineCamera3D.pitch;
            const yawDelta = field3D.rotationY - baselineCamera3D.yaw;

            // If no change, restore original
            if (Math.abs(pitchDelta) < 0.01 && Math.abs(yawDelta) < 0.01) {
                if (baselineCamera3D.annotationsCopy) {
                    baselineCamera3D.annotationsCopy.forEach(baseAnn => {
                        const ann = templateAnns.find(a => a.id === baseAnn.id);
                        if (ann) {
                            if (baseAnn.points) ann.points = JSON.parse(JSON.stringify(baseAnn.points));
                            if (baseAnn.center) ann.center = JSON.parse(JSON.stringify(baseAnn.center));
                            if (baseAnn.axes) ann.axes = JSON.parse(JSON.stringify(baseAnn.axes));
                            if (baseAnn.angle !== undefined) ann.angle = baseAnn.angle;
                        }
                    });
                }
                redraw();
                return;
            }

            const pivotX = baselineCamera3D.fieldCenterX;
            const pivotY = baselineCamera3D.fieldCenterY;
            const h = currentImage.height;

            // Use proper 3x3 homography matrix for projective transform
            // This ensures all elements transform as a consistent planar surface
            const pitchRad = pitchDelta * Math.PI / 180;
            const yawRad = yawDelta * Math.PI / 180;

            // Get baseline elevation angle (camera angle from horizontal)
            // Baseline pitch is stored as "pitch from horizontal" where higher = looking more horizontal
            const baselinePitchRad = baselineCamera3D.pitch * Math.PI / 180;
            const baselineElevation = (90 - baselineCamera3D.pitch) * Math.PI / 180;

            // Effective focal length (controls perspective strength)
            // Larger value = more subtle perspective effect
            const focalLength = h * 1.5;

            // Proper perspective transform for camera pitch/yaw rotation
            // The key insight: perspective effect depends on BOTH the delta AND baseline angle
            const cosP = Math.cos(pitchRad);
            const sinP = Math.sin(pitchRad);
            const tanBaseline = Math.tan(baselinePitchRad);
            const cosY = Math.cos(yawRad);
            const sinY = Math.sin(yawRad);

            // Vertical scale factor: how much y-axis compresses due to pitch change
            // When "lowering camera" (negative pitch delta), ellipse should get FLATTER (shorter)
            // Formula with correct sign: cos(delta) + tan(baselinePitch) * sin(delta)
            // - Negative delta -> negative sin -> flatter (< 1)
            // - Positive delta -> positive sin -> taller (> 1)
            const verticalScale = cosP + tanBaseline * sinP;

            // Clamp to reasonable range to prevent extreme distortion
            const verticalScaleClamped = Math.max(0.3, Math.min(2.0, verticalScale));

            // Yaw shear factor depends on how much we're looking down
            // At steeper angles (more top-down), yaw creates less shear
            // At shallower angles (more horizontal), yaw creates more shear
            const yawShearFactor = Math.sin(baselineElevation) * 0.5;  // 0.5 dampening for stability

            const transformPoint = (x, y) => {
                // Translate to pivot (field center)
                const dx = x - pivotX;
                const dy = y - pivotY;

                // Proper homography for camera pitch/yaw viewing a horizontal surface
                //
                // The vertical transform combines:
                // 1. Compression due to pitch change: verticalScale = cos(Œîpitch) - tan(baseline)*sin(Œîpitch)
                // 2. Perspective scaling based on depth (y position)
                //
                // The perspective w factor represents how distance from camera changes:
                // - Negative pitch delta (looking down more): top is farther, bottom is closer
                // - Positive pitch delta (looking up more): bottom is farther, top is closer

                // Perspective divisor based on y-position (depth from camera)
                // In typical broadcast view: top of screen = far (dy < 0), bottom = near (dy > 0)
                // Smaller w = point appears closer/larger, larger w = point appears farther/smaller
                const wPitch = dy * sinP / focalLength;
                const w = 1 + wPitch;

                // Clamp w to prevent division issues
                const wSafe = Math.max(0.1, Math.min(10, w));

                // YAW PARALLAX: For camera panning, horizontal parallax depends on DEPTH
                //   - dy < 0 (top/far): positive yaw ‚Üí positive shift (right)
                //   - dy > 0 (bottom/near): positive yaw ‚Üí negative shift (left)
                //   Formula: -dy * sinY gives correct signs
                const xp = dx * cosY - dy * sinY * yawShearFactor;
                const yp = dy * verticalScaleClamped;

                // Divide by w for projective transform
                const xOut = pivotX + xp / wSafe;
                const yOut = pivotY + yp / wSafe;

                return [xOut, yOut];
            };

            console.log('[Homography] Œîpitch=' + pitchDelta.toFixed(1) + '¬∞, Œîyaw=' + yawDelta.toFixed(1) +
                       '¬∞, baseline pitch=' + baselineCamera3D.pitch.toFixed(1) + '¬∞, baseline yaw=' + baselineCamera3D.yaw.toFixed(1) + '¬∞');
            console.log('[Homography] slider pitch=' + field3D.rotationX.toFixed(1) + '¬∞, slider yaw=' + field3D.rotationY.toFixed(1) + '¬∞');
            console.log('[Homography] verticalScale=' + verticalScaleClamped.toFixed(3) +
                       ', yawShearFactor=' + yawShearFactor.toFixed(3) + ', sinY=' + sinY.toFixed(4));

            // Transform all annotations using the homography
            if (baselineCamera3D.annotationsCopy) {
                baselineCamera3D.annotationsCopy.forEach(baseAnn => {
                    const ann = templateAnns.find(a => a.id === baseAnn.id);
                    if (!ann) return;

                    if (baseAnn.type === 'line' && baseAnn.points) {
                        // Transform all line points
                        ann.points = baseAnn.points.map(pt => transformPoint(pt[0], pt[1]));
                    } else if (baseAnn.type === 'ellipse' && baseAnn.center) {
                        const [cx, cy] = baseAnn.center;
                        const [rx, ry] = baseAnn.axes;
                        const angle = baseAnn.angle || 0;

                        // SIMPLIFIED ELLIPSE TRANSFORM
                        // For a circle on the field plane viewed from above:
                        // - Pitch change: scales the minor axis (vertical compression/expansion)
                        // - Yaw change: rotates the ellipse and slightly affects both axes
                        //
                        // This is more stable than sampling+fitting approach

                        // Transform center point
                        const [newCx, newCy] = transformPoint(cx, cy);

                        // For ellipse axes, use direct scaling:
                        // - X-axis (horizontal): scales with cosY (yaw rotation)
                        // - Y-axis (vertical): scales with verticalScaleClamped (pitch change)
                        //
                        // Also need to account for the w-factor at center
                        const dcx = cx - pivotX;
                        const dcy = cy - pivotY;
                        const wAtCenter = 1 + (dcy * sinP / focalLength) + (dcx * sinY / focalLength);
                        const wCenterSafe = Math.max(0.5, Math.min(2, wAtCenter));

                        // Scale factors for each axis
                        const xScale = cosY / wCenterSafe;
                        const yScale = verticalScaleClamped / wCenterSafe;

                        // Original ellipse has axes [rx, ry] at angle 'angle'
                        // After pitch/yaw transform:
                        // - The horizontal axis scales by xScale
                        // - The vertical axis scales by yScale
                        // - Yaw adds rotation

                        // Convert to parametric form to apply scaling
                        const angleRad = angle * Math.PI / 180;
                        const cosAng = Math.cos(angleRad);
                        const sinAng = Math.sin(angleRad);

                        // Major axis vector (length rx)
                        const ax1 = rx * cosAng;
                        const ay1 = rx * sinAng;
                        // Minor axis vector (length ry)
                        const ax2 = -ry * sinAng;
                        const ay2 = ry * cosAng;

                        // Apply scaling to axis vectors
                        const nax1 = ax1 * xScale;
                        const nay1 = ay1 * yScale;
                        const nax2 = ax2 * xScale;
                        const nay2 = ay2 * yScale;

                        // Apply yaw rotation
                        const yawShear = sinY * yawShearFactor;
                        const rotAx1 = nax1 * cosY - nay1 * yawShear;
                        const rotAy1 = nay1;
                        const rotAx2 = nax2 * cosY - nay2 * yawShear;
                        const rotAy2 = nay2;

                        // Compute new ellipse parameters from transformed axes
                        // Using the fact that for ellipse x = a*cos(t)*u1 + b*sin(t)*u2
                        // The new axes lengths are the lengths of the transformed axis vectors
                        const newRx = Math.sqrt(rotAx1*rotAx1 + rotAy1*rotAy1);
                        const newRy = Math.sqrt(rotAx2*rotAx2 + rotAy2*rotAy2);

                        // New angle is the direction of the major axis
                        let newAngle = Math.atan2(rotAy1, rotAx1) * 180 / Math.PI;

                        // Ensure major axis is the larger one
                        let finalRx = newRx;
                        let finalRy = newRy;
                        let finalAngle = newAngle;
                        if (newRy > newRx) {
                            finalRx = newRy;
                            finalRy = newRx;
                            finalAngle = newAngle + 90;
                        }

                        ann.center = [newCx, newCy];
                        ann.axes = [Math.max(1, finalRx), Math.max(1, finalRy)];
                        ann.angle = finalAngle;

                        // Debug ellipse transform
                        const centerOffset = Math.sqrt(Math.pow(cx - pivotX, 2) + Math.pow(cy - pivotY, 2));
                        console.log('[Ellipse] ' + baseAnn.id + ': axes ' + rx.toFixed(0) + ',' + ry.toFixed(0) + ' -> ' + finalRx.toFixed(0) + ',' + finalRy.toFixed(0) +
                                    ', ratio ' + (ry/rx).toFixed(3) + ' -> ' + (finalRy/finalRx).toFixed(3) +
                                    ', vScale=' + verticalScaleClamped.toFixed(3) + ', wCenter=' + wCenterSafe.toFixed(3));
                    }
                });
            }

            lastPitchValue = field3D.rotationX;
            lastYawValue = field3D.rotationY;
            currentFrameEdited = true;

            // Update GT reference and RigidTemplate
            const fieldAnns = annotations.filter(a => (a.mode || 'field') === 'field');
            if (fieldAnns.length > 0) {
                fieldGTReference = {
                    annotations: JSON.parse(JSON.stringify(fieldAnns)),
                    centroid: computeFieldCentroid(fieldAnns),
                    timestamp: Date.now()
                };
                RigidTemplate.initFromAnnotations(fieldAnns);
            }

            redraw();
        }

        // Fit ellipse to a set of points using covariance method
        function fitEllipseToPoints(points) {
            if (points.length < 5) return null;

            // Calculate centroid
            let cx = 0, cy = 0;
            points.forEach(p => { cx += p[0]; cy += p[1]; });
            cx /= points.length;
            cy /= points.length;

            // Calculate covariance matrix
            let cxx = 0, cyy = 0, cxy = 0;
            points.forEach(p => {
                const dx = p[0] - cx;
                const dy = p[1] - cy;
                cxx += dx * dx;
                cyy += dy * dy;
                cxy += dx * dy;
            });
            cxx /= points.length;
            cyy /= points.length;
            cxy /= points.length;

            // Eigenvalue decomposition for ellipse axes
            const trace = cxx + cyy;
            const det = cxx * cyy - cxy * cxy;
            const disc = Math.sqrt(Math.max(0, trace * trace / 4 - det));
            const lambda1 = trace / 2 + disc;
            const lambda2 = trace / 2 - disc;

            // Semi-axes: For uniformly sampled points on ellipse with axes a,b:
            // variance = axis¬≤ / 2, so axis = sqrt(2 * variance) = sqrt(2 * lambda)
            const rx = Math.sqrt(Math.max(0.1, 2 * lambda1));
            const ry = Math.sqrt(Math.max(0.1, 2 * lambda2));

            // Rotation angle from covariance
            let angle = 0;
            if (Math.abs(cxy) > 0.001) {
                angle = Math.atan2(2 * cxy, cxx - cyy) / 2 * 180 / Math.PI;
            }

            return { cx, cy, rx: Math.max(1, rx), ry: Math.max(1, ry), angle };
        }

        // Apply yaw (rotationY) - now uses same baseline system as pitch
        function applyYawTransform() {
            // Yaw is handled together with pitch in applyPitchTransform
            // Just call that function which handles both
            applyPitchTransform();
        }

        // Reset baseline when template is reloaded or panned
        function resetBaseline() {
            baselineAnnotations = null;
            baselineCentroid = null;
            baselineCamera3D = null;  // Also reset Camera3D baseline
            console.log('[baseline] Reset - will re-store on next transform');
        }

        // Apply camera distance as RELATIVE scale around field center
        function applyCameraDistanceTransform() {
            if (!currentImage) return;

            const templateAnns = annotations.filter(a => (a.mode || 'field') === 'field' && a.isTemplate);
            if (templateAnns.length === 0) return;

            // Initialize baseline if not set
            if (!baselineCamera3D) {
                storeCamera3DBaseline();
            }

            // Convert propagated to GT if needed
            const hasPropagatedAnns = annotations.some(a => (a.mode || 'field') === 'field' && a.isGT === false && a.isTemplate);
            if (hasPropagatedAnns && !currentFrameEdited) {
                convertToGTKeyframe();
                // Re-store baseline but preserve pitch/yaw values
                storeCamera3DBaseline(true);
            }

            // Calculate scale factor from baseline distance (80 = default = 1.0)
            const scaleFactor = field3D.cameraDistance / 80;

            const pivotX = baselineCamera3D.fieldCenterX;
            const pivotY = baselineCamera3D.fieldCenterY;

            console.log('[Distance] scale=' + scaleFactor.toFixed(2) + ', pivot=(' + pivotX.toFixed(0) + ',' + pivotY.toFixed(0) + ')');

            // Apply RELATIVE scale to BASELINE positions around pivot
            if (baselineCamera3D.annotationsCopy) {
                baselineCamera3D.annotationsCopy.forEach(baseAnn => {
                    const ann = templateAnns.find(a => a.id === baseAnn.id);
                    if (!ann) return;

                    if (baseAnn.type === 'line' && baseAnn.points) {
                        ann.points = baseAnn.points.map(pt => {
                            const [x, y] = pt;
                            const dx = x - pivotX;
                            const dy = y - pivotY;
                            return [pivotX + dx * scaleFactor, pivotY + dy * scaleFactor];
                        });
                    } else if (baseAnn.type === 'ellipse' && baseAnn.center) {
                        const [cx, cy] = baseAnn.center;
                        const [rx, ry] = baseAnn.axes;

                        const dx = cx - pivotX;
                        const dy = cy - pivotY;

                        ann.center = [pivotX + dx * scaleFactor, pivotY + dy * scaleFactor];
                        ann.axes = [rx * scaleFactor, ry * scaleFactor];
                    }
                });
            }

            lastDistanceValue = field3D.cameraDistance;
            currentFrameEdited = true;

            // Update GT reference and RigidTemplate with new positions
            const fieldAnns = annotations.filter(a => (a.mode || 'field') === 'field');
            if (fieldAnns.length > 0) {
                fieldGTReference = {
                    annotations: JSON.parse(JSON.stringify(fieldAnns)),
                    centroid: computeFieldCentroid(fieldAnns),
                    timestamp: Date.now()
                };
                RigidTemplate.initFromAnnotations(fieldAnns);
            }

            redraw();
        }

        // Track last scale/length/width values for incremental transforms
        let lastScaleValue = 1.5;  // Default (matches slider default of 15/10)
        let lastLengthValue = 105;
        let lastWidthValue = 68;

        // Apply field scale as uniform scaling
        function applyScaleTransform() {
            if (!currentImage) return;

            const delta = field3D.scale - lastScaleValue;
            if (Math.abs(delta) < 0.01) return;

            const templateAnns = annotations.filter(a => (a.mode || 'field') === 'field' && a.isTemplate);
            if (templateAnns.length === 0) return;

            // Convert propagated to GT if needed
            const hasPropagatedAnns = annotations.some(a => (a.mode || 'field') === 'field' && a.isGT === false && a.isTemplate);
            if (hasPropagatedAnns && !currentFrameEdited) {
                convertToGTKeyframe();
            }

            const centroid = computeFieldCentroid(templateAnns);

            // Scale factor: use proportional scaling relative to current value
            // This makes the change feel consistent regardless of current scale
            const safeLast = Math.max(0.1, lastScaleValue);  // Prevent division by zero
            const scaleFactor = field3D.scale / safeLast;

            // Clamp to prevent extreme changes (max 10% per slider tick)
            const clampedScaleFactor = Math.max(0.9, Math.min(1.1, scaleFactor));

            templateAnns.forEach(ann => {
                if (ann.type === 'line' && ann.points) {
                    ann.points = ann.points.map(pt => {
                        let [x, y] = pt;
                        x = centroid.x + (x - centroid.x) * clampedScaleFactor;
                        y = centroid.y + (y - centroid.y) * clampedScaleFactor;
                        return [x, y];
                    });
                } else if (ann.type === 'ellipse' && ann.center) {
                    let [cx, cy] = ann.center;
                    cx = centroid.x + (cx - centroid.x) * clampedScaleFactor;
                    cy = centroid.y + (cy - centroid.y) * clampedScaleFactor;
                    ann.center = [cx, cy];
                    ann.axes = [ann.axes[0] * clampedScaleFactor, ann.axes[1] * clampedScaleFactor];
                }
            });

            lastScaleValue = field3D.scale;
            currentFrameEdited = true;

            // Update GT reference and RigidTemplate with new positions
            const fieldAnns = annotations.filter(a => (a.mode || 'field') === 'field');
            if (fieldAnns.length > 0) {
                fieldGTReference = {
                    annotations: JSON.parse(JSON.stringify(fieldAnns)),
                    centroid: computeFieldCentroid(fieldAnns),
                    timestamp: Date.now()
                };
                RigidTemplate.initFromAnnotations(fieldAnns);
            }

            redraw();
            console.log('[scale] Applied scale factor:', clampedScaleFactor.toFixed(4));
        }

        // Apply field length change as vertical scaling
        function applyLengthTransform() {
            if (!currentImage) return;

            const delta = field3D.fieldLength - lastLengthValue;
            if (Math.abs(delta) < 0.1) return;

            const templateAnns = annotations.filter(a => (a.mode || 'field') === 'field' && a.isTemplate);
            if (templateAnns.length === 0) return;

            // Convert propagated to GT if needed
            const hasPropagatedAnns = annotations.some(a => (a.mode || 'field') === 'field' && a.isGT === false && a.isTemplate);
            if (hasPropagatedAnns && !currentFrameEdited) {
                convertToGTKeyframe();
            }

            const centroid = computeFieldCentroid(templateAnns);

            // Length affects vertical dimension (Y axis in screen space)
            // Use proportional scaling for consistent feel
            const safeLast = Math.max(10, lastLengthValue);
            const scaleFactor = field3D.fieldLength / safeLast;
            const clampedScaleFactor = Math.max(0.95, Math.min(1.05, scaleFactor));

            templateAnns.forEach(ann => {
                if (ann.type === 'line' && ann.points) {
                    ann.points = ann.points.map(pt => {
                        let [x, y] = pt;
                        // Only scale Y (vertical/length direction)
                        y = centroid.y + (y - centroid.y) * clampedScaleFactor;
                        return [x, y];
                    });
                } else if (ann.type === 'ellipse' && ann.center) {
                    let [cx, cy] = ann.center;
                    cy = centroid.y + (cy - centroid.y) * clampedScaleFactor;
                    ann.center = [cx, cy];
                    // Scale vertical axis of ellipse
                    ann.axes = [ann.axes[0], ann.axes[1] * clampedScaleFactor];
                }
            });

            lastLengthValue = field3D.fieldLength;
            currentFrameEdited = true;

            // Update GT reference and RigidTemplate with new positions
            const fieldAnns = annotations.filter(a => (a.mode || 'field') === 'field');
            if (fieldAnns.length > 0) {
                fieldGTReference = {
                    annotations: JSON.parse(JSON.stringify(fieldAnns)),
                    centroid: computeFieldCentroid(fieldAnns),
                    timestamp: Date.now()
                };
                RigidTemplate.initFromAnnotations(fieldAnns);
            }

            redraw();
            console.log('[length] Applied delta:', delta.toFixed(2), 'scale:', scaleFactor.toFixed(4));
        }

        // Apply field width change as horizontal scaling
        function applyWidthTransform() {
            if (!currentImage) return;

            const delta = field3D.fieldWidth - lastWidthValue;
            if (Math.abs(delta) < 0.1) return;

            const templateAnns = annotations.filter(a => (a.mode || 'field') === 'field' && a.isTemplate);
            if (templateAnns.length === 0) return;

            // Convert propagated to GT if needed
            const hasPropagatedAnns = annotations.some(a => (a.mode || 'field') === 'field' && a.isGT === false && a.isTemplate);
            if (hasPropagatedAnns && !currentFrameEdited) {
                convertToGTKeyframe();
            }

            const centroid = computeFieldCentroid(templateAnns);

            // Width affects horizontal dimension (X axis in screen space)
            // Use proportional scaling for consistent feel
            const safeLast = Math.max(10, lastWidthValue);
            const scaleFactor = field3D.fieldWidth / safeLast;
            const clampedScaleFactor = Math.max(0.95, Math.min(1.05, scaleFactor));

            templateAnns.forEach(ann => {
                if (ann.type === 'line' && ann.points) {
                    ann.points = ann.points.map(pt => {
                        let [x, y] = pt;
                        // Only scale X (horizontal/width direction)
                        x = centroid.x + (x - centroid.x) * clampedScaleFactor;
                        return [x, y];
                    });
                } else if (ann.type === 'ellipse' && ann.center) {
                    let [cx, cy] = ann.center;
                    cx = centroid.x + (cx - centroid.x) * clampedScaleFactor;
                    ann.center = [cx, cy];
                    // Scale horizontal axis of ellipse
                    ann.axes = [ann.axes[0] * clampedScaleFactor, ann.axes[1]];
                }
            });

            lastWidthValue = field3D.fieldWidth;
            currentFrameEdited = true;

            // Update GT reference and RigidTemplate with new positions
            const fieldAnns = annotations.filter(a => (a.mode || 'field') === 'field');
            if (fieldAnns.length > 0) {
                fieldGTReference = {
                    annotations: JSON.parse(JSON.stringify(fieldAnns)),
                    centroid: computeFieldCentroid(fieldAnns),
                    timestamp: Date.now()
                };
                RigidTemplate.initFromAnnotations(fieldAnns);
            }

            redraw();
            console.log('[width] Applied delta:', delta.toFixed(2), 'scale:', scaleFactor.toFixed(4));
        }

        // Sync 3D slider values to match current template corner positions
        // This ensures slider edits are relative to the current position, not defaults
        function syncSlidersToCurrentTemplate() {
            // Extract corner positions from current template annotations
            const corners = extractCornersFromAnnotations(
                annotations.filter(a => (a.mode || 'field') === 'field')
            );

            if (!corners || !currentImage) {
                console.log('[syncSliders] No corners found');
                return;
            }

            const w = currentImage.width;
            const h = currentImage.height;

            // Calculate key metrics from corners
            const centerX = (corners.topLeft.x + corners.topRight.x + corners.bottomLeft.x + corners.bottomRight.x) / 4;
            const topY = (corners.topLeft.y + corners.topRight.y) / 2;
            const bottomY = (corners.bottomLeft.y + corners.bottomRight.y) / 2;
            const topWidth = Math.hypot(corners.topRight.x - corners.topLeft.x, corners.topRight.y - corners.topLeft.y);
            const bottomWidth = Math.hypot(corners.bottomRight.x - corners.bottomLeft.x, corners.bottomRight.y - corners.bottomLeft.y);
            const fieldHeight = bottomY - topY;

            // Calculate tilt angle from top corners
            const tiltAngle = Math.atan2(corners.topRight.y - corners.topLeft.y, corners.topRight.x - corners.topLeft.x) * 180 / Math.PI;

            // Calculate perspective ratio
            const perspectiveRatio = topWidth / bottomWidth;

            // Estimate 3D parameters from these metrics
            // These are approximations - the 3D projection is complex

            // Position X: offset from center
            const offsetX = (centerX - w / 2) / (w / 4);  // Normalize to slider range
            field3D.offsetX = Math.max(-30, Math.min(30, offsetX * 10));

            // Position Z: based on vertical position (higher topY = more positive Z)
            const offsetZ = ((topY - h * 0.2) / h) * 30;
            field3D.offsetZ = Math.max(-30, Math.min(30, offsetZ));

            // Rotation Z (roll): directly from tilt angle
            field3D.rotationZ = Math.max(-30, Math.min(30, tiltAngle));

            // Scale: based on field height relative to frame
            const scaleEstimate = (fieldHeight / h) * 2.5;
            field3D.scale = Math.max(0.1, Math.min(5, scaleEstimate));

            // Camera distance: based on perspective ratio (more perspective = closer)
            // perspectiveRatio close to 1 = far away, close to 0 = very close
            const distanceEstimate = 1.5 + (1 - perspectiveRatio) * 2;
            field3D.cameraDistance = Math.max(0.5, Math.min(5, distanceEstimate));

            // Pitch (rotationX): use detected elevation angle from circle if available
            // elevationAngle is camera angle above ground: 0¬∞=ground level, 90¬∞=overhead
            // rotationX for 3D view: 0¬∞=top-down, 90¬∞=side view
            // So rotationX ‚âà 90 - elevationAngle (with adjustment for viewing angle)
            let pitchEstimate;
            if (detectedElevationAngle !== null) {
                // Use circle-derived elevation directly
                // Typical broadcast: elevation 10-25¬∞ ‚Üí rotationX 65-80¬∞
                pitchEstimate = 90 - detectedElevationAngle;
                console.log(`[syncSliders] Using detected elevation: ${detectedElevationAngle.toFixed(1)}¬∞ ‚Üí pitch: ${pitchEstimate.toFixed(1)}¬∞`);
            } else {
                // Fallback: estimate from perspective ratio
                pitchEstimate = 60 + (1 - perspectiveRatio) * 30;
                console.log(`[syncSliders] Fallback pitch from perspective: ${pitchEstimate.toFixed(1)}¬∞`);
            }
            field3D.rotationX = Math.max(-360, Math.min(360, pitchEstimate));

            // Yaw (rotationY): estimate from horizontal skew
            // If left side is higher than right, yaw is positive
            const leftHeight = corners.bottomLeft.y - corners.topLeft.y;
            const rightHeight = corners.bottomRight.y - corners.topRight.y;
            const heightDiff = (rightHeight - leftHeight) / h;
            const yawEstimate = heightDiff * 50;
            field3D.rotationY = Math.max(-360, Math.min(360, yawEstimate));

            // Update ALL slider UI to match
            document.getElementById('rotationX').value = Math.round(field3D.rotationX * 10);
            document.getElementById('rotXValue').textContent = field3D.rotationX.toFixed(1);

            document.getElementById('rotationY').value = Math.round(field3D.rotationY * 10);
            document.getElementById('rotYValue').textContent = field3D.rotationY.toFixed(1);

            document.getElementById('rotationZ').value = Math.round(field3D.rotationZ * 10);
            document.getElementById('rotZValue').textContent = field3D.rotationZ.toFixed(1);

            document.getElementById('fieldScale').value = Math.round(field3D.scale * 10);
            document.getElementById('scaleValue').textContent = field3D.scale.toFixed(1);

            document.getElementById('cameraDistance').value = Math.round(field3D.cameraDistance * 10);
            document.getElementById('distValue').textContent = field3D.cameraDistance.toFixed(1);

            document.getElementById('positionX').value = Math.round(field3D.offsetX * 10);
            document.getElementById('posXValue').textContent = field3D.offsetX.toFixed(1);

            document.getElementById('positionZ').value = Math.round(field3D.offsetZ * 10);
            document.getElementById('posZValue').textContent = field3D.offsetZ.toFixed(1);

            // Update lastSliderValues so incremental transforms start from this baseline
            lastSliderValues = {
                offsetX: field3D.offsetX,
                offsetZ: field3D.offsetZ,
                rotationZ: field3D.rotationZ,
                scale: field3D.scale
            };

            // Reset ALL tracking values for incremental transforms
            lastScaleValue = field3D.scale;
            lastLengthValue = field3D.fieldLength;
            lastWidthValue = field3D.fieldWidth;
            lastDistanceValue = field3D.cameraDistance;

            // Store baseline for absolute transforms (pitch/yaw)
            if (typeof storeBaseline === 'function') {
                storeBaseline();
            }

            // If Camera3D baseline exists, use those values for pitch/yaw
            // This ensures sliders match the baseline exactly
            if (baselineCamera3D) {
                field3D.rotationX = baselineCamera3D.pitch;
                field3D.rotationY = baselineCamera3D.yaw;
                field3D.cameraDistance = 80;  // Reset to default (1.0 scale)
            } else {
                // Initialize Camera3D baseline from current annotations
                const templateAnns = annotations.filter(a => (a.mode || 'field') === 'field' && a.isTemplate);
                if (templateAnns.length > 0) {
                    storeCamera3DBaseline();
                    field3D.rotationX = baselineCamera3D.pitch;
                    field3D.rotationY = baselineCamera3D.yaw;
                }
            }

            // Update slider UI with baseline values
            document.getElementById('rotationX').value = Math.round(field3D.rotationX * 10);
            document.getElementById('rotXValue').textContent = field3D.rotationX.toFixed(1);
            document.getElementById('rotationY').value = Math.round(field3D.rotationY * 10);
            document.getElementById('rotYValue').textContent = field3D.rotationY.toFixed(1);
            document.getElementById('cameraDistance').value = Math.round(field3D.cameraDistance * 10);
            document.getElementById('distValue').textContent = field3D.cameraDistance.toFixed(1);

            lastPitchValue = field3D.rotationX;
            lastYawValue = field3D.rotationY;

            console.log('[syncSliders] Synced sliders to current template:', {
                offsetX: field3D.offsetX.toFixed(1),
                offsetZ: field3D.offsetZ.toFixed(1),
                rotationZ: field3D.rotationZ.toFixed(1),
                scale: field3D.scale.toFixed(1),
                cameraDistance: field3D.cameraDistance.toFixed(1),
                pitch: field3D.rotationX.toFixed(1),
                yaw: field3D.rotationY.toFixed(1)
            });
        }

        // 3D Field View controls - auto-update template when sliders change
        function update3DTemplate(forceRegenerate = false) {
            if (!currentImage) return;

            // Check if we have any existing template annotations (propagated or GT)
            const hasTemplateAnns = annotations.some(a => (a.mode || 'field') === 'field' && a.isTemplate);
            const hasPropagatedAnns = annotations.some(a => (a.mode || 'field') === 'field' && a.isGT === false && a.isTemplate);

            // If we have existing template AND not forcing regenerate, apply incremental transform instead
            if (hasTemplateAnns && !forceRegenerate) {
                // Convert propagated to GT if needed
                if (hasPropagatedAnns && !currentFrameEdited) {
                    convertToGTKeyframe();
                    console.log('[update3DTemplate] Converted propagated to GT keyframe');
                }

                // Apply incremental transformation to existing template
                // This preserves the template shape while allowing slider adjustments
                applyIncrementalTransform();

                currentFrameEdited = true;
                redraw();
                return;
            }

            // When forcing regeneration (pitch/yaw/camera changes), we need to sync
            // the non-changed parameters from the current template first
            // This ensures the regeneration produces a similar template with just the user's change applied
            if (forceRegenerate && hasTemplateAnns) {
                // Save ALL current slider values before syncing (user might have changed any of them)
                const savedValues = {
                    rotationX: field3D.rotationX,
                    rotationY: field3D.rotationY,
                    rotationZ: field3D.rotationZ,
                    cameraDistance: field3D.cameraDistance,
                    fieldLength: field3D.fieldLength,
                    fieldWidth: field3D.fieldWidth,
                    offsetX: field3D.offsetX,
                    offsetY: field3D.offsetY,
                    offsetZ: field3D.offsetZ,
                    scale: field3D.scale
                };

                // Sync from current template (this sets field3D values based on template corners)
                syncSlidersToCurrentTemplate();

                // Restore ALL saved values - preserve user's slider positions
                field3D.rotationX = savedValues.rotationX;
                field3D.rotationY = savedValues.rotationY;
                field3D.rotationZ = savedValues.rotationZ;
                field3D.cameraDistance = savedValues.cameraDistance;
                field3D.fieldLength = savedValues.fieldLength;
                field3D.fieldWidth = savedValues.fieldWidth;
                field3D.offsetX = savedValues.offsetX;
                field3D.offsetY = savedValues.offsetY;
                field3D.offsetZ = savedValues.offsetZ;
                field3D.scale = savedValues.scale;

                console.log('[update3DTemplate] Synced baseline before regeneration, all user values preserved');
            }

            const template3D = generate3DFieldTemplate(currentImage.width, currentImage.height, field3D);

            // Mark regenerated template as GT since user explicitly edited it via sliders
            template3D.forEach(ann => {
                ann.isGT = true;
            });

            // Replace only template annotations, keep user annotations
            annotations = annotations.filter(a => !a.isTemplate);
            annotations = annotations.concat(template3D);

            // Update GT reference and RigidTemplate so propagation uses the edited template positions
            const fieldAnns = annotations.filter(a => (a.mode || 'field') === 'field');
            if (fieldAnns.length > 0) {
                fieldGTReference = {
                    annotations: JSON.parse(JSON.stringify(fieldAnns)),
                    centroid: computeFieldCentroid(fieldAnns),
                    timestamp: Date.now()
                };
                lastFieldTransform = { dx: 0, dy: 0, scale: 1 };
                // Initialize RigidTemplate with regenerated template
                RigidTemplate.initFromAnnotations(fieldAnns);
            }

            // Reset incremental slider tracking after regeneration
            lastSliderValues = {
                offsetX: field3D.offsetX,
                offsetZ: field3D.offsetZ,
                rotationZ: field3D.rotationZ,
                scale: field3D.scale
            };

            // Reset scale/length/width tracking for incremental transforms
            lastScaleValue = field3D.scale;
            lastLengthValue = field3D.fieldLength;
            lastWidthValue = field3D.fieldWidth;

            currentFrameEdited = true;
            redraw();
        }

        document.getElementById('rotationX').addEventListener('input', (e) => {
            // Pitch (tilt down toward field) - proper 3D rotation
            field3D.rotationX = parseInt(e.target.value) / 10;
            document.getElementById('rotXValue').textContent = field3D.rotationX.toFixed(1);
            applyProper3DRotation();
        });

        document.getElementById('rotationY').addEventListener('input', (e) => {
            // Yaw (pan left/right) - proper 3D rotation relative to current pitch
            field3D.rotationY = parseInt(e.target.value) / 10;
            document.getElementById('rotYValue').textContent = field3D.rotationY.toFixed(1);
            applyProper3DRotation();
        });

        document.getElementById('rotationZ').addEventListener('input', (e) => {
            // Roll (horizon tilt) - proper 3D rotation relative to current pitch/yaw
            field3D.rotationZ = parseInt(e.target.value) / 10;
            document.getElementById('rotZValue').textContent = field3D.rotationZ.toFixed(1);
            applyProper3DRotation();
        });

        document.getElementById('cameraDistance').addEventListener('input', (e) => {
            field3D.cameraDistance = parseInt(e.target.value) / 10;
            document.getElementById('distValue').textContent = field3D.cameraDistance.toFixed(1);
            // Camera distance affects projection - use proper 3D
            applyProper3DRotation();
        });

        document.getElementById('fieldScale').addEventListener('input', (e) => {
            field3D.scale = parseInt(e.target.value) / 10;
            document.getElementById('scaleValue').textContent = field3D.scale.toFixed(1);
            // Scale affects focal length - use proper 3D
            applyProper3DRotation();
        });

        document.getElementById('positionX').addEventListener('input', (e) => {
            field3D.offsetX = parseInt(e.target.value) / 10;
            document.getElementById('posXValue').textContent = field3D.offsetX.toFixed(1);
            // Camera X position - use proper 3D
            applyProper3DRotation();
        });

        document.getElementById('positionY').addEventListener('input', (e) => {
            field3D.offsetY = parseInt(e.target.value) / 10;
            document.getElementById('posYValue').textContent = field3D.offsetY.toFixed(1);
            // Camera Y position - use proper 3D
            applyProper3DRotation();
        });

        document.getElementById('positionZ').addEventListener('input', (e) => {
            field3D.offsetZ = parseInt(e.target.value) / 10;
            document.getElementById('posZValue').textContent = field3D.offsetZ.toFixed(1);
            // Camera Z offset - use proper 3D
            applyProper3DRotation();
        });

        document.getElementById('fieldLength').addEventListener('input', (e) => {
            field3D.fieldLength = parseInt(e.target.value) / 10;
            document.getElementById('fieldLengthValue').textContent = field3D.fieldLength.toFixed(1);
            // Apply as incremental vertical scaling
            applyLengthTransform();
        });

        document.getElementById('fieldWidth').addEventListener('input', (e) => {
            field3D.fieldWidth = parseInt(e.target.value) / 10;
            document.getElementById('fieldWidthValue').textContent = field3D.fieldWidth.toFixed(1);
            // Apply as incremental horizontal scaling
            applyWidthTransform();
        });

        document.getElementById('load3DTemplate').onclick = () => {
            if (!currentImage) {
                setStatus('Load a video first');
                return;
            }
            saveState();
            update3DTemplate(true);  // Force regenerate from 3D parameters
            updateAnnotationsPanel();
            setStatus('3D template loaded');
        };

        document.getElementById('reset3DView').onclick = () => {
            field3D = {
                rotationX: 70,
                rotationY: 0,
                rotationZ: 0,
                cameraDistance: 80,
                offsetX: 0,
                offsetY: 0,
                offsetZ: 0,
                scale: 1.5,
                fieldLength: 105,
                fieldWidth: 68
                // Note: 6yd box, 18yd box, center circle use fixed FIFA standard dimensions
            };
            // Update UI sliders to match (multiply by 10 for slider values)
            document.getElementById('rotationX').value = field3D.rotationX * 10;
            document.getElementById('rotXValue').textContent = field3D.rotationX.toFixed(1);
            document.getElementById('rotationY').value = field3D.rotationY * 10;
            document.getElementById('rotYValue').textContent = field3D.rotationY.toFixed(1);
            document.getElementById('rotationZ').value = field3D.rotationZ * 10;
            document.getElementById('rotZValue').textContent = field3D.rotationZ.toFixed(1);
            document.getElementById('cameraDistance').value = field3D.cameraDistance * 10;
            document.getElementById('distValue').textContent = field3D.cameraDistance.toFixed(1);
            document.getElementById('fieldScale').value = field3D.scale * 10;
            document.getElementById('scaleValue').textContent = field3D.scale.toFixed(1);
            document.getElementById('positionX').value = field3D.offsetX * 10;
            document.getElementById('posXValue').textContent = field3D.offsetX.toFixed(1);
            document.getElementById('positionY').value = field3D.offsetY * 10;
            document.getElementById('posYValue').textContent = field3D.offsetY.toFixed(1);
            document.getElementById('positionZ').value = field3D.offsetZ * 10;
            document.getElementById('posZValue').textContent = field3D.offsetZ.toFixed(1);
            document.getElementById('fieldLength').value = field3D.fieldLength * 10;
            document.getElementById('fieldLengthValue').textContent = field3D.fieldLength.toFixed(1);
            document.getElementById('fieldWidth').value = field3D.fieldWidth * 10;
            document.getElementById('fieldWidthValue').textContent = field3D.fieldWidth.toFixed(1);

            // Reset incremental tracking values to defaults
            lastScaleValue = 1.5;
            lastLengthValue = 105;
            lastWidthValue = 68;
            lastSliderValues = {
                offsetX: 0,
                offsetZ: 0,
                rotationZ: 0,
                scale: 1.5
            };

            update3DTemplate();
            setStatus('3D view reset');
        };

        // ============================================
        // FIELD CALIBRATION SYSTEM
        // Click on known field points to compute homography
        // ============================================

        let calibrationMode = false;
        let calibrationPoints = [];  // [{pixel: {x, y}, fieldPoint: string, world: {x, y}}]
        let pendingCalibrationClick = null;  // {x, y} - waiting for point type selection

        // 3D world coordinates for all selectable field points (in meters)
        // Using FIELD_LENGTH=105m, FIELD_WIDTH=68m as reference
        const CALIBRATION_FIELD_POINTS = {
            // Field corners
            corner_tl: { x: 0, y: 0 },
            corner_tr: { x: 105, y: 0 },
            corner_bl: { x: 0, y: 68 },
            corner_br: { x: 105, y: 68 },

            // Center line
            center_top: { x: 52.5, y: 0 },
            center_mid: { x: 52.5, y: 34 },
            center_bottom: { x: 52.5, y: 68 },

            // Left penalty area (18 yards = 16.46m deep, 44 yards = 40.23m wide)
            penalty_left_top: { x: 16.46, y: (68 - 40.23) / 2 },
            penalty_left_bottom: { x: 16.46, y: (68 + 40.23) / 2 },
            penalty_left_goal_top: { x: 0, y: (68 - 40.23) / 2 },
            penalty_left_goal_bottom: { x: 0, y: (68 + 40.23) / 2 },

            // Right penalty area
            penalty_right_top: { x: 105 - 16.46, y: (68 - 40.23) / 2 },
            penalty_right_bottom: { x: 105 - 16.46, y: (68 + 40.23) / 2 },
            penalty_right_goal_top: { x: 105, y: (68 - 40.23) / 2 },
            penalty_right_goal_bottom: { x: 105, y: (68 + 40.23) / 2 },

            // Left goal area (6 yards = 5.49m deep, 20 yards = 18.29m wide)
            goal_area_left_top: { x: 5.49, y: (68 - 18.29) / 2 },
            goal_area_left_bottom: { x: 5.49, y: (68 + 18.29) / 2 },
            goal_area_left_goal_top: { x: 0, y: (68 - 18.29) / 2 },
            goal_area_left_goal_bottom: { x: 0, y: (68 + 18.29) / 2 },

            // Right goal area
            goal_area_right_top: { x: 105 - 5.49, y: (68 - 18.29) / 2 },
            goal_area_right_bottom: { x: 105 - 5.49, y: (68 + 18.29) / 2 },
            goal_area_right_goal_top: { x: 105, y: (68 - 18.29) / 2 },
            goal_area_right_goal_bottom: { x: 105, y: (68 + 18.29) / 2 },

            // Center circle (radius = 9.15m)
            center_circle_top: { x: 52.5, y: 34 - 9.15 },
            center_circle_bottom: { x: 52.5, y: 34 + 9.15 },
            center_circle_left: { x: 52.5 - 9.15, y: 34 },
            center_circle_right: { x: 52.5 + 9.15, y: 34 }
        };

        // Enter calibration mode
        document.getElementById('calibrateFieldBtn').onclick = () => {
            calibrationMode = true;
            calibrationPoints = [];
            pendingCalibrationClick = null;
            document.getElementById('calibrationPanel').style.display = 'block';
            document.getElementById('fieldPointSelector').value = '';
            updateCalibrationUI();
            setStatus('Calibration mode: Click on a visible field point');
            redraw();
        };

        // Exit calibration mode
        document.getElementById('exitCalibration').onclick = () => {
            calibrationMode = false;
            calibrationPoints = [];
            pendingCalibrationClick = null;
            document.getElementById('calibrationPanel').style.display = 'none';
            setStatus('Exited calibration mode');
            redraw();
        };

        // Clear all calibration points
        document.getElementById('clearCalibration').onclick = () => {
            calibrationPoints = [];
            pendingCalibrationClick = null;
            document.getElementById('fieldPointSelector').value = '';
            updateCalibrationUI();
            setStatus('Calibration points cleared');
            redraw();
        };

        // Undo last calibration point
        document.getElementById('undoCalibrationPoint').onclick = () => {
            if (pendingCalibrationClick) {
                pendingCalibrationClick = null;
                document.getElementById('fieldPointSelector').value = '';
            } else if (calibrationPoints.length > 0) {
                calibrationPoints.pop();
            }
            updateCalibrationUI();
            redraw();
        };

        // Field point selector changed
        document.getElementById('fieldPointSelector').onchange = (e) => {
            const pointType = e.target.value;
            if (!pointType || !pendingCalibrationClick) return;

            // Check if this point type is already used
            if (calibrationPoints.some(p => p.fieldPoint === pointType)) {
                setStatus('This point is already marked! Choose another or undo.');
                e.target.value = '';
                return;
            }

            // Add the calibration point
            const worldCoord = CALIBRATION_FIELD_POINTS[pointType];
            if (!worldCoord) {
                setStatus('Unknown point type');
                return;
            }

            calibrationPoints.push({
                pixel: pendingCalibrationClick,
                fieldPoint: pointType,
                world: worldCoord
            });

            pendingCalibrationClick = null;
            e.target.value = '';
            updateCalibrationUI();
            redraw();

            const pointName = e.target.options[e.target.selectedIndex]?.text || pointType;
            setStatus(`Added: ${pointName} (${calibrationPoints.length} points total)`);
        };

        // Update calibration UI
        function updateCalibrationUI() {
            const countDiv = document.getElementById('calibrationPoints');
            const generateBtn = document.getElementById('generateFromCalibration');

            countDiv.textContent = `Points: ${calibrationPoints.length} / 4 minimum`;
            if (pendingCalibrationClick) {
                countDiv.textContent += ' (select point type!)';
                countDiv.style.color = '#fcd34d';
            } else {
                countDiv.style.color = '#d1fae5';
            }

            if (calibrationPoints.length >= 4) {
                generateBtn.disabled = false;
                generateBtn.textContent = `Generate Template (${calibrationPoints.length} points)`;
            } else {
                generateBtn.disabled = true;
                generateBtn.textContent = `Generate Template (need ${4 - calibrationPoints.length} more)`;
            }
        }

        // Draw calibration points on canvas
        function drawCalibrationPoints(ctx) {
            if (!calibrationMode) return;

            // Draw confirmed points
            calibrationPoints.forEach((pt, idx) => {
                ctx.beginPath();
                ctx.arc(pt.pixel.x, pt.pixel.y, 8, 0, Math.PI * 2);
                ctx.fillStyle = '#10b981';
                ctx.fill();
                ctx.strokeStyle = '#fff';
                ctx.lineWidth = 2;
                ctx.stroke();

                // Label
                ctx.fillStyle = '#fff';
                ctx.font = 'bold 12px Arial';
                ctx.textAlign = 'left';
                ctx.fillText(`${idx + 1}: ${pt.fieldPoint}`, pt.pixel.x + 12, pt.pixel.y + 4);
            });

            // Draw pending click point
            if (pendingCalibrationClick) {
                ctx.beginPath();
                ctx.arc(pendingCalibrationClick.x, pendingCalibrationClick.y, 10, 0, Math.PI * 2);
                ctx.fillStyle = '#fbbf24';
                ctx.fill();
                ctx.strokeStyle = '#fff';
                ctx.lineWidth = 2;
                ctx.stroke();

                ctx.fillStyle = '#fff';
                ctx.font = 'bold 12px Arial';
                ctx.textAlign = 'left';
                ctx.fillText('? Select point type', pendingCalibrationClick.x + 14, pendingCalibrationClick.y + 4);
            }
        }

        // Compute homography using normalized DLT (Direct Linear Transform) for CALIBRATION
        // Maps world coordinates (field meters) to pixel coordinates (image)
        // Takes array of {pixel: {x,y}, world: {x,y}} correspondences
        function computeCalibrationHomography(correspondences) {
            // Need at least 4 points
            if (correspondences.length < 4) return null;

            const n = correspondences.length;

            // ============================================
            // STEP 1: Normalize coordinates for numerical stability
            // ============================================

            // Compute centroids
            let srcCentroid = { x: 0, y: 0 };
            let dstCentroid = { x: 0, y: 0 };
            for (const corr of correspondences) {
                srcCentroid.x += corr.world.x;
                srcCentroid.y += corr.world.y;
                dstCentroid.x += corr.pixel.x;
                dstCentroid.y += corr.pixel.y;
            }
            srcCentroid.x /= n;
            srcCentroid.y /= n;
            dstCentroid.x /= n;
            dstCentroid.y /= n;

            // Compute average distances from centroid
            let srcAvgDist = 0;
            let dstAvgDist = 0;
            for (const corr of correspondences) {
                srcAvgDist += Math.hypot(corr.world.x - srcCentroid.x, corr.world.y - srcCentroid.y);
                dstAvgDist += Math.hypot(corr.pixel.x - dstCentroid.x, corr.pixel.y - dstCentroid.y);
            }
            srcAvgDist /= n;
            dstAvgDist /= n;

            // Scale factors to make average distance = sqrt(2)
            const srcScale = srcAvgDist > 0 ? Math.SQRT2 / srcAvgDist : 1;
            const dstScale = dstAvgDist > 0 ? Math.SQRT2 / dstAvgDist : 1;

            console.log('[Calibration] Normalization - src centroid:', srcCentroid, 'scale:', srcScale.toFixed(4));
            console.log('[Calibration] Normalization - dst centroid:', dstCentroid, 'scale:', dstScale.toFixed(4));

            // ============================================
            // STEP 2: Build DLT matrix with normalized coordinates
            // ============================================

            const A = [];
            for (const corr of correspondences) {
                // Normalize coordinates
                const X = (corr.world.x - srcCentroid.x) * srcScale;
                const Y = (corr.world.y - srcCentroid.y) * srcScale;
                const x = (corr.pixel.x - dstCentroid.x) * dstScale;
                const y = (corr.pixel.y - dstCentroid.y) * dstScale;

                // DLT matrix rows
                A.push([-X, -Y, -1, 0, 0, 0, x * X, x * Y, x]);
                A.push([0, 0, 0, -X, -Y, -1, y * X, y * Y, y]);
            }

            // Compute A'A (9x9 matrix)
            const ATA = [];
            for (let i = 0; i < 9; i++) {
                ATA[i] = [];
                for (let j = 0; j < 9; j++) {
                    let sum = 0;
                    for (let k = 0; k < A.length; k++) {
                        sum += A[k][i] * A[k][j];
                    }
                    ATA[i][j] = sum;
                }
            }

            // Inverse power iteration to find smallest eigenvector
            let h = [1, 0, 0, 0, 1, 0, 0, 0, 1];
            for (let iter = 0; iter < 100; iter++) {
                const h_new = solveLinearSystem(ATA, h);
                if (!h_new) break;

                let norm = 0;
                for (let i = 0; i < 9; i++) norm += h_new[i] * h_new[i];
                norm = Math.sqrt(norm);
                if (norm < 1e-10) break;

                for (let i = 0; i < 9; i++) h_new[i] /= norm;
                h = h_new;
            }

            // Normalized homography
            const Hn = [
                [h[0], h[1], h[2]],
                [h[3], h[4], h[5]],
                [h[6], h[7], h[8]]
            ];

            // ============================================
            // STEP 3: Denormalize: H = T_dst^-1 * Hn * T_src
            // ============================================

            // T_src normalizes world coords: p' = s*(p - c)
            // T_dst normalizes pixel coords: q' = s*(q - c)
            // We want: q = H * p, but we computed: q' = Hn * p'
            // So: s_d*(q - c_d) = Hn * s_s*(p - c_s)
            // q = (1/s_d) * Hn * s_s * p + c_d - (1/s_d)*Hn*s_s*c_s

            // Build normalization matrices
            const T_src = [
                [srcScale, 0, -srcScale * srcCentroid.x],
                [0, srcScale, -srcScale * srcCentroid.y],
                [0, 0, 1]
            ];

            const T_dst_inv = [
                [1 / dstScale, 0, dstCentroid.x],
                [0, 1 / dstScale, dstCentroid.y],
                [0, 0, 1]
            ];

            // H = T_dst_inv * Hn * T_src
            const temp = multiplyMatrix3x3(Hn, T_src);
            const H = multiplyMatrix3x3(T_dst_inv, temp);

            return H;
        }

        // Multiply two 3x3 matrices
        function multiplyMatrix3x3(A, B) {
            const C = [[0, 0, 0], [0, 0, 0], [0, 0, 0]];
            for (let i = 0; i < 3; i++) {
                for (let j = 0; j < 3; j++) {
                    for (let k = 0; k < 3; k++) {
                        C[i][j] += A[i][k] * B[k][j];
                    }
                }
            }
            return C;
        }

        // Solve linear system Ax = b using Gaussian elimination with partial pivoting
        function solveLinearSystem(A, b) {
            const n = A.length;
            // Create augmented matrix
            const aug = A.map((row, i) => [...row, b[i]]);

            // Forward elimination
            for (let i = 0; i < n; i++) {
                // Find pivot
                let maxVal = Math.abs(aug[i][i]);
                let maxRow = i;
                for (let k = i + 1; k < n; k++) {
                    if (Math.abs(aug[k][i]) > maxVal) {
                        maxVal = Math.abs(aug[k][i]);
                        maxRow = k;
                    }
                }

                // Swap rows
                [aug[i], aug[maxRow]] = [aug[maxRow], aug[i]];

                if (Math.abs(aug[i][i]) < 1e-10) continue;

                // Eliminate
                for (let k = i + 1; k < n; k++) {
                    const factor = aug[k][i] / aug[i][i];
                    for (let j = i; j <= n; j++) {
                        aug[k][j] -= factor * aug[i][j];
                    }
                }
            }

            // Back substitution
            const x = new Array(n).fill(0);
            for (let i = n - 1; i >= 0; i--) {
                if (Math.abs(aug[i][i]) < 1e-10) {
                    x[i] = 0;
                    continue;
                }
                x[i] = aug[i][n];
                for (let j = i + 1; j < n; j++) {
                    x[i] -= aug[i][j] * x[j];
                }
                x[i] /= aug[i][i];
            }

            return x;
        }

        // Apply homography to transform world point to pixel
        function applyHomography(H, worldX, worldY) {
            const w = H[2][0] * worldX + H[2][1] * worldY + H[2][2];
            if (Math.abs(w) < 1e-10) return null;

            const x = (H[0][0] * worldX + H[0][1] * worldY + H[0][2]) / w;
            const y = (H[1][0] * worldX + H[1][1] * worldY + H[1][2]) / w;

            return { x, y };
        }

        // Generate template from calibration
        document.getElementById('generateFromCalibration').onclick = () => {
            if (calibrationPoints.length < 4) {
                setStatus('Need at least 4 calibration points');
                return;
            }

            console.log('[Calibration] Computing homography from', calibrationPoints.length, 'points');

            // Compute homography
            const H = computeCalibrationHomography(calibrationPoints);
            if (!H) {
                setStatus('Failed to compute homography - check point positions');
                return;
            }

            console.log('[Calibration] Homography matrix:', H);

            // Test reprojection error
            let totalError = 0;
            calibrationPoints.forEach(pt => {
                const projected = applyHomography(H, pt.world.x, pt.world.y);
                if (projected) {
                    const err = Math.hypot(projected.x - pt.pixel.x, projected.y - pt.pixel.y);
                    totalError += err;
                    console.log(`[Calibration] ${pt.fieldPoint}: error = ${err.toFixed(1)}px`);
                }
            });
            const avgError = totalError / calibrationPoints.length;
            console.log(`[Calibration] Average reprojection error: ${avgError.toFixed(1)}px`);

            if (avgError > 20) {
                setStatus(`Warning: High reprojection error (${avgError.toFixed(1)}px) - check point accuracy`);
            }

            // Sanity check: verify the 4 field corners project reasonably
            const testCorners = [
                { world: { x: 0, y: 0 }, name: 'TL' },
                { world: { x: 105, y: 0 }, name: 'TR' },
                { world: { x: 0, y: 68 }, name: 'BL' },
                { world: { x: 105, y: 68 }, name: 'BR' }
            ];

            const projectedCorners = testCorners.map(c => ({
                ...c,
                pixel: applyHomography(H, c.world.x, c.world.y)
            }));

            console.log('[Calibration] Projected field corners:');
            projectedCorners.forEach(c => {
                console.log(`  ${c.name}: (${c.pixel.x.toFixed(0)}, ${c.pixel.y.toFixed(0)})`);
            });

            // Check for obviously wrong projections
            const tl = projectedCorners[0].pixel;
            const tr = projectedCorners[1].pixel;
            const bl = projectedCorners[2].pixel;
            const br = projectedCorners[3].pixel;

            // Top should be above bottom
            if (tl.y > bl.y || tr.y > br.y) {
                setStatus('Calibration error: field appears upside down. Check your point selections.');
                console.error('[Calibration] REJECTED: Field is upside down');
                return;
            }

            // Left should be left of right
            if (tl.x > tr.x || bl.x > br.x) {
                setStatus('Calibration error: field appears mirrored. Check your point selections.');
                console.error('[Calibration] REJECTED: Field is mirrored');
                return;
            }

            // Check for extreme extrapolation (corners way outside frame)
            const imgWidth = img ? img.width : 1280;
            const imgHeight = img ? img.height : 720;
            const maxExtend = 3; // Allow up to 3x frame size for extrapolation

            const isReasonable = (p) => {
                return p.x > -imgWidth * maxExtend && p.x < imgWidth * (1 + maxExtend) &&
                       p.y > -imgHeight * maxExtend && p.y < imgHeight * (1 + maxExtend);
            };

            if (!projectedCorners.every(c => isReasonable(c.pixel))) {
                setStatus('Calibration error: extreme extrapolation detected. Add more calibration points.');
                console.error('[Calibration] REJECTED: Extreme extrapolation');
                return;
            }

            // Clear existing field annotations
            annotations = annotations.filter(a => (a.mode || 'field') !== 'field');

            // Generate template lines using the homography
            const FIELD_L = 105;  // meters
            const FIELD_W = 68;   // meters

            // Define all template lines with world coordinates
            const templateLines = [
                { id: 'touchline_top', points: [[0, 0], [52.5, 0], [105, 0]], label: 'Touchline Top' },
                { id: 'touchline_bottom', points: [[0, 68], [52.5, 68], [105, 68]], label: 'Touchline Bottom' },
                { id: 'goal_line_left', points: [[0, 0], [0, 68]], label: 'Goal Line Left' },
                { id: 'goal_line_right', points: [[105, 0], [105, 68]], label: 'Goal Line Right' },
                { id: 'center_line', points: [[52.5, 0], [52.5, 34], [52.5, 68]], label: 'Center Line' },
                // Left penalty area
                { id: 'penalty_left', points: [
                    [0, (68 - 40.23) / 2],
                    [16.46, (68 - 40.23) / 2],
                    [16.46, (68 + 40.23) / 2],
                    [0, (68 + 40.23) / 2]
                ], label: 'Penalty Area Left' },
                // Right penalty area
                { id: 'penalty_right', points: [
                    [105, (68 - 40.23) / 2],
                    [105 - 16.46, (68 - 40.23) / 2],
                    [105 - 16.46, (68 + 40.23) / 2],
                    [105, (68 + 40.23) / 2]
                ], label: 'Penalty Area Right' },
                // Left goal area
                { id: 'goal_area_left', points: [
                    [0, (68 - 18.29) / 2],
                    [5.49, (68 - 18.29) / 2],
                    [5.49, (68 + 18.29) / 2],
                    [0, (68 + 18.29) / 2]
                ], label: 'Goal Area Left' },
                // Right goal area
                { id: 'goal_area_right', points: [
                    [105, (68 - 18.29) / 2],
                    [105 - 5.49, (68 - 18.29) / 2],
                    [105 - 5.49, (68 + 18.29) / 2],
                    [105, (68 + 18.29) / 2]
                ], label: 'Goal Area Right' }
            ];

            // Project and add lines
            templateLines.forEach(line => {
                const projectedPoints = line.points.map(([wx, wy]) => {
                    const p = applyHomography(H, wx, wy);
                    return p ? [p.x, p.y] : null;
                }).filter(p => p !== null);

                if (projectedPoints.length >= 2) {
                    annotations.push({
                        type: 'line',
                        id: line.id,
                        label: line.label,
                        points: projectedPoints,
                        mode: 'field',
                        isGT: true,
                        isTemplate: true
                    });
                }
            });

            // Note: Center circle ellipse removed for simplicity
            // Center circle calibration points can still be used for homography input
            // but we don't render the ellipse - lines only are more stable

            // Exit calibration mode
            calibrationMode = false;
            document.getElementById('calibrationPanel').style.display = 'none';

            // Update UI
            updateAnnotationsPanel();
            redraw();
            setStatus(`Template generated from ${calibrationPoints.length} calibration points (avg error: ${avgError.toFixed(1)}px)`);

            // Store as baseline for transforms
            storeCamera3DBaseline();
        };

        // Handle clicks in calibration mode
        function handleCalibrationClick(x, y) {
            if (!calibrationMode) return false;

            // If there's a pending click waiting for type selection, don't allow another click
            if (pendingCalibrationClick) {
                setStatus('Please select the point type for the yellow marker first');
                return true;
            }

            pendingCalibrationClick = { x, y };
            updateCalibrationUI();
            setStatus('Now select what field point this is from the dropdown');
            redraw();
            return true;
        }

        // ============================================
        // DRAGGABLE TEMPLATE POINTS FOR CALIBRATION
        // Drag ANY point to calibrate. Once 4+ points are set,
        // homography is computed and shape stays valid rectangle.
        // ============================================

        // Pinned points - points user has manually positioned
        let pinnedPoints = {};  // { pointName: {x, y} }
        let draggingPoint = null;
        let calibrateDragStart = null;  // Renamed to avoid conflict with general dragStartPos
        let currentDragPos = null;  // Track drag position for drawing dot at cursor
        let anchorHandlesVisible = true;

        // Called when template is loaded/generated - reset state
        function initTemplateAnchors() {
            pinnedPoints = {};
            draggingPoint = null;
            calibrateDragStart = null;
            currentDragPos = null;
            console.log('[Calibrate] Ready - drag any point to calibrate');
        }

        // Get all template points with their current positions
        function getAllTemplatePoints() {
            const points = {};
            const templateAnns = annotations.filter(a => a.isTemplate && a.templatePoints);
            for (const ann of templateAnns) {
                if (!ann.templatePoints || !ann.points) continue;
                ann.templatePoints.forEach((ptName, idx) => {
                    if (ann.points[idx] && !points[ptName]) {
                        points[ptName] = {
                            x: ann.points[idx][0],
                            y: ann.points[idx][1]
                        };
                    }
                });
            }
            return points;
        }

        // Count pinned points
        function countPinnedPoints() {
            return Object.keys(pinnedPoints).length;
        }

        // Regenerate template from pinned points - SIMPLE direct homography
        function regenerateTemplateFromPins() {
            const numPins = countPinnedPoints();
            if (numPins < 4) {
                console.log('[Calibrate] Need 4+ points, have', numPins);
                return false;
            }

            // Build correspondences directly from pinned points
            const correspondences = [];
            for (const [ptName, pixelPos] of Object.entries(pinnedPoints)) {
                const world = CALIBRATION_FIELD_POINTS[ptName];
                if (world) {
                    correspondences.push({
                        name: ptName,
                        world: { x: world.x / 105, y: world.y / 68 },
                        pixel: pixelPos
                    });
                }
            }

            if (correspondences.length < 4) {
                return false;
            }

            // Compute homography directly - no constraints, just fit the points
            const H = computeHomographyDLT(correspondences);
            if (!H || H.flat().some(v => !isFinite(v))) {
                console.error('[Calibrate] Homography failed');
                return false;
            }

            console.log('[Calibrate] Homography computed from', correspondences.length, 'points');

            // Regenerate all template lines
            const newAnnotations = [];
            FIELD_TEMPLATE_LINES.forEach(line => {
                const projectedPoints = line.points.map(ptName => {
                    const world = CALIBRATION_FIELD_POINTS[ptName];
                    if (!world) return null;
                    const u = world.x / 105;
                    const v = world.y / 68;
                    const proj = applyHomography(H, u, v);
                    if (!proj || !isFinite(proj.x) || !isFinite(proj.y)) return null;
                    return [proj.x, proj.y];
                }).filter(p => p !== null);

                if (projectedPoints.length >= 2) {
                    newAnnotations.push({
                        type: 'line',
                        id: line.id,
                        label: line.label,
                        points: projectedPoints,
                        templatePoints: line.points,
                        mode: 'field',
                        isGT: true,
                        isTemplate: true
                    });
                }
            });

            // Replace template
            const oldCount = annotations.filter(a => a.isTemplate).length;
            annotations = annotations.filter(a => !a.isTemplate);
            annotations = annotations.concat(newAnnotations);

            console.log('[Calibrate] Replaced', oldCount, 'template annotations with', newAnnotations.length, 'new ones');
            console.log('[Calibrate] Total annotations now:', annotations.length);
            return true;
        }

        // Compute homography using Direct Linear Transform with normalization
        function computeHomographyDLT(correspondences) {
            const n = correspondences.length;
            if (n < 4) return null;

            // Step 1: Normalize points for numerical stability
            // Normalize world points
            let sumWx = 0, sumWy = 0;
            for (const c of correspondences) { sumWx += c.world.x; sumWy += c.world.y; }
            const meanWx = sumWx / n, meanWy = sumWy / n;
            let scaleW = 0;
            for (const c of correspondences) {
                scaleW += Math.hypot(c.world.x - meanWx, c.world.y - meanWy);
            }
            scaleW = (n * Math.sqrt(2)) / scaleW;

            // Normalize pixel points
            let sumPx = 0, sumPy = 0;
            for (const c of correspondences) { sumPx += c.pixel.x; sumPy += c.pixel.y; }
            const meanPx = sumPx / n, meanPy = sumPy / n;
            let scaleP = 0;
            for (const c of correspondences) {
                scaleP += Math.hypot(c.pixel.x - meanPx, c.pixel.y - meanPy);
            }
            scaleP = (n * Math.sqrt(2)) / scaleP;

            console.log('[DLT] Normalization - world:', {meanWx, meanWy, scaleW}, 'pixel:', {meanPx, meanPy, scaleP});

            // Build normalized correspondences
            const normCorr = correspondences.map(c => ({
                world: { x: (c.world.x - meanWx) * scaleW, y: (c.world.y - meanWy) * scaleW },
                pixel: { x: (c.pixel.x - meanPx) * scaleP, y: (c.pixel.y - meanPy) * scaleP }
            }));

            // Build the 2n x 9 matrix A for DLT
            const A = [];
            for (const c of normCorr) {
                const X = c.world.x, Y = c.world.y;
                const x = c.pixel.x, y = c.pixel.y;
                A.push([-X, -Y, -1, 0, 0, 0, x*X, x*Y, x]);
                A.push([0, 0, 0, -X, -Y, -1, y*X, y*Y, y]);
            }

            // Compute A^T * A (9x9)
            const ATA = [];
            for (let i = 0; i < 9; i++) {
                ATA[i] = [];
                for (let j = 0; j < 9; j++) {
                    let sum = 0;
                    for (let k = 0; k < A.length; k++) {
                        sum += A[k][i] * A[k][j];
                    }
                    ATA[i][j] = sum;
                }
            }

            // Find smallest eigenvector using power iteration on (ATA + shift*I)^-1
            // Add small shift to avoid singularity
            const shift = 1e-6;
            for (let i = 0; i < 9; i++) ATA[i][i] += shift;

            let h = [1, 1, 1, 1, 1, 1, 1, 1, 1];  // Start with non-trivial guess
            for (let iter = 0; iter < 100; iter++) {
                const h_new = solveLinearSystemNxN(ATA, h);
                if (!h_new) {
                    console.log('[DLT] Linear solve failed at iter', iter);
                    break;
                }

                let norm = 0;
                for (let i = 0; i < 9; i++) norm += h_new[i] * h_new[i];
                norm = Math.sqrt(norm);
                if (norm < 1e-12) break;
                for (let i = 0; i < 9; i++) h_new[i] /= norm;

                // Check convergence
                let diff = 0;
                for (let i = 0; i < 9; i++) diff += (h_new[i] - h[i]) * (h_new[i] - h[i]);
                h = h_new;
                if (diff < 1e-14) break;
            }

            // Build normalized homography
            const Hn = [
                [h[0], h[1], h[2]],
                [h[3], h[4], h[5]],
                [h[6], h[7], h[8]]
            ];

            // Denormalize: H = Tp^-1 * Hn * Tw
            // Tw normalizes world: [scaleW, 0, -meanWx*scaleW; 0, scaleW, -meanWy*scaleW; 0, 0, 1]
            // Tp normalizes pixel: [scaleP, 0, -meanPx*scaleP; 0, scaleP, -meanPy*scaleP; 0, 0, 1]
            // Tp^-1 = [1/scaleP, 0, meanPx; 0, 1/scaleP, meanPy; 0, 0, 1]

            const Tw = [
                [scaleW, 0, -meanWx * scaleW],
                [0, scaleW, -meanWy * scaleW],
                [0, 0, 1]
            ];
            const TpInv = [
                [1/scaleP, 0, meanPx],
                [0, 1/scaleP, meanPy],
                [0, 0, 1]
            ];

            // H = TpInv * Hn * Tw
            const HnTw = multiplyMatrix3x3(Hn, Tw);
            const H = multiplyMatrix3x3(TpInv, HnTw);

            console.log('[DLT] Final H:', JSON.stringify(H));
            return H;
        }

        // 3x3 matrix multiplication
        function multiplyMatrix3x3(A, B) {
            const C = [[0,0,0], [0,0,0], [0,0,0]];
            for (let i = 0; i < 3; i++) {
                for (let j = 0; j < 3; j++) {
                    for (let k = 0; k < 3; k++) {
                        C[i][j] += A[i][k] * B[k][j];
                    }
                }
            }
            return C;
        }

        // Solve NxN linear system Ax=b
        function solveLinearSystemNxN(A, b) {
            const n = A.length;
            const aug = A.map((row, i) => [...row, b[i]]);

            for (let col = 0; col < n; col++) {
                let maxVal = Math.abs(aug[col][col]);
                let maxRow = col;
                for (let row = col + 1; row < n; row++) {
                    if (Math.abs(aug[row][col]) > maxVal) {
                        maxVal = Math.abs(aug[row][col]);
                        maxRow = row;
                    }
                }
                if (maxVal < 1e-12) return null;
                [aug[col], aug[maxRow]] = [aug[maxRow], aug[col]];

                for (let row = col + 1; row < n; row++) {
                    const f = aug[row][col] / aug[col][col];
                    for (let j = col; j <= n; j++) aug[row][j] -= f * aug[col][j];
                }
            }

            const x = new Array(n).fill(0);
            for (let i = n - 1; i >= 0; i--) {
                x[i] = aug[i][n];
                for (let j = i + 1; j < n; j++) x[i] -= aug[i][j] * x[j];
                x[i] /= aug[i][i];
            }
            return x;
        }

        // Draw all template points as draggable handles
        function drawTemplateAnchorHandles(ctx) {
            if (!anchorHandlesVisible || !scale) return;

            const templateAnns = annotations.filter(a => a.isTemplate && a.templatePoints);
            if (templateAnns.length === 0) return;

            const allPoints = getAllTemplatePoints();
            const numPinned = countPinnedPoints();

            // Draw all template points
            for (const [ptName, pos] of Object.entries(allPoints)) {
                const isPinned = pinnedPoints[ptName] !== undefined;
                const isDragging = draggingPoint === ptName;
                const isCorner = ptName.startsWith('corner_');

                // If dragging this point, draw at drag position instead
                const drawPos = (isDragging && currentDragPos) ? currentDragPos : pos;
                const sx = drawPos.x * scale;
                const sy = drawPos.y * scale;

                // Draw handle - corners larger
                const radius = isCorner ? (isDragging ? 12 : 9) : (isDragging ? 9 : 6);
                ctx.beginPath();
                ctx.arc(sx, sy, radius, 0, Math.PI * 2);

                if (isDragging) {
                    ctx.fillStyle = '#fbbf24';  // Yellow when dragging
                } else if (isPinned) {
                    ctx.fillStyle = '#10b981';  // Green when pinned
                } else {
                    ctx.fillStyle = 'rgba(59, 130, 246, 0.8)';  // Blue for all unpinned points
                }
                ctx.fill();
                ctx.strokeStyle = '#fff';
                ctx.lineWidth = 2;
                ctx.stroke();
            }

            // Status text
            ctx.font = 'bold 12px Arial';
            ctx.textAlign = 'left';
            if (draggingPoint) {
                ctx.fillStyle = '#fbbf24';
                ctx.fillText(`Dragging: ${draggingPoint.replace(/_/g, ' ')}`, 10, 25);
            } else if (numPinned > 0) {
                ctx.fillStyle = numPinned >= 4 ? '#10b981' : '#fbbf24';
                ctx.fillText(`${numPinned}/4 points pinned${numPinned >= 4 ? ' - calibrated!' : ''}`, 10, 25);
            }
        }

        // Hit test - any template point is draggable
        function hitTestAnchorPoint(x, y) {
            const allPoints = getAllTemplatePoints();
            let closest = null;
            let closestDist = 25;  // Max hit distance

            for (const [ptName, pos] of Object.entries(allPoints)) {
                const dist = Math.hypot(x - pos.x, y - pos.y);
                if (dist < closestDist) {
                    closestDist = dist;
                    closest = { pointName: ptName, pos };
                }
            }
            return closest;
        }

        // Update dragged point - DON'T move template, just track position for drawing
        function updateAnchorDrag(x, y) {
            if (!draggingPoint) return;

            // Just track the position - don't modify template
            currentDragPos = { x, y };
            redraw();
        }

        // Start dragging
        function startAnchorDrag(anchorInfo, x, y) {
            draggingPoint = anchorInfo.pointName;
            calibrateDragStart = anchorInfo.pos ? { ...anchorInfo.pos } : null;
            console.log('[Calibrate] Start drag:', draggingPoint);
        }

        // End drag - pin the point and snap template to fit ALL pinned points
        function endAnchorDrag(x, y) {
            if (!draggingPoint) return;

            // Store the point name before clearing drag state
            const justPinnedPoint = draggingPoint;

            // Pin this point at cursor position (use drag position if available)
            const finalPos = currentDragPos || { x, y };
            pinnedPoints[draggingPoint] = { ...finalPos };
            console.log('[Calibrate] Pinned:', draggingPoint, 'at', finalPos, 'Total:', countPinnedPoints());

            // Clear drag state
            draggingPoint = null;
            calibrateDragStart = null;
            currentDragPos = null;

            // Now snap the entire template to fit all pinned points (only if 4+)
            // Always succeeds - snaps to closest realistic geometry
            snapTemplateToConstraints();

            currentFrameEdited = true;
            updateAnnotationsPanel();
            storeCamera3DBaseline();
            redraw();
        }

        // Snap template to satisfy all pinned point constraints
        // ONLY calibrates when we have 4+ points
        // Returns true if successful, false if validation failed
        function snapTemplateToConstraints() {
            const numPins = countPinnedPoints();

            if (numPins >= 4) {
                // Regenerate template from 4+ pinned points
                const success = regenerateTemplateFromPins();

                if (success) {
                    // Update pinned points to their new positions after transform
                    const newPoints = getAllTemplatePoints();
                    for (const ptName of Object.keys(pinnedPoints)) {
                        if (newPoints[ptName]) {
                            pinnedPoints[ptName] = { ...newPoints[ptName] };
                        }
                    }
                }
            }
            // With < 4 points, just store the pinned positions
            return true;
        }

        // Translate all template points
        function translateTemplate(dx, dy) {
            const templateAnns = annotations.filter(a => a.isTemplate);
            for (const ann of templateAnns) {
                if (ann.points) {
                    ann.points = ann.points.map(p => [p[0] + dx, p[1] + dy]);
                }
                if (ann.center) {
                    ann.center = [ann.center[0] + dx, ann.center[1] + dy];
                }
            }
        }

        // Scale template around a point
        function scaleTemplateAround(cx, cy, scale) {
            const templateAnns = annotations.filter(a => a.isTemplate);
            for (const ann of templateAnns) {
                if (ann.points) {
                    ann.points = ann.points.map(p => [
                        cx + (p[0] - cx) * scale,
                        cy + (p[1] - cy) * scale
                    ]);
                }
                if (ann.center) {
                    ann.center = [
                        cx + (ann.center[0] - cx) * scale,
                        cy + (ann.center[1] - cy) * scale
                    ];
                }
                if (ann.axes) {
                    ann.axes = [ann.axes[0] * scale, ann.axes[1] * scale];
                }
            }
        }

        // Compute and apply affine transform from 3 points
        function computeAffineAndApply(constraints) {
            // For 3 points, compute affine transformation
            // This preserves parallel lines (good for rectangle)

            // Use least squares to find best translation + scale
            let sumDx = 0, sumDy = 0;
            for (const c of constraints) {
                sumDx += c.target.x - c.current.x;
                sumDy += c.target.y - c.current.y;
            }
            const dx = sumDx / constraints.length;
            const dy = sumDy / constraints.length;
            translateTemplate(dx, dy);
        }

        // For compatibility with old code
        function countAdjustedAnchors() {
            return countPinnedPoints();
        }

        // Reset all pinned points
        function resetAnchorAdjustments() {
            pinnedPoints = {};
            draggingPoint = null;
            calibrateDragStart = null;
            redraw();
            setStatus('Calibration points cleared');
        }

        // SOTACV toggle event listener
        document.getElementById('sotacvToggle').addEventListener('change', (e) => {
            useSOTACVPropagation = e.target.checked;
            console.log('[SOTACV] Propagation mode:', useSOTACVPropagation ? 'Client-side KLT+Kalman' : 'Backend optical flow');
            if (useSOTACVPropagation) {
                SOTACV.reset();  // Reset SOTACV state when enabling
            }
        });

        // Initialize
        initTimelineZoom();  // Set default timeline zoom
        loadVideos();
    </script>
</body>
</html>
